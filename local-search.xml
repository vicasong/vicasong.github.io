<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Java内存模型及变量可见性的一些简述</title>
    <link href="/java/juc-visible-sample-doc/"/>
    <url>/java/juc-visible-sample-doc/</url>
    
    <content type="html"><![CDATA[<p>最近有同事在线上遇到多线程共享变量可见性问题，简单处理后，我觉得这些基础应该需要再整理总结一下。（该部分内容需要熟悉JVM并发相关概念和了解JVM解释运行过程，有一定阅读门槛）</p><span id="more"></span><p>首先，我们应该先了解一下计算机内存、缓存和CPU之间的关系。</p><h1 id="计算机内存和CPU"><a href="#计算机内存和CPU" class="headerlink" title="计算机内存和CPU"></a>计算机内存和CPU</h1><p>大家都知道，CPU的运行速度很快，而计算机物理内存的读写速度却远远落后于CPU，为此，在CPU和物理内存之间添加了高速缓存来过渡。</p><p>为了权衡成本效益，缓存又被分成多层架构：一级缓存（L1 Cache）、二级缓存（L2 Cache）、三级缓存（L3 Cache），其容量依次变大，速度、和成本依次下降。</p><p>现代架构的CPU在显微镜下其局部大概是这样的：</p><img src="/images/cpu-cache-mic.jpg" class="" title="CPU显微图局部" alt="CPU显微图局部"><p>可以看到那一块块排列整齐的“建筑区”就是缓存，其示意图大概是这样的：</p><img src="/images/cache-line.jpg" class="" title="缓存行" alt="缓存行"><p><strong>缓存行（Cache Line）是存储交换管理的最小单元。</strong></p><p>当CPU要读取数据时，首先会从最近的存储中依次查找（首先是L1 Cache，找不到就去L2 Cache，依次直到找到要读取的数据）：</p><img src="/images/cpu-cache-grp.jpg" class="" title="存储架构" alt="存储架构"><ul><li>单核CPU，只有一个核心，缓存是CPU独占，不会出现访问冲突的问题；</li><li>单核多线程CPU，虽然有多个逻辑核心，但只有一个物理核心，多线程访问共享数据都会映射到相同的缓存位置，而且任何时刻只有一个线程在执行，因此也不会产生冲突；</li><li>多核多线程CPU，那么每一个核心都会有至少一个L1 Cache，多个线程分别在不同的核心上运行，那么每个核心都会保留一份共享数据的缓存，由于多核是并行执行，可能会出现各个核心的缓存数据不一致的冲突。</li></ul><p>为此，就要考虑多线程场景下CPU之间缓存如何保持一致。</p><h2 id="缓存一致性协议"><a href="#缓存一致性协议" class="headerlink" title="缓存一致性协议"></a>缓存一致性协议</h2><p>当多个cpu对同一块内存地址进行操作时，即共享数据时，如何保证它们操作的数据的一致性呢？</p><p><strong>缓存一致性</strong>，即当CPU0对缓存行中的数据做了修改，就要通知其他CPU，例如CPU1，它的缓存行失效了，那么CPU1想要操作该缓存行的数据时就会退行到从下一级存储重新加载数据。</p><p>缓存一致性协议有很多种不同的实现，但此处主要简述一下典型的MESI协议场景。</p><blockquote><p>在MESI协议中，每个缓存行都会有一个固定状态：<code>Modified</code>、<code>Exclusive</code>、<code>Shared</code>、<code>Invalid</code>。</p><p>假设当前有2个CPU核心：A和B</p><ul><li>当A从存储中加载一个变量时，会读取一段连续的数据，即缓存行，该缓存行将会被标记为“<strong>Exclusive</strong>”，此时只有A在操作该缓存行（唯一的数据缓存拷贝，且数据和主内存是一致的），数据会持续保留在缓存中（对缓存的修改不会立即刷新到下级存储，仅在有必要的时候）。</li><li>此时，B也要读取一个变量，刚好和A读取的数据在同一块缓存行中，那么此时B的缓存中也缓存了同样的缓存行，但A、B缓存行都会被标记为“<strong>Shared</strong>”（缓存数据和主内存依旧是保持一致的）。</li><li>然后我们假设A接下来对它读取的变量进行了修改，那么A的缓存行会被标记为“<strong>Modified</strong>”（此时，该缓存行的数据就和主内存不一致，且仅该缓存行的数据才是最新的），同时A会通知B说你的缓存行过时了，此时B的缓存行会被标记为“<strong>Invalid</strong>”（此缓存行已过期，缓存的内容不会再被使用）。</li><li>那么过了一段时间，B要再次读取它的变量了，但B此时的缓存行已经失效了，它应该去下一级存储重新读取数据，B对该数据块的读取访问会强制要求A将“<strong>Modified</strong>”标记的该缓存行刷新到下一级存储，等数据刷新后B读取到的就是最新的缓存行，此时A、B的缓存行再次被标记为“<strong>Shared</strong>”。</li></ul></blockquote><h2 id="处理器优化"><a href="#处理器优化" class="headerlink" title="处理器优化"></a>处理器优化</h2><p>上面提到缓存在多个CPU之间一致性的问题。除了缓存，还有一种硬件问题也需要注意，就是处理器优化。</p><p>为了使CPU的运算单元能被充分使用，处理器就会对代码指令做乱序执行，在单核CPU下这不会有什么问题，结果最终都是一样的，但在多核心下，对共享数据读写的乱序就会导致意想不到的问题。</p><h2 id="缓存之外"><a href="#缓存之外" class="headerlink" title="缓存之外"></a>缓存之外</h2><p>上面也提到了，缓存一致性协议会保证数据在缓存中是一致的。但理论是这样的，实际现实的时候，传统MESI协议中将缓存行（Cache Line）标记为“<strong>Invalid</strong>”和将“<strong>Invalid</strong>”标记的Cache Line刷入新数据的操作花费的成本很高，因此会有一个<strong>Invalidate Queue</strong>队列来异步进行。</p><p>同时，即使是离CPU最近的L1 Cache，依旧需要耗费好几个周期来访问数据，而当缓存写共享数据时的延迟更高，为了追求性能提升，在CPU和L1 Cache之间又加入了一层缓冲，称之为<strong>Store Buffer</strong>。但<code>store buffer</code>和其他缓存是有区别的，它只缓存写操作，CPU的部分写操作会先写入<code>store buffer</code>，之后<code>store buffer</code>会通过<strong>FIFO</strong>（先进先出）的顺序写入Cache。</p><p>上面两个额外的缓冲队列会导致数据加载或写入顺序出现乱序。</p><img src="/images/cpu-store-buffer.jpg" class="" title="缓存一致" alt="缓存一致"><p>当CPU0写共享数据时，先发送“<strong>Invalid</strong>”消息，然后把数据写入<code>store buffer</code>（会在某个时刻写入Cache），而读数据时，则先从<code>store buffer</code>中查找（其次再从Cache中查找），此时CPU1是看不到当前CPU0的<code>store buffer</code>中的数据，需要等<code>store buffer</code>刷新到Cache才会触发缓存行失效的操作；</p><p>在CPU1收到“<strong>Invalid</strong>”消息时，会把消息放入“<strong>Invalidate Queue</strong>”，随后异步将对应Cache Line设为“<strong>Invalid</strong>”，和<code>store buffer</code>不同，CPU1读取Cache时并不会查找“<strong>Invalidate Queue</strong>”，所以在这个异步标记Cache Line的过程中就会存在脏读。</p><h1 id="Java内存模型（JMM）"><a href="#Java内存模型（JMM）" class="headerlink" title="Java内存模型（JMM）"></a>Java内存模型（JMM）</h1><p>上面这么多硬件的问题，开发者已经头痛欲裂了。那么我们如何在编写程序的时候不用去过分考虑这么多硬件问题呢？<br>为了共享内存的正确，内存模型定义了多线程读写操作的行为规范，其解决并发问题的主要手段为：<strong>限制处理器优化</strong>、<strong>内存屏障</strong>。</p><p>Java内存模型定义了变量存储在主内存中，每个线程有自己的工作内存，其中保存了该线程使用的变量在主内存的副本拷贝，线程对变量的操作都在工作内存中进行，不能直接访问主内存，因此不同线程间无法直接访问对方工作内存中的变量，线程间共享变量的传递需要在工作内存和主存之间进行数据同步来进行。</p><p>以上提到的工作内存、主内存并非物理概念的内存，而是抽象概念，我们无需关心数据此时在Cache中还是在物理内存中，又或是在<code>store buffer</code>中。那么基于JMM，我们就可以不用管那一堆硬件问题导致的多线程问题，我们只需关注JMM本身即可。</p><p>Java内存模型就作用于工作内存和主内存之间，规定了如何进行数据同步以及什么时候进行，目的是解决多线程共享数据存在的数据不一致、指令重排、乱序执行等带来的问题。</p><h2 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h2><p>即在一个操作中，不可以被中断操作，要么完全执行，要么完全不执行。</p><p>在Java中使用关键字<code>synchronized</code>，通过对应字节码指令<code>monitorenter</code>和<code>monitorexit</code>来确保代码块的操作是原子的。</p><h2 id="有序性"><a href="#有序性" class="headerlink" title="有序性"></a>有序性</h2><p>上面提到，指令重排，它是一种优化，编译器会对程序指令进行重排优化，和CPU优化的指令乱序执行道理是一样的。</p><p>例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-type">boolean</span> <span class="hljs-variable">ready</span> <span class="hljs-operator">=</span> <span class="hljs-literal">false</span>;<br><span class="hljs-keyword">private</span> <span class="hljs-type">int</span> <span class="hljs-variable">x</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>;   <br><span class="hljs-comment">// 线程0计算</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">first</span><span class="hljs-params">()</span>&#123;<br>    x = x + <span class="hljs-number">1</span>;<br>    ready = <span class="hljs-literal">true</span>;             <br>&#125;<br><span class="hljs-comment">// 线程1计算</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">second</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-keyword">while</span> (!ready) &#123;<br>    &#125;<br>    x = x + <span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>编译优化排序后的指令不一定会按照书写顺序执行：</p><table><thead><tr><th>CPU时间片序号</th><th>线程</th><th>操作</th><th>线程内存</th><th>主内存</th></tr></thead><tbody><tr><td>1</td><td>thread-0</td><td>读取</td><td>x&#x3D;1</td><td>x&#x3D;1</td></tr><tr><td>2</td><td>thread-0</td><td>赋值</td><td>x&#x3D;1, ready&#x3D;true</td><td>x&#x3D;1, ready&#x3D;false</td></tr><tr><td>3</td><td>thread-0</td><td>写回</td><td>x&#x3D;1, ready&#x3D;true</td><td>x&#x3D;1, ready&#x3D;true</td></tr><tr><td>4</td><td>thread-1</td><td>读取</td><td>ready&#x3D;true, x&#x3D;1</td><td>x&#x3D;1, ready&#x3D;true</td></tr><tr><td>5</td><td>thread-0</td><td>计算</td><td>x&#x3D;2, ready&#x3D;true</td><td>x&#x3D;1, ready&#x3D;true</td></tr><tr><td>6</td><td>thread-0</td><td>写回</td><td>x&#x3D;2, ready&#x3D;true</td><td>x&#x3D;2, ready&#x3D;true</td></tr><tr><td>…</td><td>…</td><td>..</td><td>…</td><td>…</td></tr></tbody></table><p>而且，部分编译器还会对代码进行逻辑优化：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 优化1</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">second</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-type">boolean</span> <span class="hljs-variable">a1</span> <span class="hljs-operator">=</span> ready;<br>    <span class="hljs-keyword">while</span> (a1) &#123;&#125;<br>    x = x + <span class="hljs-number">1</span>;<br>&#125;<br><span class="hljs-comment">// 优化2</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">second</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-type">boolean</span> <span class="hljs-variable">a1</span> <span class="hljs-operator">=</span> ready;<br>    <span class="hljs-keyword">if</span> (!a1) <span class="hljs-keyword">return</span>;<br>    <span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) &#123;&#125;<br>    x = x + <span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>为此，我们可以使用<code>synchronized</code>和<code>volatile</code>关键字来确保有序：<code>volatile</code>关键字会限制指令重排和优化，<code>synchronized</code>则保证同一时刻只有一个线程运行指令从而避免。</p><h2 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h2><p>Java中的<code>volatile</code>关键字提供了一个功能，那就是其修饰的变量被修改后可以立即同步到主内存，其变量在每次读取前都从主内存刷新。</p><p>除了<code>volatile</code>，<code>synchronized</code>和<code>final</code>两个关键字也可以实现可见性，其中<code>synchronized</code>对应的字节码指令<code>monitorenter</code>和<code>monitorexit</code>会分别：</p><ul><li>清空工作内存中共享变量的值，从而使用共享变量时需要从主内存重新读取；</li><li>把工作内存中的共享变量的值写入到主内存。</li></ul><h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><h2 id="伪共享（False-Sharing）"><a href="#伪共享（False-Sharing）" class="headerlink" title="伪共享（False Sharing）"></a>伪共享（False Sharing）</h2><p>如果多个变量存在同一缓存行中不同区域时，对不同变量的修改就会争用同一个缓存行，导致看起来像是争用同一个共享变量一样。</p><img src="/images/cache-coherence.jpg" class="" title="缓存一致性" alt="缓存一致性"><p>缓存行会因此被不停标记为失效，并刷新和重新加载，这会带来性能问题。因此，对于同一块数据块上的不同变量的操作，可以通过填充数据使它们分布到不同的缓存行上来避免此性能问题。</p><h2 id="变量易失性"><a href="#变量易失性" class="headerlink" title="变量易失性"></a>变量易失性</h2><p>那么我们再次使用之前提到的代码，只是稍微简化了一下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-type">boolean</span> <span class="hljs-variable">ready</span> <span class="hljs-operator">=</span> <span class="hljs-literal">false</span>; <br><span class="hljs-comment">// 线程0</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">first</span><span class="hljs-params">()</span>&#123;<br>    ready = <span class="hljs-literal">true</span>;             <br>&#125;<br><span class="hljs-comment">// 线程1</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">second</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-keyword">while</span> (!ready) &#123;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>我们有2个线程会分别执行上面的对应方法，如代码所写：线程1将无限循环直到线程0将共享变量<code>ready</code>的值做出修改，从而终止线程1的循环。</p><p>然而事情并没有这么简单，首先每个线程都会有共享变量的副本（JMM）保存在各自的堆栈中，而当线程0对共享变量进行修改后，线程1并不能看到该变量的修改，它仍将保持无限循环。 </p><p>而且编译器很“聪明”，它认为在单线程下，变量<code>ready</code>不会被修改，甚至对条件判断逻辑做出优化。</p><blockquote><p><code>volatile</code>会强制让数据交换使用主内存（JMM抽象概念的主内存，并非物理主内存），这里有几点需要注意。  </p><ol><li>在Java1.5时代，主流CPU架构中，缓存一致性是可选功能且默认不开启，<code>volatile</code>为此担任了一个重要角色就是使用指令开启缓存一致性。但如今该功能已成为架构中的必选项，缓存一致性是硬件层协议，软件开发者无需额外处理。</li><li><code>volatile</code>不会也无法直接让数据从物理内存中读写，因为效率太低了。</li><li>CPU存储架构对其上的应用是透明的，JMM足够抽象，<code>volatile</code>不能使CPU立即刷新缓存，系统会在必要的时候进行缓存刷新操作，由缓存一致性保证数据在缓存中是始终一致的。</li></ol></blockquote><p>同时<code>volatile</code>关键字标记的变量会在编译器或CPU进行指令优化时做出一些限制。涉及到几个屏障（barriers）：<code>LoadStore</code>、<code>LoadLoad</code>、<code>StoreLoad</code>、<code>StoreStore</code>。</p><h3 id="缓存一致性-amp-内存一致性"><a href="#缓存一致性-amp-内存一致性" class="headerlink" title="缓存一致性&amp;内存一致性"></a>缓存一致性&amp;内存一致性</h3><p>缓存一致性协议确保对同一内存位置的读取将始终返回最新的值。仅当同一内存位置的缓存有多个副本时，才需要缓存一致性协议，其工作内容就是保持所有数据副本在缓存中的一致性。</p><p>内存一致性模型则关注于读取和写入到不同内存位置的相对顺序，完全存储定序，<strong>TSO（Total Storage Order）</strong>。</p><p>我们定义读取操作为<em>load</em>，写入操作为<em>store</em>，由于<code>store buffer</code>的存在，CPU对数据的写操作其他CPU并不能及时看见。</p><p>例如：</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">y</span><span class="hljs-operator">=</span><span class="hljs-number">2</span><span class="hljs-comment">;</span><br><span class="hljs-attribute">a</span><span class="hljs-operator">=</span>x<span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure><p>即使CPU0做了先<code>store y</code>，再<code>load x</code>，在CPU1看来就是先<code>load x</code>，再<code>store y</code>。因此<code>StoreLoad</code>可能会变成<code>LoadStore</code>。</p><p>由于X86架构CPU提供了TSO，所以<code>LoadStore</code>、<code>LoadLoad</code>、<code>StoreStore</code>这几个屏障相当于空操作，主要用于限制编译器优化，<code>StoreLoad</code>会有额外指令实现。</p><table><thead><tr><th>屏障类型</th><th>示例指令</th><th>说明</th></tr></thead><tbody><tr><td>LoadLoad</td><td>Load1;LoadLoad;Load2</td><td>该屏障确保Load1数据的加载先于Load2及其后所有读取指令的操作</td></tr><tr><td>StoreStore</td><td>Store1;StoreStore;Store2</td><td>该屏障确保Store1的写入操作先于Store2及其后所有写入指令的操作</td></tr><tr><td>LoadStore</td><td>Load1;LoadStore;Store2</td><td>确保Load1的数据加载先于Store2及其后所有的写入指令的操作</td></tr><tr><td>StoreLoad</td><td>Store1;StoreLoad;Load2</td><td>确保Store1的写入操作先于Load2及其后所有读取指令的操作。同时该屏障之前的所有数据访问指令完成之后，才执行该屏障之后的数据访问指令</td></tr></tbody></table><p>先看几个例子（我们假设有<code>volatile</code>变量<code>A</code>、<code>B</code>）：</p><p>1）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java">tmp=A <span class="hljs-comment">// volatile 读取</span><br>[LoadLoad]<br>[LoadStore]<br><span class="hljs-comment">// 读读、读写屏障，此时任何读取或写入操作都不能移动到屏障之前，但它们之间的顺序可重排</span><br></code></pre></td></tr></table></figure><p>2）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 读写、写写屏障，此时任何读取或写入操作都不能移动到屏障之后，但它们之间的顺序可重排</span><br>[LoadStore]<br>[StoreStore]<br>B=tmp <span class="hljs-comment">// volatile 写入</span><br></code></pre></td></tr></table></figure><p>3）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java">[LoadStore]<br>[StoreStore]<br>A=tmp1  <span class="hljs-comment">// volatile 写入</span><br>tmp2=B  <span class="hljs-comment">// volatile 读取</span><br>[LoadLoad]<br>[LoadStore]<br></code></pre></td></tr></table></figure><p>如例3，<code>volatile</code>变量的读取或写入仍然可能会被重新排序，此时需要额外的屏障去阻止CPU或编译器对此的优化排序，此处会添加一个新屏障，就是<code>StoreLoad</code>，该屏障会被添加到写操作之后。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs java">[LoadStore]<br>[StoreStore]<br>A=tmp1  <span class="hljs-comment">// volatile 写入</span><br>[StoreLoad]<br>tmp2=B  <span class="hljs-comment">// volatile 读取</span><br>[LoadLoad]<br>[LoadStore]<br></code></pre></td></tr></table></figure><p><code>StoreLoad</code>屏障同时具备<code>StoreStore</code>、<code>LoadLoad</code>、<code>LoadStore</code>三个屏障的效果，会被编译为<code>MFENCE</code>或<code>lock addl %(RSP),0</code>指令。锁定主线，停止读取操作直到所有缓冲区（注意，CPU寄存器、Store Buffer也算缓冲区）已经刷新，确保了加载的数据全局可见。</p><blockquote><p>X86是一种处理器架构，我们用的大多数CPU都是X86架构，Intel和AMD生产的绝大多数CPU，比如奔腾（Pentium），赛扬(Celeron)，酷睿(core)，Xeon等等都是该架构，而X86_64是X86的扩充，并且兼容X86</p></blockquote><h3 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h3><p>如上面所述，既然提到了内存屏障，自然会提到Java API提供的几种屏障：</p><ol><li>VarHandle#acquireFence &#x3D; loadFence</li></ol><p>对应指令<code>lfence</code>，实现Load屏障，实现方式按架构不同，如：将<strong>Invalidate Queue</strong>失效，强制读L1 Cache，且等待之前的读取完成，从而确保之后的读不会调度到<code>lfence</code>之前</p><ol start="2"><li>VarHandle#releaseFence &#x3D; storeFence</li></ol><p>对应指令<code>sfence</code>，实现Store屏障，实现方式按架构不同，如：将等待<strong>store buffer</strong>中的缓冲刷新到L1 Cache，从而确保后续写不会调度到<code>sfence</code>之前；但一直等待缓冲刷新会很不效率，有些实现会将后续写无论是否命中Cache都加入<strong>store buffer</strong>，但会对这些写进行标记，在标记过的写刷入Cache之前，<code>sfence</code>之前的写一定已经刷入Cache了，从而确保后续写不会调度到<code>sfence</code>之前</p><ol start="3"><li>VarHandle#fullFence &#x3D; fullFence</li></ol><p>对应指令<code>mfence</code>，有些平台会对应<code>lock</code>。首先<code>mfence</code>实现了Full屏障，会同时刷新<strong>store buffer</strong>和<strong>Invalidate Queue</strong>，即实现了Load和Store屏障的效果；而<code>lock</code>指令修饰的操作会锁定，只能由当前CPU访问，这个修饰会让指令原子化，且自带Full屏障的效果。同时，有些平台上IO操作、<code>exch</code>原子交换等指令也带有该内存屏障的效果。</p><p>同时注意，Full屏障并不能单纯的组合<code>lfence</code>和<code>sfence</code>，因为组合这两个屏障只能解决指令重排的问题，依然会有可见性问题存在，可以视为<code>lfence</code>和<code>sfence</code>也能被重排。</p><ol start="4"><li>VarHandle#loadLoadFence &#x3D; loadLoadFence &#x2F; VarHandle#storeStoreFence &#x3D; storeStoreFence</li></ol><p>用于编译调整，实际实现指向<code>lfence</code>和<code>sfence</code></p><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>在有些平台的JVM实现中，<code>long</code>、<code>double</code>等64位数据的读写会被拆成两次32位读写操作，在多线程并发下可能会导致读取或写入不一致的问题，使用<code>volatile</code>可以保证该类型变量读写原子性。但实际上是有性能损耗的（<code>volatile</code>还保证了顺序性），即使在X86架构64位机器上，其已经保证了对64bit数据的读取和写入是原子性的，但我们无法保证程序不会在32位机器上运行，所以对<code>long</code>、<code>double</code>使用<code>volatile</code>是有意义的。</p><p>基于上述屏障，在<code>volatile</code>被全局可见时，其之前写入的其他数据也会被刷新，从而全局可见。例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java">a=<span class="hljs-number">2</span>;<br>b=++a;<br>X=<span class="hljs-number">1</span>; <span class="hljs-comment">// volatile 写入</span><br></code></pre></td></tr></table></figure><p>那么其他线程在<code>X=1</code>可见时，其对变量<code>a</code>、<code>b</code>也可见。</p><!--https://software.rajivprab.com/2018/04/29/myths-programmers-believe-about-cpu-caches/--><!--https://shipilev.net/blog/2014/on-the-fence-with-dependencies/--><!--https://aaron-ai.com/docs/cache_consistency_and_memory_barrier/-->]]></content>
    
    
    <categories>
      
      <category>java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从Java8升级到Java17</title>
    <link href="/java/upgrade-to-java17/"/>
    <url>/java/upgrade-to-java17/</url>
    
    <content type="html"><![CDATA[<p>自2014年初发布Java8以来，现如今已经8年了。2018年9月25日，Oralce正式发布了Java11，这是继Java8之后的首个LTS（long-term support：长期支持版本）。而2021年9月又发布了第二个LTS版本：Java17，同时LTS发布节奏从三年缩短到两年。那么，下一个LTS将会是在2023年9月发布的Java21。此时选择从Java8升级，最好的选择就是Java17，Oracle从Oracle JDK 17开始再次提供免费的版本和更新，且支持商用和生产用途。</p><span id="more"></span><p>基于OptaPlanner的用例基准测试表明：</p><ul><li><p>对于默认的G1GC，Java 17 比 Java 11 快 8.66%，比 Java 16 快 2.41%</p></li><li><p>对于ParallelGC，Java 17 比 Java 11 快 6.54%，比 Java 16 快 0.37%</p></li><li><p>从Java 8 到 Java 11，G1GC平均速度改进为16.1%，ParallelGC为4.5%</p></li></ul><p>由于JAVAEE在java11+已经被移除，相关接口将被<code>jakarta</code>替代，因此部分包将发生变化：<code>javax.*</code> -&gt; <code>jakarta.*</code></p>]]></content>
    
    
    <categories>
      
      <category>java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>升级到Java模块系统</title>
    <link href="/java/upgrade-to-module/"/>
    <url>/java/upgrade-to-module/</url>
    
    <content type="html"><![CDATA[<p>具2022年初New Relic发布的《Java生态系统状况报告》显示现有超48%的应用程序在生产中使用Java 11（2020年为11.11%），而Java 8则占46.45%。Java 17的排名还不是很高，但它在发布后的几个月里，已经超过了Java 6、Java 10和Java 16版本的占比。升级到新版本的Java已经是大势所趋，为此本文着重描述如何从Java8升级到Java模块系统（Java9+）。</p><span id="more"></span><h1 id="为何要升级到模块系统"><a href="#为何要升级到模块系统" class="headerlink" title="为何要升级到模块系统"></a>为何要升级到模块系统</h1><h2 id="时代背景"><a href="#时代背景" class="headerlink" title="时代背景"></a>时代背景</h2><p>如摘要所述，Java8及以下版本已经逐渐失去大半“Java江山”。  </p><p>当然这个理由未必能让你感兴趣做出升级，请继续往下看。</p><h2 id="现如今的问题"><a href="#现如今的问题" class="headerlink" title="现如今的问题"></a>现如今的问题</h2><h3 id="类路径地狱"><a href="#类路径地狱" class="headerlink" title="类路径地狱"></a>类路径地狱</h3><p>Java运行时使用类路径（classpath）来查找类，这可以说是使用Java的常识，请看如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">String</span> <span class="hljs-variable">classPath</span> <span class="hljs-operator">=</span> System.getProperty(<span class="hljs-string">&quot;java.class.path&quot;</span>);<br><span class="hljs-type">String</span> <span class="hljs-variable">printLines</span> <span class="hljs-operator">=</span> String.join(<span class="hljs-string">&quot;\n&quot;</span>,classPath.split(<span class="hljs-string">&quot;;&quot;</span>));<br>System.out.println(printLines);<br></code></pre></td></tr></table></figure><p>这段代码很简单，用来输出打印运行当前Java程序的类路径，即使是一个简单的应用，类路径也会冗长复杂。</p><figure class="highlight text"><figcaption><span>console.out</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs text">C:\Users\xx\IdeaProjects\example\build\classes\java\main<br>C:\Users\xx\IdeaProjects\example\build\resources\main<br>C:\Users\xx\.gradle\caches\modules-2\files-2.1\com.google.guava\guava\31.1-jre\60458f877d055d0c9114d9e1a2efb737b4bc282c\guava-31.1-jre.jar<br>C:\Users\xx\.gradle\caches\modules-2\files-2.1\org.hibernate.validator\hibernate-validator\7.0.4.Final\36c91ad2987af9c5dd19eb4f011d9d294ac1721e\hibernate-validator-7.0.4.Final.jar<br>C:\Users\xx\.gradle\caches\modules-2\files-2.1\com.google.guava\failureaccess\1.0.1\1dcf1de382a0bf95a3d8b0849546c88bac1292c9\failureaccess-1.0.1.jar<br>C:\Users\xx\.gradle\caches\modules-2\files-2.1\com.google.guava\listenablefuture\9999.0-empty-to-avoid-conflict-with-guava\b421526c5f297295adef1c886e5246c39d4ac629\listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar<br>C:\Users\xx\.gradle\caches\modules-2\files-2.1\com.google.code.findbugs\jsr305\3.0.2\25ea2e8b0c338a877313bd4672d3fe056ea78f0d\jsr305-3.0.2.jar<br>C:\Users\xx\.gradle\caches\modules-2\files-2.1\org.checkerframework\checker-qual\3.12.0\d5692f0526415fcc6de94bb5bfbd3afd9dd3b3e5\checker-qual-3.12.0.jar<br>C:\Users\xx\.gradle\caches\modules-2\files-2.1\com.google.errorprone\error_prone_annotations\2.11.0\c5a0ace696d3f8b1c1d8cc036d8c03cc0cbe6b69\error_prone_annotations-2.11.0.jar<br>C:\Users\xx\.gradle\caches\modules-2\files-2.1\com.google.j2objc\j2objc-annotations\1.3\ba035118bc8bac37d7eff77700720999acd9986d\j2objc-annotations-1.3.jar<br>C:\Users\xx\.gradle\caches\modules-2\files-2.1\jakarta.validation\jakarta.validation-api\3.0.0\8c8eecc40da64037d7731356511c568d466f8480\jakarta.validation-api-3.0.0.jar<br>C:\Users\xx\.gradle\caches\modules-2\files-2.1\org.jboss.logging\jboss-logging\3.4.1.Final\40fd4d696c55793e996d1ff3c475833f836c2498\jboss-logging-3.4.1.Final.jar<br>C:\Users\xx\.gradle\caches\modules-2\files-2.1\com.fasterxml\classmate\1.5.1\3fe0bed568c62df5e89f4f174c101eab25345b6c\classmate-1.5.1.jar<br></code></pre></td></tr></table></figure><p>所有类按照<code>-classpath</code>参数定义的顺序排列成一个平面列表。当JVM加载一个类时，按照顺序读取类路径，找到所需的类，然后结束搜索就并加载类。如果在类路径中没有找到所需的类又会得到一个运行时异常，由于类会延迟加载，因此在用户看来应用程序会在使用中莫名其妙的突然出错。而当类路径上有重复类时，则会出现更为隐蔽的问题，一般来说，当类路径包含两个具有相同（完全限定名称）的类时，即使它们不相关，也只有一个会被成功加载。</p><h3 id="封装依赖"><a href="#封装依赖" class="headerlink" title="封装依赖"></a>封装依赖</h3><p>Java提供的访问修饰符（比如<code>private</code>、<code>protected</code>或<code>public</code>等），可以实现类的封装。例如将一个类置为<code>protected</code>，那么就可以防止其他类访问该类，除非这些类与该类位于相同的包中。但这样做会产生一个问题：如果想从当前库的另一个包访问该类，同时仍然防止其他类使用该类，那么应该怎么做呢？事实是无法做到。当然，可以让类公开，但公开意味着对所有库公开，也就意味着没有封装。我们没有办法隐藏这样的实现包。   </p><p>例如，<code>Guava</code>中的<code>com.google.common.base.internal.Finalizer</code>，它并不是官方API的一部分，而是一个公共类，其他<code>Guava</code>包可以使用<code>Finalizer</code>，这也意味着无法阻止任意使用者使用诸如<code>Finalizer</code>之类的类。  </p><p>对于Java平台的内部类来说也存在同样的情况。诸如<code>sun.misc</code>之类的包经常被应用程序代码所访问，虽然相关文档严重警告它们是不受支持的API，不应该使用。例如：<code>sun.misc.BASE64Encoder</code>之类的工具类仍然在应用程序代码中被使用。缺乏封装性迫使这些类被认为是“半公共”API。</p><h2 id="模块化的优势"><a href="#模块化的优势" class="headerlink" title="模块化的优势"></a>模块化的优势</h2><p>Java一直是构建大型应用程序的主流语言之一，且Java生态系统中有许多库，在此背景下构建的系统往往超出我们理解和有效开发范围，为什么这么说呢？我们无法理清各部分代码块之间的关系，在使用繁多的归档文件（Java Archive, JAR）时更加突出，模块化能很好的管理和减少这种复杂性，而从Java9开始引入了模块系统，且Java本身也已经被模块化。</p><h3 id="什么是模块化"><a href="#什么是模块化" class="headerlink" title="什么是模块化"></a>什么是模块化</h3><p>模块化（modularization）是指将系统分解成独立且相互关联的模块的行为。</p><p>模块（module）是包含代码的可识别组件，使用元数据来描述模块及与其他模块的关系。</p><p>在理想情况下，模块从编译时到运行时都是可识别的，关系是清晰明确的。一个应用程序由多个模块协作组成。</p><p><strong>强封装</strong> </p><p>模块能对其他模块隐藏其部分代码。这样就可以清晰的区分公开代码和被视为内部实现细节的隐藏代码，从而防止模块之间发生意外或不必要的耦合，即其他模块无法使用该模块被封装的内容。</p><p>其实封装依赖在Java模块系统出现之前就早有诟病，库的开发者即使明确将实现代码放在<code>xx.internal</code>之类意味不公开的内部实现包下，但谁会在意呢，只要有类可以用，就有人会使用它，导致库的更新对使用者是破坏性的。</p><p><strong>公共接口</strong></p><p>模块要一起工作，并不是所有的东西都会封装。其中未封装的代码应该是模块的公共API部分。由于其他模块可以访问这部分公共代码，须谨慎对其进行管理。对公开代码进行更改则可能会导致依赖于它的其他模块无法正常使用，因此，模块对其他模块的公开部分应该定义良好且稳定。</p><p><strong>显式依赖</strong></p><p>模块如果需要使用其他模块，则模块之间构成依赖关系，这些依赖关系必须是模块定义的一部分。显式依赖可以构建出一个模块图：节点表示模块，而边缘表示模块之间的依赖关系。<br>通过模块图可以清楚的了解应用程序和运行应用所需各个模块间的关系。它为模块的可靠配置提供了基础。</p><p>Java代码中虽然使用了显式的<code>import</code>语句，但从严格意义上讲，这些依赖关系是编译时结构，一旦代码被打包到<code>JAR</code>文件，就无法确定哪些文件包含运行所需的类。</p><h3 id="模块化带来的好处"><a href="#模块化带来的好处" class="headerlink" title="模块化带来的好处"></a>模块化带来的好处</h3><p><strong>明确的依赖</strong>  </p><p>在编译或运行代码之前，模块系统会检查模块是否满足所有依赖关系，从而导致更少的运行时错误。</p><p><strong>强封装</strong>  </p><p>模块明确向其他模块的公开内容，阻止对未公开的内部实现细节的意外依赖。</p><p><strong>安全</strong></p><p>在JVM的最深层次上执行强封装，减少Java运行时的攻击面，同时无法获得对敏感内部类的反射访问。</p><p><strong>可扩展</strong></p><p>显式定义的模块边界能够让开发团队并行工作，创建可维护的代码库。</p><p><strong>优化</strong></p><p>由于模块系统清楚的知道模块之间的关系，包括Java平台模块，因此在JVM启动期间不需要考虑其他未使用的代码。同时，也可以为此创建模块分发的最小配置（例如应用镜像）。在模块出现之前，没有可用的显式依赖信息，一个类可以引用类路径中任何其他类。</p><h1 id="迁移到模块系统"><a href="#迁移到模块系统" class="headerlink" title="迁移到模块系统"></a>迁移到模块系统</h1><p>根据系统业务及可用资源充分评估是否合适进行模块化，我们的最终目的是模块化，但现实并非如此，为此针对不同系统可选用不同的升级方案。  </p><p>以下为模块化所需的三个步骤，但同时也是模块化之路的三种不同方案即三种目标。</p><h2 id="升级Java版本"><a href="#升级Java版本" class="headerlink" title="升级Java版本"></a>升级Java版本</h2><p>向后兼容性一直是Java的主要目标。当不需要使用模块系统时，为什么还要迁移到Java9+ 呢？升级将带来新的API、工具和性能改进（<a href="/java/upgrade-to-java17/" title="从Java8升级到Java17">从Java8升级到Java17</a>）。  </p><h3 id="切换Java"><a href="#切换Java" class="headerlink" title="切换Java"></a>切换Java</h3><p>一般的，如果应用程序和依赖只使用了JDK认可的API，那么直接切换到新版本Java上编译运行是不会出现问题的。但这是理想情况，现在的Java本身已经实现了模块化，无论应用程序是否模块化。</p><p>应用程序可以依旧使用类路径（<code>-classpath</code>），而所有类路径上的代码都会被当做<em>未命名模块</em>（UnNamed Module）。  而Java模块使用模块路径（<code>--module-path</code>），由于Java平台本身已经模块化，<code>java/javac</code>命令会默认使用JDK模块路径。</p><p>我们在Java<code>jmods</code>目录可以清楚的看到平台的模块文件：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs text">java.base.jmod<br>java.compiler.jmod<br>java.datatransfer.jmod<br>java.desktop.jmod<br>java.instrument.jmod<br>java.logging.jmod<br>java.management.jmod<br>java.management.rmi.jmod<br>java.naming.jmod<br>java.net.http.jmod<br>java.prefs.jmod<br>java.rmi.jmod<br>java.scripting.jmod<br>java.se.jmod<br>java.security.jgss.jmod<br>java.security.sasl.jmod<br>java.smartcardio.jmod<br>java.sql.jmod<br>java.sql.rowset.jmod<br>java.transaction.xa.jmod<br>java.xml.crypto.jmod<br>java.xml.jmod<br>jdk.accessibility.jmod<br>jdk.aot.jmod<br>jdk.attach.jmod<br>jdk.charsets.jmod<br>jdk.compiler.jmod<br>jdk.crypto.cryptoki.jmod<br>jdk.crypto.ec.jmod<br>jdk.crypto.mscapi.jmod<br>jdk.dynalink.jmod<br>jdk.editpad.jmod<br>jdk.hotspot.agent.jmod<br>jdk.httpserver.jmod<br>jdk.internal.ed.jmod<br>jdk.internal.jvmstat.jmod<br>jdk.internal.le.jmod<br>jdk.internal.opt.jmod<br>jdk.internal.vm.ci.jmod<br>jdk.internal.vm.compiler.jmod<br>jdk.internal.vm.compiler.management.jmod<br>jdk.jartool.jmod<br>jdk.javadoc.jmod<br>jdk.jcmd.jmod<br>jdk.jconsole.jmod<br>jdk.jdeps.jmod<br>jdk.jdi.jmod<br>jdk.jdwp.agent.jmod<br>jdk.jfr.jmod<br>jdk.jlink.jmod<br>jdk.jshell.jmod<br>jdk.jsobject.jmod<br>jdk.jstatd.jmod<br>jdk.localedata.jmod<br>jdk.management.agent.jmod<br>jdk.management.jfr.jmod<br>jdk.management.jmod<br>jdk.naming.dns.jmod<br>jdk.naming.rmi.jmod<br>jdk.net.jmod<br>jdk.pack.jmod<br>jdk.rmic.jmod<br>jdk.scripting.nashorn.jmod<br>jdk.scripting.nashorn.shell.jmod<br>jdk.sctp.jmod<br>jdk.security.auth.jmod<br>jdk.security.jgss.jmod<br>jdk.unsupported.desktop.jmod<br>jdk.unsupported.jmod<br>jdk.xml.dom.jmod<br>jdk.zipfs.jmod <br></code></pre></td></tr></table></figure><h4 id="深度反射问题"><a href="#深度反射问题" class="headerlink" title="深度反射问题"></a>深度反射问题</h4><p>当使用模块时，默认情况下JDK不允许访问封装的包以及深度反射（指使用反射技术访问类的非公共代码）其他模块（包括平台模块）中的代码。在模块化系统之前，平台内部类的滥用已经成为许多安全问题的源头，并且阻碍了API的发展。而一些常用的库确实是这么做的，例如<code>javassist</code>库试图调用<code>java.lang.Class</code>上的<code>defineClass</code>方法，那么此时会引起如下错误：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">java.lang.reflect.InaccessibleObjectException: Unable to make protected final<br>    java.lang.Class java.lang.ClassLoader.defineClass(java.lang.String,byte[],<br>                                        int,int,java.security.ProtectionDomain)<br>  throws java.lang.ClassFormatError accessible: module java.base does not<br>  &quot;opens java.lang&quot; to unnamed module @0x7b3300e5<br></code></pre></td></tr></table></figure><p>如上描述，当前未命名模块不能访问平台模块<code>java.base</code>的<code>protected defineClass</code>方法，因为平台模块<code>java.base</code>未将<code>java.lang</code>包对此未命名模块开放。  </p><p>此处引入了一个概念，即开放包（open package）。同类的概念还有导出包（export package）、开放模块（open module）等。</p><p><strong>导出包</strong></p><p>导出包指模块声明自身的公共API所在的包，指示了模块对外公开的内容，而未被导出的其他包即为封装包，其他模块可以直接访问该模块的导出部分（公共部分）。</p><p><strong>开放包和开放模块</strong></p><p>许多库都希望可以进行深度反射。但由于强封装性，即使导出了实现类所在的包，也会禁止其对非公共部分进行深度反射。     </p><p>因此，开放包可以向其他模块公开包中封装的资源，允许对指定包内的代码进行深度反射，同理，开放模块则将开放范围延展到整个模块，开放整个模块看似有点不妥，但当不能确定在运行时库或框架使用什么类型时，这种做法是很方便的。 </p><p>Java9+添加了两个反射对象的新方法：<code>canAccess</code>和<code>trySetAccessible</code>，考虑到深度反射并不总是被允许，使用这些方法可以避免调用<code>setAccessible</code>时抛出异常。   </p><p>我们可以仅开放允许深度反射的包，而不导出它。这样对于框架来说，开放包是可以自由访问的，但从开发人员的角度看，这部分未导出的开放包仍被强封装。  </p><p>回到上面我们遇到的错误，未命名模块无法通过深度反射访问平台模块非公共的部分，这里需要开放平台模块<code>java.base</code>的<code>java.lang</code>包，通常在模块描述文件中使用<code>opens xxx</code>子句来开放一个包，但很显然我们无法修改平台模块。</p><p>此时可以通过命令行对那些无法控制的模块描述做出补充：   </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">java --add-opens java.base/java.lang=ALL-UNNAMED<br></code></pre></td></tr></table></figure>  <p>其中，<code>java.base/java.lang</code>是授权访问的<code>模块/包</code>格式，最后一个参数是获取访问权限的模块。因为代码仍然在类路径中，所以使用了<code>ALL-UNNAMED</code>，它表示类路径（未命名模块）。现在，这个包是开放的，所以深度反射不再是非法的。同理，我们可以使用<code>--add-exports</code>来强制导出包，但这些都只是一个解决方法。</p><h4 id="封装访问"><a href="#封装访问" class="headerlink" title="封装访问"></a>封装访问</h4><p>JDK包含许多私有的内部API，这些API应该仅被JDK所使用。从早期开始，这一规定就已被清楚地记载下来。比如<code>sun.*</code>和<code>jdk.internal.*</code>包。而当你的程序或程序依赖的库任然在使用这些类型时，将无法通过编译。</p><p>例如早期Java程序使用<code>sun.security.x509</code>包中的类型，切换到更高版本的Java时则会遇到如下的编译错误：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text"> error: package sun.security.x509 is not visible<br>import sun.security.x509.X500Name;<br>                   ^<br>  (package sun.security.x509 is declared in module java.base, which does not<br>   export it to the unnamed module)<br></code></pre></td></tr></table></figure>  <p>如果这部分代码可控，那么涉及访问封装类型时，应该对其进行修改，用公共类型替代。而当所使用的库使用了封装类型且我们自己无法修复这个问题，同上也可以使用命令行标志在编译时打破封装。<br>此处可使用<code>--add-exports &lt;module&gt;/&lt;package&gt;=&lt;targetmodule&gt;</code>这样的语法导出封装的包，但这只是一种零时解决办法。</p><h4 id="命令行过长"><a href="#命令行过长" class="headerlink" title="命令行过长"></a>命令行过长</h4><p>一些操作系统限制了可执行命令行的长度。当在迁移期间需要添加许多标志时，可能会触发这些限制。此时的替代做法是使用一个文件将所有的命令行参数提供给<code>java/javac</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">java @arguments.txt</span><br></code></pre></td></tr></table></figure>  <p>参数文件必须包含所有必要的命令行标志。文件中的每一行都包含一个选项。例如，<code>arguments.txt</code>可以包含以下内容：</p><figure class="highlight text"><figcaption><span>arguments.txt</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs text">-cp application.jar:javassist.jar<br>--add-opens java.base/java.lang=ALL-UNNAMED<br>--add-exports java.base/sun.security.x509=ALL-UNNAMED<br>-jar application.jar<br></code></pre></td></tr></table></figure>  <h4 id="移除的类型"><a href="#移除的类型" class="headerlink" title="移除的类型"></a>移除的类型</h4><p>随着Java的升级，其中一些内部类会被移除（依赖内部实现类是不规范的）。例如在<em>Java 9</em>中删除的内部类是<code>sun.misc.BASE64Encoder</code>，而在这之前的<code>Java 8</code>中引入了其公开替代实现<code>java.util.Base64</code>。</p><p>但我们并总是清楚这些替代实现，而JDK附带了一个工具<code>jdeps</code>来帮助我们。<code>jdeps</code>可以找到被删除或封装的JDK类型，并建议替换，其工作基于类文件（.class文件）而非源码文件，例如对在Java 8环境下编译且使用了<code>sun.misc.BASE64Decoder</code>的类进行解析：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs text">$ jdeps -jdkinternals removed/RemovedTypes.class<br><br>RemovedTypes.class -&gt; JDK removed internal API<br>   removed.RemovedTypes -&gt; sun.misc.BASE64Decoder<br>   JDK internal API (JDK removed internal API)<br><br>Warning: JDK internal APIs are unsupported and private to JDK implementation<br>that are subject to be removed or changed incompatibly and could<br>break your application.<br>Please modify your code to eliminate dependence on any JDK internal APIs.<br>For the most recent update on JDK internal API replacements, please check:<br>https://wiki.openjdk.java.net/display/JDK8/Java+Dependency+Analysis+Tool<br><br>JDK Internal API                         Suggested Replacement<br>----------------                         ---------------------<br>sun.misc.BASE64Decoder                   Use java.util.Base64 @since 1.8<br></code></pre></td></tr></table></figure>  <h4 id="缺失模块"><a href="#缺失模块" class="headerlink" title="缺失模块"></a>缺失模块</h4><p>JDK中Java SE和Java EE之间的重叠一直令人困惑。Java EE应用程序服务器通常提供了API的自定义实现。简单地讲，是通过将替代实现放在类路径上，覆盖默认的JDK版本来完成的。而在Java模块系统不允许多个模块提供相同的包。如果在类路径中找到重复的包（在未命名的模块中），则会将其忽略。在任何情况下，若Java SE和应用程序服务器都提供<code>java.xml.bind</code>包，则不会实现预期的行为，为了避免出现该问题，在<strong>基于类路径</strong>的场景中，默认情况下不会解析这些模块。</p><p>例如：  </p><figure class="highlight java"><figcaption><span>JaxbExample.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> example;<br><br><span class="hljs-keyword">import</span> javax.xml.bind.JAXBContext;<br><span class="hljs-keyword">import</span> javax.xml.bind.JAXBException;<br><span class="hljs-keyword">import</span> javax.xml.bind.Marshaller;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">JaxbExample</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String... args)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>      <span class="hljs-type">Book</span> <span class="hljs-variable">book</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Book</span>();<br>      book.setTitle(<span class="hljs-string">&quot;Java 9 Modularity&quot;</span>);<br><br>      <span class="hljs-type">JAXBContext</span> <span class="hljs-variable">jaxbContext</span> <span class="hljs-operator">=</span> JAXBContext.newInstance(Book.class);<br>      <span class="hljs-type">Marshaller</span> <span class="hljs-variable">jaxbMarshaller</span> <span class="hljs-operator">=</span> jaxbContext.createMarshaller();<br><br>      jaxbMarshaller.setProperty(Marshaller.JAXB_FORMATTED_OUTPUT, <span class="hljs-literal">true</span>);<br><br>      jaxbMarshaller.marshal(book, System.out);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure> <p>上述代码在Java 8可以正常使用，但在新版本Java进行编译就会出现问题：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs text">example/JaxbExample.java:3: error: package javax.xml.bind is not visible<br>import javax.xml.bind.JAXBContext;<br>               ^<br> (package javax.xml.bind is declared in module java.xml.bind, which is not<br>   in the module graph)<br>example/JaxbExample.java:4: error: package javax.xml.bind is not visible<br>import javax.xml.bind.JAXBException;<br>               ^<br> (package javax.xml.bind is declared in module java.xml.bind, which is not<br>   in the module graph)<br>example/JaxbExample.java:5: error: package javax.xml.bind is not visible<br>import javax.xml.bind.Marshaller;<br>               ^<br> (package javax.xml.bind is declared in module java.xml.bind, which is not<br>   in the module graph)<br>3 errors<br></code></pre></td></tr></table></figure>    <p>为了解决这个问题，则需要添加<code>--add-modules java.xml.bind</code>选项到命令行<code>java</code>或<code>javac</code>的调用中以添加解析模块<code>java.xml.bind</code>。当然这些模块会随着版本升级逐渐被删除，你可以通过将这些技术的Jar文件添加到类路径来避免。</p><h2 id="移动到模块路径"><a href="#移动到模块路径" class="headerlink" title="移动到模块路径"></a>移动到模块路径</h2><h3 id="模块化"><a href="#模块化" class="headerlink" title="模块化"></a>模块化</h3><p>终于，我们可以开始着手当前迁移项目（此处的项目表示一个单独的代码模块）的模块化改造了，这部分内容简要概括一下：</p><p><strong>模块描述</strong>  </p><p>我们只需要在项目根包（<code>/</code>）下创建一个名为<code>module-info.java</code>的模块描述文件即可将当前项目转换为模块，模块描述内容很简单，例如：</p><figure class="highlight java"><figcaption><span>module-info.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">module</span> me.example.test &#123;                  <span class="hljs-comment">// (1)</span><br>    <span class="hljs-keyword">requires</span> java.sql;                    <span class="hljs-comment">// (2)</span><br>    <span class="hljs-keyword">exports</span> me.example.api;               <span class="hljs-comment">// (3)</span><br>    opens me.example.entity;              <span class="hljs-comment">// (4)</span><br>    uses java.sql.Driver;                 <span class="hljs-comment">// (5)</span><br>    provides me.example.api.DemoService   <span class="hljs-comment">// (6)</span><br>            with me.example.api.impl.DemoServiceFactory;<br>&#125;<br></code></pre></td></tr></table></figure> <p>解释一下上面所用的描述符：  </p><ul><li>(1) 指定了当前模块的唯一命名<br>格式为 <code>[open] module &lt;Module Name&gt;</code>    </li><li>(2)<code>requires</code> 子句指定了模块显式依赖<br>只有指定为显式依赖，才可以在代码中直接使用依赖模块的导出内容，格式为<code>requires &lt;Module Name&gt;</code>    </li><li>(3)<code>exports</code> 子句指定模块导出的公共包<br>即对外公开的API，非导出部分都将被封装，格式为<code>exports &lt;Package Name&gt; [to &lt;Module Name&gt;]</code>    </li><li>(4)<code>opens</code> 子句指定模块的开放包<br>即允许深度反射的部分，格式为 <code>opens &lt;Package Name&gt; [to &lt;Module Name&gt;]</code>，例如：一般考虑到对ROM框架的支持会开放数据实体包    </li><li>(5)<code>uses</code> 子句表明了模块可以使用实现了指定接口的服务<br>例如上所描述的<code>java.sql.Driver</code>，该子句用于指定服务依赖关系（可选依赖）    </li><li>(5)<code>provides</code> 子句表明该模块可以对外提供实现了指定接口的服务<br>例如上所描述的提供实现了<code>me.example.api.DemoService</code>的服务</li></ul><p>在上面的示例中提到了一个新概念：服务依赖。<br>我们先考虑一个常见的场景：模块A对外导出了公共API <code>DemoService</code>，同时会有一个封装的默认实现<code>DefaultDemoServiceImpl</code>，但实现是被封装的，为此需要在公开部分添加一个能获取该默认实现的方法，例如使用一个工厂，很显然模块A的公共API多了一个用于获取默认实现的工厂API，且我们很难再对这个公共工厂做出修改，API不应与其实现紧密耦合。    </p><p>我们现在可以通过Java模块系统中的服务机制进行解耦。使用服务，可以真正地共享公共接口，并将实现代码强封装到未导出的包中。而是否使用模块系统中的服务是完全可选的，因此服务依赖也就成为可选依赖。  </p><p>早在模块系统出现之前，Java中就已经存在一个类似的设计———— <code>ServiceLoader</code>，也就是所谓的SPI（Service Provider Interface）。如下所示，我们使用模块系统中的服务获取<code>java.sql.Driver</code>实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.ServiceLoader;<br><span class="hljs-keyword">import</span> java.sql.Driver;<br><span class="hljs-comment">// ...</span><br>ServiceLoader&lt;Driver&gt; driverLoader = ServiceLoader.load(Driver.class);<br>Optional&lt;ServiceLoader.Provider&lt;Driver&gt;&gt; driverOptional = driverLoader.stream().findFirst();<br><span class="hljs-keyword">if</span> (driverOptional.isPresent()) &#123;<br>   <span class="hljs-type">Driver</span> <span class="hljs-variable">driver</span> <span class="hljs-operator">=</span> driverOptional.get();<br>   <span class="hljs-comment">// ...</span><br>&#125;<br><span class="hljs-comment">// ...</span><br></code></pre></td></tr></table></figure>   <p>由于我们在模块描述中已经表明了可选依赖<code>uses java.sql.Driver</code>，所以，一旦在模块路径发现有对应服务的提供者，就会创建于本模块的服务依赖，例如在模块路径中添加了<code>java.sql.Driver</code>服务的提供模块如Mysql、Oracle等（前提是这些模块在描述<code>provides</code>子句中声明了其对外提供服务），我们就可以通过<code>ServiceLoader</code>获取（延迟加载）这些实现，同时还能识别这些实现（通过检查<code>ServiceLoader.Provider</code>对象）。基于篇幅，这部分简单介绍就到此为止。</p><h3 id="自动模块"><a href="#自动模块" class="headerlink" title="自动模块"></a>自动模块</h3><p>由于我们的项目已经模块化，成为一个命名模块，此时项目就无法再访问类路径上的内容了（未命名模块）。为此需要将项目直接依赖的库从类路径移到模块路径。</p><p>尽管一些库本身并未模块化，其仍然可以作为模块在模块路径中使用，而这些库在模块路径上时会被转化为自动模块（Automatic Module）。截至目前，我们知道了Java模块系统提供了三种类型的模块：未命名模块、自动模块和命名模块。让我们区分一下这些模块类型的特点：</p><table><thead><tr><th>类型</th><th>生成规则</th><th>命名</th><th>依赖关系</th><th>公开导出</th><th>开放封装</th><th>拆分包</th><th>特殊</th></tr></thead><tbody><tr><td>未命名模块</td><td>在类路径上</td><td>ALL-UNNAMED</td><td>读取所有其他模块</td><td>所有包</td><td>所有包</td><td>允许</td><td>不允许被命名模块读取</td></tr><tr><td>自动模块</td><td>不包含<code>module-info.class</code>模块描述，且在模块路径上</td><td>META-INF&#x2F;MANIFEST.MF中指定或文件名转换</td><td>读取所有其他自动模块和未命名模块</td><td>所有包</td><td>所有包</td><td>不允许</td><td>依赖将被传递</td></tr><tr><td>命名模块</td><td>包含<code>module-info.class</code>模块描述，且在模块路径上</td><td>模块描述指定</td><td>模块描述指定（requires）</td><td>模块描述指定（exports）</td><td>模块描述指定（opens）</td><td>不允许</td><td>不允许读取未命名模块</td></tr></tbody></table><blockquote><p>拆分包：指不同模块或库拥有相同限定名的包，就好像一个包的内容被拆分到了不同的模块或库中。在Java引入模块系统前（Java9+）是允许拆分包存在的。</p></blockquote><p>自动模块的名称可以通过<code>META-INF/MANIFEST.MF</code>的<code>Automatic-Module-Name</code>节点属性指定，这是库作者对模块化最低程度的支持。而当未指定自动模块名称时，自动模块的名称则由库文件名决定：<br><em>使用点（.）替换文件名中的非字母数字字符（[^A-Za-z0-9]），剔除重复的点（.）</em>，例如：<code>jackson-databind-1.0.0.jar</code>将成为自动模块<code>jackson.databind</code>。</p><p>解析模块图是根据一组给定的根模块计算出来的，在自动模块的情况下，模块解析会产生混乱。当模块未指定自动模块显式依赖时，自动模块和其传递依赖（所有其他自动模块）就不会被解析，同时，使用<code>--add-modules</code>手动添加依赖项非常耗时。而当应用程序<code>requires</code>一个自动模块时，所有自动模块都会被自动解析，这样一来，就可能导致未使用的自动模块也被解析（占用不必要的资源），所以请保持模块路径尽可能“干净”，仅将和应用有直接显式依赖关系的自动模块放在模块路径上。</p><p>但在众多的库中，我们很难清楚其模块的引用关系，此时可以使用<code>jdeps</code>工具，在上面我们已经使用过该工具了。现在我们使用该工具进行库的依赖分析，对于如下应用：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs text">├── lib<br>│   ├── jackson-annotations-2.8.8.jar<br>│   ├── jackson-core-2.8.8.jar<br>│   └── jackson-databind-2.8.8.jar<br>└── out<br>    └── demo<br>        ├── Book.class<br>        └── Main.class<br></code></pre></td></tr></table></figure>   <p>使用命令分析类路径编译的应用： </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">jdeps -recursive -summary -<span class="hljs-built_in">cp</span> lib/*.jar out</span><br><br>jackson-annotations-2.8.8.jar -&gt; java.base<br>jackson-core-2.8.8.jar -&gt; java.base<br>jackson-databind-2.8.8.jar -&gt; lib/jackson-annotations-2.8.8.jar<br>jackson-databind-2.8.8.jar -&gt; lib/jackson-core-2.8.8.jar<br>jackson-databind-2.8.8.jar -&gt; java.base<br>jackson-databind-2.8.8.jar -&gt; java.desktop<br>jackson-databind-2.8.8.jar -&gt; java.logging<br>jackson-databind-2.8.8.jar -&gt; java.sql<br>jackson-databind-2.8.8.jar -&gt; java.xml<br>out -&gt; lib/jackson-databind-2.8.8.jar<br>out -&gt; java.base<br></code></pre></td></tr></table></figure>  <p>根据上面的输出已经可以得出结论，为了将代码迁移到模块，需要使<code>jackson-databind</code>成为自动模块。同时<code>jackson-databind</code>依赖于<code>jackson-core</code>和<code>jackson-annotations</code>，所以这些库可以停留在类路径或移动到模块路径。如果想知道为什么存在依赖关系，可以省略上述命令中的<code>-summary</code>参数打印更多的细节，以及准确显示哪些包需要哪些其他包，如果信息还不够详细，可以添加参数<code>-verbose:class</code>以打印类级别依赖关系。</p><p>未命名模块本身只能通过自动模块读取，迁移过程并非一蹴而就，往往会存在部分类路径和模块路径混合使用的情况。</p><h3 id="问题修复"><a href="#问题修复" class="headerlink" title="问题修复"></a>问题修复</h3><p><strong>反射加载</strong></p><p>迁移到模块时应该特别注意那些使用反射加载的代码。常见的例子比如加载JDBC驱动可能会使用如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> demo;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Main</span> &#123;<br><br>  <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String... args)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>    Class&lt;?&gt; clazz = Class.forName(<span class="hljs-string">&quot;org.hsqldb.jdbcDriver&quot;</span>);<br>    System.out.println(clazz.getName());<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>  <p>此时我们的模块还没有指定具体的显式依赖描述，运行代码时将会抛出一个异常：<code>java.lang.ClassNotFoundException: org.hsqldb.jdbcDriver</code>，因为<code>hsqldb</code>自动模块未被加载。当然我们可以在我们的模块描述中添加自动模块的显式依赖，但这样做很糟糕，我们不应该依赖具体的实现，为了使应用能正常启动，我们可以在启动命令中临时添加参数<code>--add-modules hsqldb</code>。</p><p>现在驱动可以加载了，但又会引起一个异常，由于我们加载的驱动依赖于<code>java.sql.Driver</code>（<code>java.sql</code>模块），而我们的模块描述中并未对其进行依赖声明，所以我们修改模块的描述，添加<code>requires java.sql;</code>子句。 此时如果删除启动命令中的<code>--add-modules hsqldb</code>参数，应用仍能正常启动，这是为什么？</p><p>我们显式依赖了模块<code>java.sql</code>，而该模块定义了<code>java.sql.Driver</code>服务接口，同时<code>uses</code>该服务，而<code>hsqldb</code>的库提供了一个这样的服务实现，它通过旧的SPI方式（META-INF&#x2F;services中使用文件注册服务）提供了服务实现，所以基于服务绑定，<code>hsqldb</code>的自动模块会从模块路径上被解析。</p><p><strong>拆分包</strong> </p><p>拆分包意味着两个模块包含相同的包，Java模块系统不允许拆分包。因此，从类路径到模块路径可能会遇到拆分包的问题。</p><p>拆分包始终是不正常的，而当使用解析可传递依赖项的构建工具（如Maven等）时，很容易出现同一个库的多个版本，当Java模块系统检测到一个包存在于模块路径上的多个模块中时，就会拒绝启动。如果在迁移时遇到了拆分包问题，无论如何都是无法绕过的。即使从用户角度来看基于类路径的应用程序可以正确工作，你也最终需要处理这些问题。</p><p><strong>Idea启动问题</strong> </p><p>截至文档发布，我使用的Idea版本为<code>2021.2.1</code>，其存在一些模块化资源打包的Bug，例如：</p><p>Idea将<code>resources</code>资源编译输出到<code>build/resources/main</code>目录下，而模块目录为<code>build/classes/java/main</code>，此时就会出现资源找不到的问题，可以通过添加<code>VM Options</code>的<code>--patch-module</code>参数选项，如：<code>--patch-module me.example.test=example/build/resources/main</code>将资源目录通过<code>patch</code>的方式追加到指定模块。</p><h2 id="模块化改造"><a href="#模块化改造" class="headerlink" title="模块化改造"></a>模块化改造</h2><p>虽然项目已经通过添加模块描述文件实现了模块化，但并不是一个优秀的模块，我们还需要对项目的包进行调整，仅导出我们认为需要导出的包，同时使用服务依赖进行对具体实现的解耦，如果有提供API的实现，则需要描述服务提供<code>provides</code>。</p><p>同时，相应的自动模块应该使用其模块化的版本替代。</p><p>而资源也是封装在模块中的，推荐的做法是使用服务提供实现各模块间资源共享。</p><blockquote><p>文献参考：《Java 9 Modularity》</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>modularity</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Feign客户端Fallback全局代理</title>
    <link href="/spring-cloud/feign-fallback-proxy/"/>
    <url>/spring-cloud/feign-fallback-proxy/</url>
    
    <content type="html"><![CDATA[<p>在网络请求时，可能会出现异常请求，如果还想再异常情况下使系统可用，那么就需要容错处理，使用FeignClient时可对fallback进行配置，但随着接口数不断增加，配置也越来越重复繁琐，且大多容错逻辑均一致，因此需要对容错配置进行代理，提供全局统一容错处理。</p><span id="more"></span><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>Spring Cloud Feign的Fallback实现有两种设置方式：</p><ul><li><code>@FeignClient</code>注解<code>fallback</code>属性指定一个实现Feign接口的fallback处理类</li><li><code>@FeignClient</code>注解<code>fallbackFactory</code>属性指定一个实现<code>FallbackFactory&lt;T&gt;</code>工厂接口类</li></ul><p>由于Fallback大多配合<em>Hystrix</em>实现， 所以需要开启Hystrix：</p><figure class="highlight properties"><figcaption><span>application.properties</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-attr">feign.hystrix.enabled</span>=<span class="hljs-string">true</span><br></code></pre></td></tr></table></figure><blockquote><p>当然，升级<code>open-feign</code>到4.x就不用这么麻烦了</p></blockquote><h2 id="实现Feign接口的fallback处理类"><a href="#实现Feign接口的fallback处理类" class="headerlink" title="实现Feign接口的fallback处理类"></a>实现Feign接口的fallback处理类</h2><p>例如下接口：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@FeignClient(name = &quot;user&quot;, fallback = UserFeignFallback.class)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">interface</span> <span class="hljs-title class_">UserFeign</span> &#123;<br><br>    <span class="hljs-meta">@PostMapping</span><br>    <span class="hljs-keyword">void</span> <span class="hljs-title function_">saveUser</span><span class="hljs-params">(User user)</span>;<br><br>    <span class="hljs-meta">@GetMapping(&quot;/&#123;id&#125;&quot;)</span><br>    User <span class="hljs-title function_">getUserByID</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable(&quot;id&quot;)</span> String id)</span>;<br><br>    <span class="hljs-meta">@GetMapping</span><br>    List&lt;User&gt; <span class="hljs-title function_">listAllUser</span><span class="hljs-params">()</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>所需实现Feign接口的fallback处理类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Component</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">UserFeignFallback</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">UserFeign</span> &#123;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">saveUser</span><span class="hljs-params">(User user)</span> &#123;<br>        <span class="hljs-comment">// do something when saveUser failed.</span><br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> User <span class="hljs-title function_">getUserByID</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable(&quot;id&quot;)</span> String id)</span> &#123;<br>        <span class="hljs-comment">// do something when queryUser failed.</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> List&lt;User&gt; <span class="hljs-title function_">listAllUser</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-comment">// do something when listUser failed.</span><br>        <span class="hljs-keyword">return</span> Collections.emptyList();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="实现FallbackFactory工厂接口类"><a href="#实现FallbackFactory工厂接口类" class="headerlink" title="实现FallbackFactory工厂接口类"></a>实现FallbackFactory工厂接口类</h2><p>例如下接口：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@FeignClient(name = &quot;user&quot;, fallbackFactory = UserFeignFallbackFactory.class)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">interface</span> <span class="hljs-title class_">UserFeign</span> &#123;<br><br>    <span class="hljs-meta">@PostMapping</span><br>    <span class="hljs-keyword">void</span> <span class="hljs-title function_">saveUser</span><span class="hljs-params">(User user)</span>;<br><br>    <span class="hljs-meta">@GetMapping(&quot;/&#123;id&#125;&quot;)</span><br>    User <span class="hljs-title function_">getUserByID</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable(&quot;id&quot;)</span> String id)</span>;<br><br>    <span class="hljs-meta">@GetMapping</span><br>    List&lt;User&gt; <span class="hljs-title function_">listAllUser</span><span class="hljs-params">()</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>所需实现实现FallbackFactory工厂接口类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Component</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">UserFeignFallbackFactory</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">FallbackFactory</span>&lt;UserFeign&gt; &#123;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> UserFeign <span class="hljs-title function_">create</span><span class="hljs-params">(Throwable cause)</span> &#123;<br>        <span class="hljs-comment">// log throwable error...</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">UserFeignFallback</span>();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>以上配置在有些时候显得多余且繁琐 </p></blockquote><h1 id="代理FeignContext"><a href="#代理FeignContext" class="headerlink" title="代理FeignContext"></a>代理FeignContext</h1><p>由于<em>FeignBean</em>从<em>FeignContext</em>（child contexts that allows a set of Specifications to define the beans）构建，所以写一个<code>BeanPostProcessor</code>拦截<code>FeignContext</code>:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> Object <span class="hljs-title function_">postProcessAfterInitialization</span><span class="hljs-params">(Object bean, String beanName)</span> <span class="hljs-keyword">throws</span> BeansException &#123;<br>    <span class="hljs-keyword">if</span> (bean <span class="hljs-keyword">instanceof</span> FeignContext &amp;&amp; !(bean <span class="hljs-keyword">instanceof</span> TargetFeignContextWrapper)) &#123;<br>        <span class="hljs-type">FeignContext</span> <span class="hljs-variable">context</span> <span class="hljs-operator">=</span> (FeignContext) bean;<br>        registerFeignClientFallback(context);<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">TargetFeignContextWrapper</span>(context, beanFactory);<br>    &#125;<br>    <span class="hljs-keyword">return</span> bean;<br>&#125;<br></code></pre></td></tr></table></figure><p>然后在获取FeignTarget时代理Feign客户端：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/** FeignContext wrapper */</span><br><span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">TargetFeignContextWrapper</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">FeignContext</span> &#123;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> FeignContext delegate;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> ConfigurableListableBeanFactory beanFactory;<br>    <span class="hljs-comment">/** HystrixTargeter */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> Class&lt;?&gt; ClassHystrixTargeter;<br>    <span class="hljs-comment">/** 默认Target */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> Class&lt;?&gt; ClassDefaultTargeter;<br><br>    <span class="hljs-keyword">static</span> &#123;<br>        <span class="hljs-keyword">try</span> &#123;<br>            <span class="hljs-comment">// package-access class load</span><br>            ClassHystrixTargeter =<br>                    TargetFeignContextWrapper.class.getClassLoader().loadClass(<span class="hljs-string">&quot;org.springframework.cloud.openfeign.HystrixTargeter&quot;</span>);<br>            ClassDefaultTargeter =<br>                    TargetFeignContextWrapper.class.getClassLoader().loadClass(<span class="hljs-string">&quot;org.springframework.cloud.openfeign.DefaultTargeter&quot;</span>);<br>        &#125; <span class="hljs-keyword">catch</span> (ClassNotFoundException e) &#123;<br>            log.warn(<span class="hljs-string">&quot;Unable to load HystrixTargeter.&quot;</span>, e);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">TargetFeignContextWrapper</span><span class="hljs-params">(FeignContext delegate, ConfigurableListableBeanFactory beanFactory)</span> &#123;<br>        <span class="hljs-built_in">this</span>.delegate = delegate;<br>        <span class="hljs-built_in">this</span>.beanFactory = beanFactory;<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> &lt;T&gt; T <span class="hljs-title function_">getInstance</span><span class="hljs-params">(String name, Class&lt;T&gt; type)</span> &#123;<br>        <span class="hljs-comment">// 目标对象</span><br>        <span class="hljs-type">T</span> <span class="hljs-variable">object</span> <span class="hljs-operator">=</span> <span class="hljs-built_in">this</span>.delegate.getInstance(name, type);<br>        <span class="hljs-comment">// 必要进行包装代理</span><br>        <span class="hljs-keyword">return</span> warpIfNecessary(object);<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> &lt;T&gt; Map&lt;String, T&gt; <span class="hljs-title function_">getInstances</span><span class="hljs-params">(String name, Class&lt;T&gt; type)</span> &#123;<br>        Map&lt;String, T&gt; instances = <span class="hljs-built_in">this</span>.delegate.getInstances(name, type);<br>        <span class="hljs-keyword">if</span> (instances == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>        &#125;<br>        <span class="hljs-comment">// 保持原始Bean顺序（链路追踪Sleuth代理的FeignContext返回HashMap，导致bean即使声明了ordered依旧无须，因此在使用该框架时注意）</span><br>        Map&lt;String, T&gt; convertedInstances = <span class="hljs-keyword">new</span> <span class="hljs-title class_">LinkedHashMap</span>&lt;&gt;();<br>        <span class="hljs-keyword">for</span> (Map.Entry&lt;String, T&gt; entry : instances.entrySet()) &#123;<br>            convertedInstances.put(entry.getKey(),<br>                    warpIfNecessary(entry.getValue()));<br>        &#125;<br>        <span class="hljs-comment">// 自定义排序</span><br>        <span class="hljs-keyword">return</span> sortByOrdered(convertedInstances);<br>    &#125;<br><br>    <span class="hljs-comment">/** 针对需要的Bean进行包装代理 */</span><br>    <span class="hljs-keyword">private</span> &lt;T&gt; T <span class="hljs-title function_">warpIfNecessary</span><span class="hljs-params">(T object)</span> &#123;<br>        <span class="hljs-keyword">if</span> (object != <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">if</span> ((ClassHystrixTargeter != <span class="hljs-literal">null</span> &amp;&amp; ClassHystrixTargeter.isAssignableFrom(object.getClass())) ||<br>                    (ClassDefaultTargeter != <span class="hljs-literal">null</span> &amp;&amp; ClassDefaultTargeter.isAssignableFrom(object.getClass()))) &#123;<br>                <span class="hljs-comment">// 如果是 Targeter， 进行AOP代理</span><br>                <span class="hljs-keyword">return</span> (T)enhancement(object);<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> object;<br>    &#125;<br><br>    <span class="hljs-comment">/** 对BeanMap进行排序 */</span><br>    <span class="hljs-keyword">private</span> &lt;T&gt; Map&lt;String, T&gt; <span class="hljs-title function_">sortByOrdered</span><span class="hljs-params">(Map&lt;String, T&gt; beans)</span> &#123;<br>        <span class="hljs-keyword">if</span> (beans != <span class="hljs-literal">null</span> &amp;&amp; !beans.isEmpty()) &#123;<br>            List&lt;Map.Entry&lt;String, T&gt;&gt; sortList = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;(beans.entrySet());<br>            <span class="hljs-comment">//noinspection rawtypes</span><br>            sortList.sort(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Comparator</span>&lt;Map.Entry&lt;String, T&gt;&gt;() &#123;<br>                <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">Comparator</span> <span class="hljs-variable">orderComparator</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">OrderComparator</span>();<br><br>                <span class="hljs-meta">@SuppressWarnings(&quot;unchecked&quot;)</span><br>                <span class="hljs-meta">@Override</span><br>                <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">compare</span><span class="hljs-params">(Map.Entry&lt;String, T&gt; o1, Map.Entry&lt;String, T&gt; o2)</span> &#123;<br>                    <span class="hljs-type">Object</span> <span class="hljs-variable">bean1</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;<br>                    <span class="hljs-type">Object</span> <span class="hljs-variable">bean2</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;<br>                    <span class="hljs-keyword">if</span> (o1 != <span class="hljs-literal">null</span>) &#123;<br>                        bean1 = o1.getValue();<br>                    &#125;<br>                    <span class="hljs-keyword">if</span> (o2 != <span class="hljs-literal">null</span>) &#123;<br>                        bean2 = o2.getValue();<br>                    &#125;<br>                    <span class="hljs-keyword">return</span> orderComparator.compare(bean1, bean2);<br>                &#125;<br>            &#125;);<br>            Map&lt;String, T&gt; result = <span class="hljs-keyword">new</span> <span class="hljs-title class_">LinkedHashMap</span>&lt;&gt;();<br>            sortList.forEach(entry -&gt; result.put(entry.getKey(), entry.getValue()));<br>            <span class="hljs-keyword">return</span> result;<br>        &#125;<br>        <span class="hljs-keyword">return</span> beans;<br>    &#125;<br><br>    <span class="hljs-comment">/** 对 HystrixTargeter 执行增强代理 */</span><br>    <span class="hljs-keyword">private</span> Object <span class="hljs-title function_">enhancement</span><span class="hljs-params">(Object target)</span> &#123;<br>        <span class="hljs-type">Object</span> <span class="hljs-variable">proxy</span> <span class="hljs-operator">=</span> enhancementCache.get(target);<br>        <span class="hljs-keyword">if</span> (proxy == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">synchronized</span> (<span class="hljs-built_in">this</span>) &#123;<br>                proxy = enhancementCache.get(target);<br>                <span class="hljs-keyword">if</span> (proxy == <span class="hljs-literal">null</span>) &#123;<br>                    Map&lt;String, FeignHystrixContextRegister&gt; feignHystrixContextRegisterBeans =<br>                            beanFactory.getBeansOfType(FeignHystrixContextRegister.class);<br>                    <span class="hljs-type">Enhancer</span> <span class="hljs-variable">enhancer</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Enhancer</span>();<br>                    <span class="hljs-comment">// 增强HystrixTargeter</span><br>                    enhancer.setSuperclass(target.getClass());<br>                    enhancer.setCallback((MethodInterceptor) (contextThis, method, args, methodProxy) -&gt; &#123;<br>                        <span class="hljs-keyword">if</span> (method.getName().equals(<span class="hljs-string">&quot;target&quot;</span>)) &#123;<br>                            <span class="hljs-comment">// args = FeignClientFactoryBean factory, Feign.Builder feign, FeignContext context, Target.HardCodedTarget&lt;T&gt; target</span><br>                            Feign.<span class="hljs-type">Builder</span> <span class="hljs-variable">feign</span> <span class="hljs-operator">=</span> (Feign.Builder) args[<span class="hljs-number">1</span>];<br>                            <span class="hljs-keyword">if</span> (feign != <span class="hljs-literal">null</span>) &#123;<br>                                <span class="hljs-comment">// 可选，对Feign请求拦截器进行排序（有需求的可以使用反射进行操作）</span><br>                                HystrixFeignHelper.sortRequestInterceptors(feign);<br>                            &#125;<br>                            <span class="hljs-keyword">if</span> (feign <span class="hljs-keyword">instanceof</span> HystrixFeign.Builder) &#123;<br>                                <span class="hljs-comment">// 代理方法执行</span><br>                                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">HystrixFeignHelper</span>((HystrixFeign.Builder)feign, feignHystrixContextRegisterBeans.values())<br>                                        .target(args[<span class="hljs-number">0</span>],<br>                                                (HystrixFeign.Builder)args[<span class="hljs-number">1</span>],<br>                                                (FeignContext)args[<span class="hljs-number">2</span>],<br>                                                (Target.HardCodedTarget)args[<span class="hljs-number">3</span>]);<br>                            &#125;<br>                        &#125;<br>                        <span class="hljs-keyword">return</span> methodProxy.invoke(target, args);<br>                    &#125;);<br>                    proxy = enhancer.create();<br>                    enhancementCache.put(target, proxy);<br>                &#125;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> proxy;<br>    &#125;<br><br>    <span class="hljs-comment">// AOP缓存</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> Map&lt;Object, Object&gt; enhancementCache = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ConcurrentHashMap</span>&lt;&gt;();<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="代理Feign-Builder"><a href="#代理Feign-Builder" class="headerlink" title="代理Feign.Builder"></a>代理Feign.Builder</h1><p>现在，我们已经拦截了Feign的获取，并返回我们代理的对象，而代理对象如何生成，代理逻辑如何构建，将是本小节讨论的重点。</p><h2 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h2><p>我们代理<code>HystrixFeign.Builder</code>核心是其<code>build</code>方法，返回Feign客户端，发起来自<code>target</code>方法：整个流程基本保持默认，即获取配置，调用<code>HystrixFeign.Builder</code>的<code>build</code>方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> &lt;T&gt; T <span class="hljs-title function_">target</span><span class="hljs-params">(Object factory, Feign.Builder feign,</span><br><span class="hljs-params">                    FeignContext context, Target.HardCodedTarget&lt;T&gt; target)</span> <span class="hljs-keyword">throws</span> Throwable &#123;<br>    <span class="hljs-keyword">if</span> (!(feign <span class="hljs-keyword">instanceof</span> feign.hystrix.HystrixFeign.Builder)) &#123;<br>        <span class="hljs-comment">// 我们只处理HystrixFeign</span><br>        <span class="hljs-keyword">return</span> feign.target(target);<br>    &#125;<br>    feign.hystrix.HystrixFeign.<span class="hljs-type">Builder</span> <span class="hljs-variable">builder</span> <span class="hljs-operator">=</span> (feign.hystrix.HystrixFeign.Builder) feign;<br>    <span class="hljs-comment">// 指定contextId</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">contextId</span> <span class="hljs-operator">=</span> Fields.getFieldValue(factory, <span class="hljs-string">&quot;contextId&quot;</span>, String.class);<br>    <span class="hljs-comment">// 服务名称</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">name</span> <span class="hljs-operator">=</span> Fields.getFieldValue(factory, <span class="hljs-string">&quot;name&quot;</span>, String.class);<br>    <span class="hljs-comment">// 失败处理</span><br>    Class&lt;?&gt; fallback = Fields.getFieldValue(factory, <span class="hljs-string">&quot;fallback&quot;</span>, Class.class);<br>    <span class="hljs-comment">// 失败工厂</span><br>    Class&lt;?&gt; fallbackFactory = Fields.getFieldValue(factory, <span class="hljs-string">&quot;fallbackFactory&quot;</span>, Class.class);<br>    <span class="hljs-type">String</span> <span class="hljs-variable">clientName</span> <span class="hljs-operator">=</span> StringUtils.isEmpty(contextId) ? name : contextId;<br>    <span class="hljs-type">SetterFactory</span> <span class="hljs-variable">setterFactory</span> <span class="hljs-operator">=</span> context.getInstance(name, SetterFactory.class);<br>    <span class="hljs-keyword">if</span> (setterFactory != <span class="hljs-literal">null</span>) &#123;<br>        builder.setterFactory(setterFactory);<br>    &#125;<br>    <span class="hljs-keyword">if</span> (fallback != <span class="hljs-keyword">void</span>.class) &#123;<br>        <span class="hljs-type">T</span> <span class="hljs-variable">fallbackInstance</span> <span class="hljs-operator">=</span> getFromContext(<span class="hljs-string">&quot;fallback&quot;</span>, clientName, context,<br>                fallback, target.type());<br>        <span class="hljs-keyword">return</span> build(target, fallbackInstance);<br>    &#125;<br>    <span class="hljs-keyword">if</span> (fallbackFactory != <span class="hljs-keyword">void</span>.class) &#123;<br>        FallbackFactory&lt;? <span class="hljs-keyword">extends</span> <span class="hljs-title class_">T</span>&gt; fallbackFactoryInstance = (FallbackFactory&lt;? <span class="hljs-keyword">extends</span> <span class="hljs-title class_">T</span>&gt;) getFromContext(<br>                <span class="hljs-string">&quot;fallbackFactory&quot;</span>, clientName, context, fallbackFactory,<br>                FallbackFactory.class);<br>        <span class="hljs-keyword">return</span> build(target, fallbackFactoryInstance);<br>    &#125;<br>    <span class="hljs-comment">// fallback未指定，保持默认</span><br>    <span class="hljs-keyword">return</span> feign.target(target);<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Build"><a href="#Build" class="headerlink" title="Build"></a>Build</h2><p>由于我们代理了<code>HystrixFeign.Builder</code>，而Feign客户端的构建需要调用<code>Feign.Builder</code>的<code>build</code>方法（当然如果嫌麻烦可以使用反射实现<code>build</code>方法原流程），我们代理的<code>HystrixFeign.Builder</code>对象所见的access只能访问未指定<code>fallback</code>的<code>build</code>方法，因此需要构建一个<code>hystrix build</code>方法流程，为此我们使用<code>MethodHandle</code>获取<code>super</code>父级方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/** HystrixFeign操作（兼容其他框架对HystrixFeign的定制化） */</span><br><span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">HystrixFeignHelper</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">Feign</span>.Builder&#123;<br>    <span class="hljs-comment">/** 被代理的Builder */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> HystrixFeign.Builder delegate;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> Collection&lt;FeignHystrixContextRegister&gt; contextRegisters;<br>    <span class="hljs-comment">/** 父类的invocationHandlerFactory方法 */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> MethodHandle invocationHandlerFactoryMethod;<br>    <span class="hljs-comment">/** 父类的contract方法 */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> MethodHandle contractMethod;<br>    <span class="hljs-comment">/** 父类的build方法 */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> MethodHandle buildMethod;<br>    <span class="hljs-comment">/** 初始化反射 */</span><br>    <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">init</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">try</span> &#123;<br>            <span class="hljs-type">Field</span> <span class="hljs-variable">impl_lookup</span> <span class="hljs-operator">=</span> ReflectionUtils.findField(MethodHandles.Lookup.class, <span class="hljs-string">&quot;IMPL_LOOKUP&quot;</span>);<br>            Objects.requireNonNull(impl_lookup).setAccessible(<span class="hljs-literal">true</span>);<br>            <span class="hljs-comment">// 查找super方法</span><br>            MethodHandles.<span class="hljs-type">Lookup</span> <span class="hljs-variable">lookup</span> <span class="hljs-operator">=</span> (MethodHandles.Lookup) impl_lookup.get(<span class="hljs-literal">null</span>);<br>            <span class="hljs-comment">// 以下均为super方法</span><br>            invocationHandlerFactoryMethod = lookup.findSpecial(Feign.Builder.class,<br>                    <span class="hljs-string">&quot;invocationHandlerFactory&quot;</span>,<br>                    MethodType.methodType(Feign.Builder.class, InvocationHandlerFactory.class),<br>                    Feign.Builder.class);<br>            contractMethod = lookup.findSpecial(Feign.Builder.class,<br>                    <span class="hljs-string">&quot;contract&quot;</span>,<br>                    MethodType.methodType(Feign.Builder.class, Contract.class),<br>                    Feign.Builder.class);<br>            buildMethod = lookup.findSpecial(Feign.Builder.class,<br>                    <span class="hljs-string">&quot;build&quot;</span>,<br>                    MethodType.methodType(Feign.class),<br>                    Feign.Builder.class);<br>        &#125; <span class="hljs-keyword">catch</span> (NoSuchMethodException | IllegalAccessException e) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">IllegalStateException</span>(e);<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">HystrixFeignHelper</span><span class="hljs-params">(HystrixFeign.Builder delegate, Collection&lt;FeignHystrixContextRegister&gt; contextRegisters)</span> &#123;<br>        <span class="hljs-built_in">this</span>.delegate = delegate;<br>        <span class="hljs-built_in">this</span>.contextRegisters = contextRegisters;<br>    &#125;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 代理的HystrixFeign.Builder target构建</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> target    target</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> fallback  fallback实例</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> &lt;T&gt;   类型</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span>  feign实例</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@throws</span> Throwable    异常</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> &lt;T&gt; T <span class="hljs-title function_">build</span><span class="hljs-params">(Target&lt;T&gt; target, T fallback)</span> <span class="hljs-keyword">throws</span> Throwable &#123;<br>        <span class="hljs-keyword">return</span> build(fallback != <span class="hljs-literal">null</span> ? <span class="hljs-keyword">new</span> <span class="hljs-title class_">FallbackFactory</span>.Default&lt;T&gt;(fallback) : <span class="hljs-literal">null</span>)<br>                .newInstance(target);<br>    &#125;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 代理的HystrixFeign.Builder target构建</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> target    target</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> fallbackFactory  fallback工厂</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> &lt;T&gt;   类型</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span>  feign实例</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@throws</span> Throwable    异常</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> &lt;T&gt; T <span class="hljs-title function_">build</span><span class="hljs-params">(Target&lt;T&gt; target, FallbackFactory&lt;? extends T&gt; fallbackFactory)</span> <span class="hljs-keyword">throws</span> Throwable &#123;<br>        <span class="hljs-keyword">return</span> build(fallbackFactory).newInstance(target);<br>    &#125;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 代理的HystrixFeign.Builder target构建</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> nullableFallbackFactory   统一的fallback工厂</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span>  feign实例</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@throws</span> Throwable    异常</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> Feign <span class="hljs-title function_">build</span><span class="hljs-params">(<span class="hljs-keyword">final</span> FallbackFactory&lt;?&gt; nullableFallbackFactory)</span> <span class="hljs-keyword">throws</span> Throwable &#123;<br>        <span class="hljs-type">SetterFactory</span> <span class="hljs-variable">setterFactory</span> <span class="hljs-operator">=</span> Fields.getFieldValue(delegate, <span class="hljs-string">&quot;setterFactory&quot;</span>, SetterFactory.class);<br>        <span class="hljs-type">Contract</span> <span class="hljs-variable">contract</span> <span class="hljs-operator">=</span> Fields.getFieldValue(delegate, <span class="hljs-string">&quot;contract&quot;</span>, Contract.class);<br>        invocationHandlerFactoryMethod.bindTo(delegate).invoke(<span class="hljs-keyword">new</span> <span class="hljs-title class_">InvocationHandlerFactory</span>() &#123;<br>            <span class="hljs-meta">@Override</span><br>            <span class="hljs-keyword">public</span> InvocationHandler <span class="hljs-title function_">create</span><span class="hljs-params">(Target target,</span><br><span class="hljs-params">                                            Map&lt;Method, MethodHandler&gt; dispatch)</span> &#123;<br>                <span class="hljs-comment">// 使用自定义的InvocationHandler以传递上下文，仿照 feign.hystrix.HystrixInvocationHandler 即可</span><br>                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">MyHystrixInvocationHandler</span>(target,<br>                        dispatch, setterFactory,<br>                        nullableFallbackFactory,<br>                        contextRegisters);<br>            &#125;<br>        &#125;);<br>        contractMethod.bindTo(delegate).invoke(<span class="hljs-keyword">new</span> <span class="hljs-title class_">HystrixDelegatingContract</span>(contract));<br>        <span class="hljs-keyword">return</span> (Feign) buildMethod.bindTo(delegate).invoke();<br>    &#125;<br>&#125;<br><span class="hljs-comment">/** Feign客户端fallback代理注册信息 */</span><br><span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">FeignClientRegisterInfo</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> String name;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> String contextId;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> Class&lt;?&gt; type;<br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">FeignClientRegisterInfo</span><span class="hljs-params">(String name, String contextId, Class&lt;?&gt; type)</span> &#123;<br>        <span class="hljs-built_in">this</span>.name = name;<br>        <span class="hljs-built_in">this</span>.contextId = contextId;<br>        <span class="hljs-built_in">this</span>.type = type;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="配置覆写"><a href="#配置覆写" class="headerlink" title="配置覆写"></a>配置覆写</h1><p>Feign客户端的配置信息均来自 <code>FeignClientFactoryBean</code>，因此使用一个<code>BeanFactoryPostProcessor</code>来拦截处理配置部分：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">postProcessBeanFactory</span><span class="hljs-params">(ConfigurableListableBeanFactory beanFactory)</span> <span class="hljs-keyword">throws</span> BeansException &#123;<br>    Collection&lt;?&gt; beans = queryFeignClientFactoryBeans(beanFactory);<br>    <span class="hljs-keyword">if</span> (!CollectionUtils.isEmpty(beans)) &#123;<br>        Objects.requireNonNull(beans).forEach(<span class="hljs-built_in">this</span>::processFeignClientFactoryBean);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        log.warn(<span class="hljs-string">&quot;No FeignClientFactoryBeans found.&quot;</span>);<br>    &#125;<br>&#125;<br><span class="hljs-comment">/** 在beanFactory中查找所有FeignClient的FactoryBean实例 */</span><br><span class="hljs-keyword">private</span> Collection&lt;?&gt; queryFeignClientFactoryBeans(ConfigurableListableBeanFactory beanFactory) &#123;<br>    Map&lt;String, ?&gt; beansOfType = <span class="hljs-literal">null</span>;<br>    <span class="hljs-keyword">try</span> &#123;<br>        <span class="hljs-type">ClassLoader</span> <span class="hljs-variable">loader</span> <span class="hljs-operator">=</span> Optional.ofNullable(beanFactory.getBeanClassLoader()).orElse(HystrixFeignClientFallbackProcess.class.getClassLoader());<br>        <span class="hljs-comment">// FeignClientFactoryBean 是 package-access 级别的类</span><br>        Class&lt;?&gt; feignClientFactoryBeanClass = loader.loadClass(<span class="hljs-string">&quot;org.springframework.cloud.openfeign.FeignClientFactoryBean&quot;</span>);<br>        beansOfType = beanFactory.getBeansOfType(feignClientFactoryBeanClass);<br>    &#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>        log.error(<span class="hljs-string">&quot;Error fetch all feign client factory beans.&quot;</span>, e);<br>    &#125;<br>    <span class="hljs-keyword">if</span> (beansOfType != <span class="hljs-literal">null</span>) &#123;<br>        <span class="hljs-keyword">return</span> beansOfType.values();<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>&#125;<br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 注册失败工厂bean</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@param</span> context feign的应用上下文</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">registerFeignClientFallback</span><span class="hljs-params">(FeignContext context)</span> &#123;<br>    <span class="hljs-comment">// 我们定义一个全局fallback处理</span><br>    <span class="hljs-type">FeignFallbackInvocation</span> <span class="hljs-variable">fallbackInvocation</span> <span class="hljs-operator">=</span> beanFactory.getBean(FeignFallbackInvocation.class);<br>    <span class="hljs-comment">// 获取FeignContext的具名context方法</span><br>    <span class="hljs-type">Method</span> <span class="hljs-variable">getContext</span> <span class="hljs-operator">=</span> ReflectionUtils.findMethod(FeignContext.class, <span class="hljs-string">&quot;getContext&quot;</span>, String.class);<br>    Objects.requireNonNull(getContext).setAccessible(<span class="hljs-literal">true</span>);<br>    <span class="hljs-keyword">for</span> (FeignClientRegisterInfo info : feignClientRegisterInfos) &#123;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">contextId</span> <span class="hljs-operator">=</span> info.contextId;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">name</span> <span class="hljs-operator">=</span> info.name;<br>        Class&lt;?&gt; type = info.type;<br>        <span class="hljs-comment">// 上下文名称</span><br>        <span class="hljs-type">String</span> <span class="hljs-variable">feignClientName</span> <span class="hljs-operator">=</span> StringUtils.isEmpty(contextId) ? name : contextId;<br>        <span class="hljs-keyword">try</span> &#123;<br>            <span class="hljs-comment">// 获取当前feignClient的具名context</span><br>            <span class="hljs-type">AnnotationConfigApplicationContext</span> <span class="hljs-variable">applicationContext</span> <span class="hljs-operator">=</span> (AnnotationConfigApplicationContext)<br>                    getContext.invoke(context, feignClientName);<br>            <span class="hljs-comment">// 将失败工厂注册于此</span><br>            applicationContext.registerBean(feignClientName + <span class="hljs-string">&quot;FallbackFactory&quot;</span>,<br>                    CommonFeignClientFallbackFactory.class,<br>                    () -&gt; <span class="hljs-keyword">new</span> <span class="hljs-title class_">CommonFeignClientFallbackFactory</span>&lt;&gt;(type, fallbackInvocation));<br>        &#125; <span class="hljs-keyword">catch</span> (ReflectiveOperationException e) &#123;<br>            log.error(<span class="hljs-string">&quot;Error register feign client fallback factory of [&quot;</span> + feignClientName + <span class="hljs-string">&quot;]&quot;</span>, e);<br>        &#125;<br>    &#125;<br>&#125;<br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 处理FeignClientFactoryBean，设置自动失败工厂</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@param</span> bean  FeignClientFactoryBean</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">processFeignClientFactoryBean</span><span class="hljs-params">(Object bean)</span> &#123;<br>    <span class="hljs-keyword">try</span> &#123;<br>        <span class="hljs-comment">// feign客户端目标接口</span><br>        Class&lt;?&gt; type = Fields.getFieldValue(bean, <span class="hljs-string">&quot;type&quot;</span>, Class.class);<br>        <span class="hljs-comment">// 服务名称</span><br>        <span class="hljs-type">String</span> <span class="hljs-variable">name</span> <span class="hljs-operator">=</span> Fields.getFieldValue(bean, <span class="hljs-string">&quot;name&quot;</span>, String.class);<br>        <span class="hljs-comment">// 指定contextId</span><br>        <span class="hljs-type">String</span> <span class="hljs-variable">contextId</span> <span class="hljs-operator">=</span> Fields.getFieldValue(bean, <span class="hljs-string">&quot;contextId&quot;</span>, String.class);<br>        <span class="hljs-comment">// 失败处理</span><br>        Class&lt;?&gt; fallback = Fields.getFieldValue(bean, <span class="hljs-string">&quot;fallback&quot;</span>, Class.class);<br>        <span class="hljs-comment">// 失败工厂</span><br>        Class&lt;?&gt; fallbackFactory = Fields.getFieldValue(bean, <span class="hljs-string">&quot;fallbackFactory&quot;</span>, Class.class);<br>        <span class="hljs-keyword">if</span> (fallback != <span class="hljs-keyword">void</span>.class || fallbackFactory != <span class="hljs-keyword">void</span>.class) &#123;<br>            <span class="hljs-comment">// 用户定义了失败处理，则不进行代理</span><br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-comment">// 使用统一的失败工厂</span><br>        Fields.setFieldValue(bean, <span class="hljs-string">&quot;fallbackFactory&quot;</span>, CommonFeignClientFallbackFactory.class);<br>        feignClientRegisterInfos.add(<span class="hljs-keyword">new</span> <span class="hljs-title class_">FeignClientRegisterInfo</span>(name, contextId, type));<br>    &#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>        log.error(<span class="hljs-string">&quot;Process FeignClientFactoryBean error: &quot;</span> + bean, e);<br>    &#125;<br>&#125;<br><span class="hljs-comment">/** 需要注册失败工厂的feign客户端信息 */</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> Collection&lt;FeignClientRegisterInfo&gt; feignClientRegisterInfos = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br><br><span class="hljs-comment">/** 统一的失败工厂（使用代理） */</span><br><span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">CommonFeignClientFallbackFactory</span>&lt;T&gt; <span class="hljs-keyword">implements</span> <span class="hljs-title class_">FallbackFactory</span>&lt;T&gt; &#123;<br>    <span class="hljs-comment">// 目标接口</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> Class&lt;T&gt; target;<br>    <span class="hljs-comment">// 失败处理</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> FeignFallbackInvocation fallbackInvocation;<br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">CommonFeignClientFallbackFactory</span><span class="hljs-params">(Class&lt;T&gt; target, FeignFallbackInvocation fallbackInvocation)</span> &#123;<br>        <span class="hljs-built_in">this</span>.target = target;<br>        <span class="hljs-built_in">this</span>.fallbackInvocation = fallbackInvocation;<br>    &#125;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-meta">@SuppressWarnings(&quot;unchecked&quot;)</span><br>    <span class="hljs-keyword">public</span> T <span class="hljs-title function_">create</span><span class="hljs-params">(Throwable cause)</span> &#123;<br>        <span class="hljs-keyword">return</span> (T) Proxy.newProxyInstance(target.getClassLoader(), <span class="hljs-keyword">new</span> <span class="hljs-title class_">Class</span>&lt;?&gt;[]&#123;target&#125;, (proxy, method, args) -&gt; &#123;<br>            <span class="hljs-type">String</span> <span class="hljs-variable">name</span> <span class="hljs-operator">=</span> method.getName();<br>            <span class="hljs-keyword">switch</span> (name) &#123;<br>                <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;equals&quot;</span>:<br>                    <span class="hljs-keyword">return</span> CommonFeignClientFallbackFactory.<span class="hljs-built_in">this</span>.equals(args[<span class="hljs-number">0</span>]);<br>                <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;hashCode&quot;</span>:<br>                    <span class="hljs-keyword">return</span> CommonFeignClientFallbackFactory.<span class="hljs-built_in">this</span>.hashCode();<br>                <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;toString&quot;</span>:<br>                    <span class="hljs-keyword">return</span> CommonFeignClientFallbackFactory.<span class="hljs-built_in">this</span>.toString();<br>            &#125;<br>            <span class="hljs-keyword">return</span> fallbackInvocation.fallback(target, method, args, cause);<br>        &#125;);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>然后只需要实现我们定义的全局fallback即可：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Component</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">DefaultFeignFallbackInvocation</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">FeignFallbackInvocation</span> &#123;<br><br>    <span class="hljs-comment">/** log recorder */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">Logger</span> <span class="hljs-variable">log</span> <span class="hljs-operator">=</span> LoggerFactory.getLogger(DefaultFeignFallbackInvocation.class);<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> ObjectMapper objectMapper;<br>    <span class="hljs-keyword">static</span> &#123;<br>        objectMapper = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ObjectMapper</span>();<br>        <span class="hljs-comment">// 反序列化时忽略json字符串中不存在的属性</span><br>        objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, <span class="hljs-literal">false</span>);<br>        <span class="hljs-comment">// 允许转义字符</span><br>        objectMapper.enable(JsonReadFeature.ALLOW_UNESCAPED_CONTROL_CHARS.mappedFeature());<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> Object <span class="hljs-title function_">fallback</span><span class="hljs-params">(Class&lt;?&gt; targetInterface, Method remoteMethod, Object[] args, Throwable exception)</span> &#123;<br>        log.error(<span class="hljs-string">&quot;Error Feign execute [&quot;</span> + remoteMethod.getName() + <span class="hljs-string">&quot;] with arguments: &quot;</span> + Arrays.toString(args) + <span class="hljs-string">&quot; at &quot;</span> + targetInterface.getName() + <span class="hljs-string">&quot; cause: &quot;</span> + exception.getMessage(), exception);<br>        <span class="hljs-keyword">if</span> (RetResult.class.isAssignableFrom(remoteMethod.getReturnType())) &#123;<br>            <span class="hljs-keyword">try</span> &#123;<br>                <span class="hljs-keyword">if</span> (exception <span class="hljs-keyword">instanceof</span> FeignException) &#123;<br>                    <span class="hljs-comment">// 客户端异常，尝试返回原始信息</span><br>                    <span class="hljs-type">String</span> <span class="hljs-variable">bodyString</span> <span class="hljs-operator">=</span> ((FeignException) exception).contentUTF8();<br>                    <span class="hljs-keyword">if</span> (!StringUtils.isEmpty(bodyString)) &#123;<br>                        RetResult&lt;?&gt; result = objectMapper.readValue(bodyString, RetResult.class);<br>                        <span class="hljs-keyword">if</span> (result != <span class="hljs-literal">null</span>) &#123;<br>                            <span class="hljs-keyword">return</span> result;<br>                        &#125;<br>                    &#125;<br>                &#125;<br>            &#125; <span class="hljs-keyword">catch</span> (Exception ignored) &#123;&#125;<br>            <span class="hljs-keyword">return</span> RetResultBuilder.fail(RetCodes.RET_REQ_SERVER_ERROR);<br>        &#125;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">BusinessRuntimeException</span>();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>还可以实现自己的<code>InvocationHandler</code>，编写特定的请求处理逻辑。</p><p>最后，将其做成配置类，通过注解导入，需要使用时在任意配置类打上该注解开启全局fallback代理：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Retention(RetentionPolicy.RUNTIME)</span><br><span class="hljs-meta">@Target(ElementType.TYPE)</span><br><span class="hljs-meta">@Documented</span><br><span class="hljs-meta">@Import(HystrixFeignClientFallbackProcess.class)</span><br><span class="hljs-keyword">public</span> <span class="hljs-meta">@interface</span> EnableFeignClientFallbackProxy &#123;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="4-x版本实现调整"><a href="#4-x版本实现调整" class="headerlink" title="4.x版本实现调整"></a>4.x版本实现调整</h1><blockquote><p>简化很多，只需<code>import</code>该配置即可生效</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">OpenFeignClientsFallbackProcess</span> <span class="hljs-keyword">implements</span><br>        <span class="hljs-title class_">BeanFactoryPostProcessor</span>,<br>        BeanPostProcessor,<br>        PriorityOrdered &#123;<br><br>    <span class="hljs-comment">/** log recorder */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">Logger</span> <span class="hljs-variable">log</span> <span class="hljs-operator">=</span> LoggerFactory.getLogger(OpenFeignClientsFallbackProcess.class);<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">FEIGN_CLIENT_FACTORY_ATTR</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;feignClientsRegistrarFactoryBean&quot;</span>;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> List&lt;FeignClientFallbackPenning&gt; fallbackPenning = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br><br>    <span class="hljs-keyword">private</span> BeanFactory beanFactory;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">postProcessBeanFactory</span><span class="hljs-params">(ConfigurableListableBeanFactory beanFactory)</span> <span class="hljs-keyword">throws</span> BeansException &#123;<br>        <span class="hljs-built_in">this</span>.beanFactory = beanFactory;<br>        <span class="hljs-keyword">for</span> (String name : beanFactory.getBeanDefinitionNames()) &#123;<br>            <span class="hljs-type">BeanDefinition</span> <span class="hljs-variable">definition</span> <span class="hljs-operator">=</span> beanFactory.getMergedBeanDefinition(name);<br>            <span class="hljs-keyword">if</span> (Objects.equals(definition.getBeanClassName(), FeignClientFactoryBean.class.getName())) &#123;<br>                processEagerlyFeignClient(definition);<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (definition.hasAttribute(FEIGN_CLIENT_FACTORY_ATTR)) &#123;<br>                processLazilyFeignClient(definition);<br>            &#125;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> Object <span class="hljs-title function_">postProcessAfterInitialization</span><span class="hljs-params">(Object bean, String beanName)</span> <span class="hljs-keyword">throws</span> BeansException &#123;<br>        <span class="hljs-keyword">if</span> (bean <span class="hljs-keyword">instanceof</span> FeignClientFactory context) &#123;<br>            registerFallbackFactory(context);<br>        &#125;<br>        <span class="hljs-keyword">return</span> bean;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">processEagerlyFeignClient</span><span class="hljs-params">(BeanDefinition definition)</span> &#123;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">className</span> <span class="hljs-operator">=</span> (String) definition.getAttribute(FactoryBean.OBJECT_TYPE_ATTRIBUTE);<br>        <span class="hljs-type">MutablePropertyValues</span> <span class="hljs-variable">properties</span> <span class="hljs-operator">=</span> definition.getPropertyValues();<br>        <span class="hljs-type">Object</span> <span class="hljs-variable">fallback</span> <span class="hljs-operator">=</span> properties.get(<span class="hljs-string">&quot;fallback&quot;</span>);<br>        <span class="hljs-type">Object</span> <span class="hljs-variable">fallbackFactory</span> <span class="hljs-operator">=</span> properties.get(<span class="hljs-string">&quot;fallbackFactory&quot;</span>);<br>        <span class="hljs-keyword">if</span> (noCustomizedFallback(fallback, fallbackFactory) &amp;&amp; className != <span class="hljs-literal">null</span>) &#123;<br>            Class&lt;?&gt; type = ClassUtils.resolveClassName(className, <span class="hljs-literal">null</span>);<br>            fallbackPenning.add(<span class="hljs-keyword">new</span> <span class="hljs-title class_">FeignClientFallbackPenning</span>((String)properties.get(<span class="hljs-string">&quot;name&quot;</span>),<br>                    (String)properties.get(<span class="hljs-string">&quot;contextId&quot;</span>),<br>                    type));<br>            properties.add(<span class="hljs-string">&quot;fallbackFactory&quot;</span>, ProxiedFeignClientFallbackFactory.class);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">processLazilyFeignClient</span><span class="hljs-params">(BeanDefinition definition)</span> &#123;<br>        <span class="hljs-type">FeignClientFactoryBean</span> <span class="hljs-variable">factoryBean</span> <span class="hljs-operator">=</span> (FeignClientFactoryBean) definition<br>                .getAttribute(FEIGN_CLIENT_FACTORY_ATTR);<br>        <span class="hljs-keyword">if</span> (factoryBean == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (noCustomizedFallback(factoryBean.getFallback(), factoryBean.getFallbackFactory())) &#123;<br>            Class&lt;?&gt; type = factoryBean.getType();<br>            fallbackPenning.add(<span class="hljs-keyword">new</span> <span class="hljs-title class_">FeignClientFallbackPenning</span>(factoryBean.getName(), factoryBean.getContextId(), type));<br>            factoryBean.setFallbackFactory(ProxiedFeignClientFallbackFactory.class);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">noCustomizedFallback</span><span class="hljs-params">(Object fallback, Object fallbackFactory)</span> &#123;<br>        <span class="hljs-keyword">return</span> (fallback == <span class="hljs-literal">null</span> &amp;&amp; fallbackFactory == <span class="hljs-literal">null</span>) || (fallback == <span class="hljs-keyword">void</span>.class &amp;&amp; fallbackFactory == <span class="hljs-keyword">void</span>.class);<br>    &#125;<br><br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">registerFallbackFactory</span><span class="hljs-params">(FeignClientFactory context)</span> &#123;<br>        ObjectProvider&lt;FeignFallbackInvocation&gt; provider = beanFactory.getBeanProvider(FeignFallbackInvocation.class);<br>        <span class="hljs-type">Method</span> <span class="hljs-variable">method</span> <span class="hljs-operator">=</span> ReflectionUtils.findMethod(FeignClientFactory.class, <span class="hljs-string">&quot;getContext&quot;</span>, String.class);<br>        <span class="hljs-keyword">if</span> (method != <span class="hljs-literal">null</span>) &#123;<br>            method.setAccessible(<span class="hljs-literal">true</span>);<br>            <span class="hljs-keyword">for</span> (FeignClientFallbackPenning penning : fallbackPenning) &#123;<br>                <span class="hljs-type">String</span> <span class="hljs-variable">name</span> <span class="hljs-operator">=</span> !StringUtils.hasText(penning.contextId()) ? penning.name() : penning.contextId();<br>                <span class="hljs-keyword">try</span> &#123;<br>                    <span class="hljs-type">GenericApplicationContext</span> <span class="hljs-variable">appContext</span> <span class="hljs-operator">=</span> (GenericApplicationContext) method.invoke(context, name);<br>                    appContext.registerBean(name + <span class="hljs-string">&quot;FallbackFactory&quot;</span>,<br>                            ProxiedFeignClientFallbackFactory.class,<br>                            () -&gt; <span class="hljs-keyword">new</span> <span class="hljs-title class_">ProxiedFeignClientFallbackFactory</span>&lt;&gt;(penning.type(), provider));<br>                    log.info(<span class="hljs-string">&quot;registered feign client fallback of [&#123;&#125;](&#123;&#125;)&quot;</span>, name, penning.type());<br>                &#125; <span class="hljs-keyword">catch</span> (IllegalAccessException | InvocationTargetException e) &#123;<br>                    log.error(<span class="hljs-string">&quot;failed to register feign client fallback factory of [&#123;&#125;] (&#123;&#125;).&quot;</span>, name, penning.type(), e);<br>                &#125;<br>            &#125;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            log.error(<span class="hljs-string">&quot;unable to resolve reflection info of &#123;&#125;.&quot;</span>, FeignClientFactory.class);<br>        &#125;<br><br>    &#125;<br><br><br><br>    <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ProxiedFeignClientFallbackFactory</span>&lt;T&gt; <span class="hljs-keyword">implements</span> <span class="hljs-title class_">FallbackFactory</span>&lt;T&gt; &#123;<br>        <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> Class&lt;T&gt; targetType;<br>        <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> ObjectProvider&lt;FeignFallbackInvocation&gt; fallbackInvocation;<br><br>        ProxiedFeignClientFallbackFactory(Class&lt;T&gt; targetType, ObjectProvider&lt;FeignFallbackInvocation&gt; fallbackInvocation) &#123;<br>            <span class="hljs-built_in">this</span>.targetType = targetType;<br>            <span class="hljs-built_in">this</span>.fallbackInvocation = fallbackInvocation;<br>        &#125;<br><br>        <span class="hljs-meta">@SuppressWarnings(&quot;unchecked&quot;)</span><br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-keyword">public</span> T <span class="hljs-title function_">create</span><span class="hljs-params">(Throwable cause)</span> &#123;<br>            <span class="hljs-type">FeignFallbackInvocation</span> <span class="hljs-variable">invocation</span> <span class="hljs-operator">=</span> fallbackInvocation.getIfAvailable();<br>            <span class="hljs-keyword">if</span> (invocation == <span class="hljs-literal">null</span>) &#123;<br>                log.warn(<span class="hljs-string">&quot;Bean of type &#123;&#125; not found. feign client fallback failed at: &#123;&#125;&quot;</span>, FeignFallbackInvocation.class, targetType);<br>            &#125;<br>            <span class="hljs-keyword">return</span> (T)Proxy.newProxyInstance(targetType.getClassLoader(), <span class="hljs-keyword">new</span> <span class="hljs-title class_">Class</span>[]&#123;targetType&#125;, (proxy, method, args) -&gt; &#123;<br>                <span class="hljs-type">String</span> <span class="hljs-variable">name</span> <span class="hljs-operator">=</span> method.getName();<br>                <span class="hljs-keyword">return</span> <span class="hljs-keyword">switch</span> (name) &#123;<br>                    <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;equals&quot;</span> -&gt; equals(args[<span class="hljs-number">0</span>]);<br>                    <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;hashCode&quot;</span> -&gt; hashCode();<br>                    <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;toString&quot;</span> -&gt; toString();<br>                    <span class="hljs-keyword">default</span> -&gt; &#123;<br>                        <span class="hljs-keyword">if</span> (invocation != <span class="hljs-literal">null</span>) &#123;<br>                            <span class="hljs-keyword">yield</span> invocation.fallback(targetType, method, args, cause);<br>                        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (cause <span class="hljs-keyword">instanceof</span> RuntimeException e) &#123;<br>                            <span class="hljs-keyword">throw</span> e;<br>                        &#125; <span class="hljs-keyword">else</span> &#123;<br>                            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RuntimeException</span>(cause);<br>                        &#125;<br>                    &#125;<br>                &#125;;<br>            &#125;);<br>        &#125;<br><br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">equals</span><span class="hljs-params">(Object other)</span> &#123;<br>            <span class="hljs-keyword">if</span> (other == <span class="hljs-built_in">this</span>) &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>            &#125;<br>            <span class="hljs-keyword">if</span> (other == <span class="hljs-literal">null</span>) &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>            &#125;<br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">super</span>.equals(other);<br>        &#125;<br><br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">hashCode</span><span class="hljs-params">()</span> &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">super</span>.hashCode() + fallbackInvocation.hashCode();<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">record</span> <span class="hljs-title class_">FeignClientFallbackPenning</span><span class="hljs-params">(String name, String contextId, Class&lt;?&gt; type)</span>&#123;&#125;;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">getOrder</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>spring-cloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>spring-cloud</tag>
      
      <tag>feign</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式集群手操 – Flume搭建 Flume+Kafka的例子</title>
    <link href="/big-data/flume-distribute-install/"/>
    <url>/big-data/flume-distribute-install/</url>
    
    <content type="html"><![CDATA[<p>Flume分布式集群搭建的示例，该示例搭建环境以之前几篇文章的操作环境为基础，而且测试例子使用KafkaSink，因此，若未搭建Kafka集群请先查阅：《<a href="/big-data/kafka-distribute-install/" title="分布式集群手操 – Kafka搭建">分布式集群手操 – Kafka搭建</a>》</p><span id="more"></span><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>下载可从官方网站选择合适的版本下载，本文以1.7.0为例</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">wget http://mirrors.tuna.tsinghua.edu.cn/apache/flume/1.7.0/apache-flume-1.7.0-bin.tar.gz<br></code></pre></td></tr></table></figure><p>解压此处不再重复说明。</p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>进入flume安装的根目录下的<em>config</em>目录，重命名<strong>flume-env.sh.template</strong>为<strong>flume-env.sh</strong>并修改其内容，主要修改<strong>JAVA_HOME</strong>为当前系统安装JDK的路径即可。</p><p>将Flume的<em>bin</em>目录写入环境变量，运行<code>flume-ng version</code>命令如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">Flume 1.7.0<br>Source code repository: https://git-wip-us.apache.org/repos/asf/flume.git<br>Revision: 511d868555dd4d16e6ce4fedc72c2d1454546707<br>Compiled by bessbd on Wed Oct 12 20:51:10 CEST 2016<br>From source with checksum 0d21b3ffdc55a07e1d08875872c00523<br></code></pre></td></tr></table></figure><h1 id="一个KafkaSink的测试例子"><a href="#一个KafkaSink的测试例子" class="headerlink" title="一个KafkaSink的测试例子"></a>一个KafkaSink的测试例子</h1><p>首先，我们以Flume数据采集集群汇总数据到处理中心，再按需发送至Kafka集群供下一步处理为原型，设计通过hdfs1、hdfs2两个agent进行日志采集，通过AvroSink汇总至hdfs3，然后再使用KafkaSink发送至Kafka消息队列</p><h2 id="编写配置文件"><a href="#编写配置文件" class="headerlink" title="编写配置文件"></a>编写配置文件</h2><h3 id="hdfs1的agent配置文件"><a href="#hdfs1的agent配置文件" class="headerlink" title="hdfs1的agent配置文件"></a>hdfs1的agent配置文件</h3><figure class="highlight plaintext"><figcaption><span>kafka-sink.conf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs conf">agent1.sources = s1<br>agent1.channels = c1<br>agent1.sinks = k1<br>agent1.sources.s1.type = exec<br>agent1.sources.s1.command = tail -F /home/bigdata/accesslog/access.log<br>agent1.sources.s1.channels = c1<br>agent1.channels.c1.type = memory<br>agent1.channels.c1.capacity = 1000<br>agent1.channels.c1.transactionCapacity = 100<br>agent1.sinks.k1.type = avro<br>agent1.sinks.k1.channel = c1<br>agent1.sinks.k1.hostname = hdfs3<br>agent1.sinks.k1.port = 4545<br></code></pre></td></tr></table></figure><p>以上配置信息表明该<em>agent</em>的名称为agent1，<em>source</em>为<code>exec tail -f &lt;文件&gt;</code>，可针对生产环境使用不同的<em>source</em>，参见<a href="http://flume.apache.org/FlumeUserGuide.html">官方用户文档</a>，使用内存缓冲通道，<em>avro</em>的<strong>sink</strong>，目标为hdfs3的4545端口</p><h3 id="hdfs2的agent配置文件"><a href="#hdfs2的agent配置文件" class="headerlink" title="hdfs2的agent配置文件"></a>hdfs2的agent配置文件</h3><p>该文件同hdfs1的<em>agent</em>配置文件，只是<em>agent</em>的名称不同而已，为<code>agent2</code></p><h3 id="hdfs3的agent配置文件"><a href="#hdfs3的agent配置文件" class="headerlink" title="hdfs3的agent配置文件"></a>hdfs3的agent配置文件</h3><figure class="highlight plaintext"><figcaption><span>kafka-sink.conf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs conf">agent3.sources = s3<br>agent3.channels = c3<br>agent3.sinks = k3<br>agent3.sources.s3.type = avro<br>agent3.sources.s3.channels = c3<br>agent3.sources.s3.bind = 0.0.0.0<br>agent3.sources.s3.port = 4545<br>agent3.channels.c3.type = memory<br>agent3.channels.c3.capacity = 1000<br>agent3.channels.c3.transactionCapacity = 100<br>agent3.sinks.k3.channel = c3<br>agent3.sinks.k3.type = org.apache.flume.sink.kafka.KafkaSink<br>agent3.sinks.k3.kafka.topic = mytopic<br>agent3.sinks.k3.kafka.bootstrap.servers = hdfs1:9092,hdfs2:9092,hdfs3:9092<br>agent3.sinks.k3.kafka.flumeBatchSize = 30<br>agent3.sinks.k3.kafka.producer.acks = 1<br>agent3.sinks.k3.kafka.producer.linger.ms = 1<br>agent3.sinks.k3.kafka.producer.compression.type = snappy<br></code></pre></td></tr></table></figure><p>以上配置文件指明hdfs3的<em>agent</em>名称为<strong>agent3</strong>，<em>source</em>为<strong>avro</strong>，绑定端口4545，同样使用内存做为缓冲通道，使用<em>KafkaSink</em>，指定了服务集群、BatchSize、Topic、压缩方式等</p><h2 id="启动Kafka集群"><a href="#启动Kafka集群" class="headerlink" title="启动Kafka集群"></a>启动Kafka集群</h2><p>在Kafka安装目录下运行命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">./bin/kafka-server-start.sh config/server.properties &amp;<br></code></pre></td></tr></table></figure><p>创建指定的Topic</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">./bin/kafka-topics.sh -zookeeper hdfs1:2181,hdfs2:2181,hdfs3:2181 -topic mytopic -replication-factor 1 -partitions 1 -create<br></code></pre></td></tr></table></figure><p>创建消费者（用于查看Kafka消息是否存在）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">./bin/kafka-console-consumer.sh -zookeeper hdfs1:2181,hdfs2:2181,hdfs3:2181 - from-begining -topic mytopic<br></code></pre></td></tr></table></figure><h2 id="启动Flume"><a href="#启动Flume" class="headerlink" title="启动Flume"></a>启动Flume</h2><p>在hdfs1节点运行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">flume-ng agent -n agent1 -c conf -f ~/services/apache-flume-1.7.0-bin/conf/kafka-sink.conf<br></code></pre></td></tr></table></figure><p>在hdfs2节点运行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">flume-ng agent -n agent2 -c conf -f ~/services/apache-flume-1.7.0-bin/conf/kafka-sink.conf<br></code></pre></td></tr></table></figure><p>在hdfs3节点运行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">flume-ng agent -n agent3 -c conf -f ~/services/apache-flume-1.7.0-bin/conf/kafka-sink.conf<br></code></pre></td></tr></table></figure><p>然后启动模拟的access日志生成脚本，该脚本会不断在<code>access.log</code>文件末尾附加模拟的访问日志记录（关于该脚本，可参见《<a href="/big-data/storm-nginx-accesslog/" title="Storm实时处理 – Nginx访问日志">Storm实时处理 – Nginx访问日志</a>》</p><p>此时可看到消费者控制台输出了大量访问日志信息，测试成功</p>]]></content>
    
    
    <categories>
      
      <category>big-data</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>distribution</tag>
      
      <tag>big-data</tag>
      
      <tag>flume</tag>
      
      <tag>kafka</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Storm示例 - Storm实时日志处理平台的搭建</title>
    <link href="/big-data/storm-data-platform/"/>
    <url>/big-data/storm-data-platform/</url>
    
    <content type="html"><![CDATA[<p>此示例工程以Storm+Flume+Kafka分布式集群为运行环境，搭建日志流式处理平台，实时解析访问日志，统计、监控服务访问，是之前一篇Storm实战的完善和补充。</p><span id="more"></span><h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>该示例运行环境的搭建，在本博客的相关文章均有介绍，示例的环境架构如下图所示，日志信息由Flume集群收集并统一发放到Kafka集群，再由Storm集群读取处理（只有三台虚拟机进行集群模拟）。</p><img src="/images/storm-data-frame.png" class="" title="环境架构" alt="环境架构"><h1 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h1><h2 id="结构分析"><a href="#结构分析" class="headerlink" title="结构分析"></a>结构分析</h2><p>该示例较为简单，主要分为三类Bolt，即<strong>Load</strong>、<strong>Count</strong>、<strong>Summary</strong>（或<em>Collect</em>）负责数据的加载解析、统计分析、汇总存储。结构如图：</p><img src="/images/storm-data-program.png" class="" title="项目图解" alt="项目图解"><h2 id="工具的选取"><a href="#工具的选取" class="headerlink" title="工具的选取"></a>工具的选取</h2><p>取操作最为频繁的调用，作为静态工具单独编写，例如：数据的解析、存储等。<br>本示例使用Gson解析日志行为PO对象，而数据写入则由于<em>SummaryBolt</em>并行度约定为<code>1</code>，使用全局<em>PrepareStatement</em>对象以免去不必要的对象生成，提升性能。<br>该部分较为简单，源码可查看我的<a href="https://github.com/vicasong/StormDataPlatform">Github</a></p><h2 id="程序编写"><a href="#程序编写" class="headerlink" title="程序编写"></a>程序编写</h2><h3 id="Spout说明"><a href="#Spout说明" class="headerlink" title="Spout说明"></a>Spout说明</h3><p>由于使用<em>storm-kafka</em>类库，<strong>KafkaSpout</strong>将十分简单，只需配置一下<strong>SpoutConfig</strong>即可。</p><h3 id="LoadBolt实现"><a href="#LoadBolt实现" class="headerlink" title="LoadBolt实现"></a>LoadBolt实现</h3><p>主要任务就是读取Tuple的数据行，然后使用Gson工具解析为PO对象，根据统计的时间精度生成标识字段以便传递到下一个Bolt时是同一个时段的数据，需要在Bolt顺序声明中指定字段。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">LoadBolt</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">BaseBasicBolt</span> &#123;<br>    <span class="hljs-comment">//按小时统计，格式化时间精度为每小时</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">SimpleDateFormat</span> <span class="hljs-variable">format</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">SimpleDateFormat</span>(<span class="hljs-string">&quot;yyyy-MM-dd-HH&quot;</span>);<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">execute</span><span class="hljs-params">(Tuple input, BasicOutputCollector collector)</span> &#123;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">sourceLine</span> <span class="hljs-operator">=</span> input.getString(<span class="hljs-number">0</span>);<br>        <span class="hljs-keyword">if</span>(sourceLine.trim().length() &lt; <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span>;<br>        <span class="hljs-keyword">try</span> &#123;<br>            <span class="hljs-type">AccessLog</span> <span class="hljs-variable">entity</span> <span class="hljs-operator">=</span> LogParser.parse(sourceLine);<br>            collector.emit(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Values</span>(format.format(entity.getTime_local())+<span class="hljs-string">&quot; &quot;</span>+entity.getRequest_url(),<br>                    entity));<br>        &#125;<span class="hljs-keyword">catch</span> (JsonParseException ex)&#123;<br>            <span class="hljs-comment">// Nothing To Do</span><br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">declareOutputFields</span><span class="hljs-params">(OutputFieldsDeclarer declarer)</span> &#123;<br>        declarer.declare(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Fields</span>(<span class="hljs-string">&quot;id&quot;</span>,<span class="hljs-string">&quot;entity&quot;</span>));<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="CountBolt实现"><a href="#CountBolt实现" class="headerlink" title="CountBolt实现"></a>CountBolt实现</h3><p>统计当前时段的PageView数量和UserView数量，同时包括一些状态信息、最多访问的信息等，此处较为灵活，按需编写即可。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">CountBolt</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">BaseBasicBolt</span> &#123;<br>    <span class="hljs-keyword">private</span> Map&lt;String, Integer&gt; counter = <span class="hljs-literal">null</span>;<br>    <span class="hljs-keyword">private</span> Map&lt;String, Integer&gt; status = <span class="hljs-literal">null</span>;<br>    <span class="hljs-keyword">private</span> Map&lt;String, Integer&gt; method = <span class="hljs-literal">null</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">String</span> <span class="hljs-variable">pvKey</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;pv&quot;</span>;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">prepare</span><span class="hljs-params">(Map stormConf, TopologyContext context)</span> &#123;<br>        counter = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;String, Integer&gt;();<br>        status = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;String, Integer&gt;();<br>        method = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;String, Integer&gt;();<br>        <span class="hljs-built_in">super</span>.prepare(stormConf, context);<br>    &#125;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">countPvUvByIp</span><span class="hljs-params">(AccessLog entity)</span>&#123;<br>        <span class="hljs-comment">//Count The Page View</span><br>        <span class="hljs-type">Integer</span> <span class="hljs-variable">pv</span> <span class="hljs-operator">=</span> counter.get(pvKey);<br>        <span class="hljs-keyword">if</span>(pv == <span class="hljs-literal">null</span>)&#123;<br>            pv = <span class="hljs-number">0</span>;<br>        &#125;<br>        counter.put(pvKey, ++ pv);<br>        <span class="hljs-comment">//Count The User View</span><br>        <span class="hljs-type">String</span> <span class="hljs-variable">uvKey</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;_uv&quot;</span>;<br>        <span class="hljs-keyword">if</span>(!counter.containsKey(entity.getRemote_addr()+ uvKey))&#123;<br>            counter.put(entity.getRemote_addr()+ uvKey, <span class="hljs-number">1</span>);<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">countStatus</span><span class="hljs-params">(AccessLog entity)</span>&#123;<br>        <span class="hljs-comment">//Count Status Pv</span><br>        <span class="hljs-type">Integer</span> <span class="hljs-variable">pv3xx</span> <span class="hljs-operator">=</span> status.get(<span class="hljs-string">&quot;3xxPv&quot;</span>);<br>        <span class="hljs-type">Integer</span> <span class="hljs-variable">pv4xx</span> <span class="hljs-operator">=</span> status.get(<span class="hljs-string">&quot;4xxPv&quot;</span>);<br>        <span class="hljs-type">Integer</span> <span class="hljs-variable">pvOther</span> <span class="hljs-operator">=</span> status.get(<span class="hljs-string">&quot;otherPv&quot;</span>);<br>        <span class="hljs-type">String</span> <span class="hljs-variable">stat</span> <span class="hljs-operator">=</span> String.valueOf(entity.getStatus());<br>        <span class="hljs-keyword">if</span>(stat.startsWith(<span class="hljs-string">&quot;3&quot;</span>))<br>            status.put(<span class="hljs-string">&quot;3xxPv&quot;</span>, pv3xx == <span class="hljs-literal">null</span>? <span class="hljs-number">1</span>:++ pv3xx);<br>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(stat.startsWith(<span class="hljs-string">&quot;4&quot;</span>))<br>            status.put(<span class="hljs-string">&quot;4xxPv&quot;</span>, pv4xx == <span class="hljs-literal">null</span>? <span class="hljs-number">1</span>:++ pv4xx);<br>        <span class="hljs-keyword">else</span><br>            status.put(<span class="hljs-string">&quot;otherPv&quot;</span>, pvOther == <span class="hljs-literal">null</span>? <span class="hljs-number">1</span>:++ pvOther);<br>        <span class="hljs-comment">//Count Method Pv By User</span><br>        <span class="hljs-type">String</span> <span class="hljs-variable">mKey</span> <span class="hljs-operator">=</span> entity.getRequest_method() + <span class="hljs-string">&quot; &quot;</span> +entity.getRemote_addr();<br>        <span class="hljs-type">Integer</span> <span class="hljs-variable">mCount</span> <span class="hljs-operator">=</span> method.get(mKey);<br>        <span class="hljs-keyword">if</span>(mCount == <span class="hljs-literal">null</span>)&#123;<br>            mCount = <span class="hljs-number">0</span>;<br>        &#125;<br>        method.put(mKey, ++ mCount);<br>    &#125;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> <span class="hljs-title function_">safeGet</span><span class="hljs-params">(Map&lt;String,Integer&gt; map, String key)</span>&#123;<br>        <span class="hljs-keyword">return</span> map.get(key) == <span class="hljs-literal">null</span> ? <span class="hljs-number">0</span>: map.get(key);<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">execute</span><span class="hljs-params">(Tuple input, BasicOutputCollector collector)</span> &#123;<br>        <span class="hljs-type">AccessLog</span> <span class="hljs-variable">entity</span> <span class="hljs-operator">=</span> (AccessLog) input.getValueByField(<span class="hljs-string">&quot;entity&quot;</span>);<br>        <span class="hljs-type">String</span> <span class="hljs-variable">timeId</span> <span class="hljs-operator">=</span> input.getValueByField(<span class="hljs-string">&quot;id&quot;</span>).toString().split(<span class="hljs-string">&quot; &quot;</span>)[<span class="hljs-number">0</span>];<br>        countPvUvByIp(entity);<br>        countStatus(entity);<br>        <span class="hljs-type">String</span> <span class="hljs-variable">maxMethod</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;&quot;</span>;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">maxMethodCount</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(String key : method.keySet())&#123;<br>            <span class="hljs-keyword">if</span>(method.get(key) &gt; maxMethodCount)&#123;<br>                maxMethodCount = method.get(key);<br>                maxMethod = key;<br>            &#125;<br>        &#125;<br>        String[] temp = maxMethod.split(<span class="hljs-string">&quot; &quot;</span>);<br>        collector.emit(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Values</span>(timeId, entity.getRequest_url(), counter.get(pvKey), counter.size() - <span class="hljs-number">1</span>,<br>                safeGet(status, <span class="hljs-string">&quot;4xxPv&quot;</span>), safeGet(status, <span class="hljs-string">&quot;3xxPv&quot;</span>), safeGet(status, <span class="hljs-string">&quot;otherPv&quot;</span>),<br>                temp[<span class="hljs-number">0</span>], temp[<span class="hljs-number">1</span>]));<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">declareOutputFields</span><span class="hljs-params">(OutputFieldsDeclarer declarer)</span> &#123;<br>        declarer.declare(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Fields</span>(<span class="hljs-string">&quot;time&quot;</span>,<span class="hljs-string">&quot;resource&quot;</span>,<span class="hljs-string">&quot;pv&quot;</span>,<span class="hljs-string">&quot;uv&quot;</span>,<span class="hljs-string">&quot;4xxPv&quot;</span>,<br>                <span class="hljs-string">&quot;3xxPv&quot;</span>,<span class="hljs-string">&quot;otherPv&quot;</span>,<span class="hljs-string">&quot;maxMethod&quot;</span>, <span class="hljs-string">&quot;maxUser&quot;</span>));<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="SummaryBolt实现"><a href="#SummaryBolt实现" class="headerlink" title="SummaryBolt实现"></a>SummaryBolt实现</h3><p>只是对CountBolt的输出进行汇总存储，按字段取出，写入数据库即可，并行度可根据需要调整（同时需要注意数据写入工具的并发实现）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SummaryBolt</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">BaseBasicBolt</span> &#123;<br>    <span class="hljs-keyword">private</span> String url,username,password,tabname;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">prepare</span><span class="hljs-params">(Map stormConf, TopologyContext context)</span> &#123;<br>        url = stormConf.get(<span class="hljs-string">&quot;mysql.url&quot;</span>).toString();<br>        username = stormConf.get(<span class="hljs-string">&quot;mysql.username&quot;</span>).toString();<br>        password = stormConf.get(<span class="hljs-string">&quot;mysql.password&quot;</span>).toString();<br>        tabname = stormConf.get(<span class="hljs-string">&quot;mysql.tablename&quot;</span>).toString();<br>        <span class="hljs-built_in">super</span>.prepare(stormConf, context);<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">execute</span><span class="hljs-params">(Tuple input, BasicOutputCollector collector)</span> &#123;<br>        <span class="hljs-comment">//&quot;time&quot;,&quot;resource&quot;,&quot;pv&quot;,&quot;uv&quot;,&quot;4xxPv&quot;,&quot;3xxPv&quot;,&quot;otherPv&quot;,&quot;maxMethod&quot;, &quot;maxUser&quot;</span><br>        <span class="hljs-type">String</span> <span class="hljs-variable">time</span> <span class="hljs-operator">=</span> input.getStringByField(<span class="hljs-string">&quot;time&quot;</span>);<br>        <span class="hljs-type">String</span> <span class="hljs-variable">resource</span> <span class="hljs-operator">=</span> input.getStringByField(<span class="hljs-string">&quot;resource&quot;</span>);<br>        <span class="hljs-type">int</span> <span class="hljs-variable">pv</span> <span class="hljs-operator">=</span> input.getIntegerByField(<span class="hljs-string">&quot;pv&quot;</span>);<br>        <span class="hljs-type">int</span> <span class="hljs-variable">uv</span> <span class="hljs-operator">=</span> input.getIntegerByField(<span class="hljs-string">&quot;uv&quot;</span>);<br>        <span class="hljs-type">int</span> <span class="hljs-variable">pv4xx</span> <span class="hljs-operator">=</span> input.getIntegerByField(<span class="hljs-string">&quot;4xxPv&quot;</span>);<br>        <span class="hljs-type">int</span> <span class="hljs-variable">pv3xx</span> <span class="hljs-operator">=</span> input.getIntegerByField(<span class="hljs-string">&quot;3xxPv&quot;</span>);<br>        <span class="hljs-type">int</span> <span class="hljs-variable">otherPv</span> <span class="hljs-operator">=</span> input.getIntegerByField(<span class="hljs-string">&quot;otherPv&quot;</span>);<br>        <span class="hljs-type">String</span> <span class="hljs-variable">maxMethod</span> <span class="hljs-operator">=</span> input.getStringByField(<span class="hljs-string">&quot;maxMethod&quot;</span>);<br>        <span class="hljs-type">String</span> <span class="hljs-variable">maxUser</span> <span class="hljs-operator">=</span> input.getStringByField(<span class="hljs-string">&quot;maxUser&quot;</span>);<br>        DBWriter.write(url, username, password, tabname, time,resource,pv,uv,pv3xx,pv4xx,otherPv,maxMethod,maxUser);<br>    &#125;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">cleanup</span><span class="hljs-params">()</span> &#123;<br>        DBWriter.close();<br>        <span class="hljs-built_in">super</span>.cleanup();<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">declareOutputFields</span><span class="hljs-params">(OutputFieldsDeclarer declarer)</span> &#123;<br>        <span class="hljs-comment">//Nothing</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="主类实现"><a href="#主类实现" class="headerlink" title="主类实现"></a>主类实现</h3><p>流程很简单：<strong>加载配置信息→配置KafkaSpout→Bolt的安排→准备Topology→提交Topology</strong><br>需要注意的部分已在代码注释处标明。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Program</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        <span class="hljs-type">Properties</span> <span class="hljs-variable">properties</span> <span class="hljs-operator">=</span> loadProperties(<span class="hljs-string">&quot;config.properties&quot;</span>);<br>        <span class="hljs-comment">//依次指定Zookeeper集群主机、Kafka消息主题、Zookeeper存储Kafka消息偏移数据的根目录及分区标识名称</span><br>        <span class="hljs-comment">//因此，消息偏移量数据会存储在类似：&lt;Zkroot&gt;/&lt;id&gt;/partition_&lt;partitionNumber&gt;，注意Zkroot必须以/开始</span><br>        <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> 注意修改ZkRoot和id</span><br>        <span class="hljs-type">SpoutConfig</span> <span class="hljs-variable">kafkaConfig</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">SpoutConfig</span>(<span class="hljs-keyword">new</span> <span class="hljs-title class_">ZkHosts</span>(properties.getProperty(<span class="hljs-string">&quot;zookeeper.server&quot;</span>)),<br>                properties.getProperty(<span class="hljs-string">&quot;kafka.topic&quot;</span>),<span class="hljs-string">&quot;/mystorm&quot;</span>,<span class="hljs-string">&quot;access&quot;</span>);<br>        <span class="hljs-comment">//设置消息解析的Scheme，此处为String字符串</span><br>        kafkaConfig.scheme = <span class="hljs-keyword">new</span> <span class="hljs-title class_">SchemeAsMultiScheme</span>(<span class="hljs-keyword">new</span> <span class="hljs-title class_">StringScheme</span>());<br>        <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> 指定并发度,Fields</span><br>        <span class="hljs-type">TopologyBuilder</span> <span class="hljs-variable">builder</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">TopologyBuilder</span>();<br>        builder.setSpout(<span class="hljs-string">&quot;kafka-spout&quot;</span>, <span class="hljs-keyword">new</span> <span class="hljs-title class_">KafkaSpout</span>(kafkaConfig));<br>        builder.setBolt(<span class="hljs-string">&quot;load-bolt&quot;</span>, <span class="hljs-keyword">new</span> <span class="hljs-title class_">LoadBolt</span>(),<span class="hljs-number">6</span>).shuffleGrouping(<span class="hljs-string">&quot;kafka-spout&quot;</span>);<br>        builder.setBolt(<span class="hljs-string">&quot;count-bolt&quot;</span>, <span class="hljs-keyword">new</span> <span class="hljs-title class_">CountBolt</span>(),<span class="hljs-number">6</span>).fieldsGrouping(<span class="hljs-string">&quot;load-bolt&quot;</span>, <span class="hljs-keyword">new</span> <span class="hljs-title class_">Fields</span>(<span class="hljs-string">&quot;id&quot;</span>));<br>        builder.setBolt(<span class="hljs-string">&quot;summary-bolt&quot;</span>, <span class="hljs-keyword">new</span> <span class="hljs-title class_">SummaryBolt</span>(), <span class="hljs-number">1</span>).shuffleGrouping(<span class="hljs-string">&quot;count-bolt&quot;</span>);<br>        <span class="hljs-type">Config</span> <span class="hljs-variable">config</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Config</span>();<br>        config.setMaxSpoutPending(<span class="hljs-number">10</span>);<br>        config.setNumWorkers(<span class="hljs-number">1</span>);<br>        config.setMaxTaskParallelism(<span class="hljs-number">10</span>);<br>        config.put(Config.TOPOLOGY_TRIDENT_BATCH_EMIT_INTERVAL_MILLIS, <span class="hljs-number">1000</span>);<br>        config.put(<span class="hljs-string">&quot;mysql.url&quot;</span>, properties.getProperty(<span class="hljs-string">&quot;mysql.url&quot;</span>));<br>        config.put(<span class="hljs-string">&quot;mysql.username&quot;</span>, properties.getProperty(<span class="hljs-string">&quot;mysql.username&quot;</span>));<br>        config.put(<span class="hljs-string">&quot;mysql.password&quot;</span>, properties.getProperty(<span class="hljs-string">&quot;mysql.password&quot;</span>));<br>        config.put(<span class="hljs-string">&quot;mysql.tablename&quot;</span>, properties.getProperty(<span class="hljs-string">&quot;mysql.tablename&quot;</span>));<br>        <span class="hljs-type">StormTopology</span> <span class="hljs-variable">topology</span> <span class="hljs-operator">=</span> builder.createTopology();<br>        <span class="hljs-keyword">try</span> &#123;<br>            StormSubmitter.submitTopology(properties.getProperty(<span class="hljs-string">&quot;topology.name&quot;</span>), config, topology);<br>        &#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>            e.printStackTrace();<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> Properties <span class="hljs-title function_">loadProperties</span><span class="hljs-params">(String fileName)</span>&#123;<br>        <span class="hljs-type">Properties</span> <span class="hljs-variable">prop</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Properties</span>();<br>        <span class="hljs-keyword">try</span> &#123;<br>            prop.load(Program.class.getClassLoader().getResourceAsStream(fileName));<br>        &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;<br>            System.err.println(<span class="hljs-string">&quot;Missing config file : &quot;</span>+fileName);<br>            System.exit(<span class="hljs-number">1</span>);<br>        &#125;<br>        <span class="hljs-keyword">return</span> prop;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="部署运行"><a href="#部署运行" class="headerlink" title="部署运行"></a>部署运行</h2><h3 id="数据库搭建"><a href="#数据库搭建" class="headerlink" title="数据库搭建"></a>数据库搭建</h3><p>创建指定的用户，例如：创建名为<em>vica</em>的网络用户，对数据库<em>accesslog_count</em>拥有所以控制权</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">grant</span> <span class="hljs-keyword">all</span> privileges <span class="hljs-keyword">on</span> `accesslog_count`.<span class="hljs-operator">*</span> <span class="hljs-keyword">to</span> <span class="hljs-string">&#x27;vica&#x27;</span>@<span class="hljs-string">&#x27;%&#x27;</span> identified <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;xxxxxx&#x27;</span>;<br></code></pre></td></tr></table></figure><p>然后为其创建数据库和表：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- CREATE DATABASE</span><br><span class="hljs-keyword">CREATE</span> DATABASE accesslog_count;<br><span class="hljs-comment">-- CREATE TABLE</span><br>USE accesslog_count;<br><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> `t_count`(<br>  `<span class="hljs-type">time</span>`  <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">15</span>)  <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span> ,<br>  `resource` <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">240</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span> ,<br>  `page_view`  <span class="hljs-type">INT</span>   <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span> ,<br>  `user_view`  <span class="hljs-type">INT</span>   <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span> ,<br>  `pv_3`     <span class="hljs-type">INT</span>   <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span> ,<br>  `pv_4`     <span class="hljs-type">INT</span>   <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span> ,<br>  `pv_other`  <span class="hljs-type">INT</span>  <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span> ,<br>  `max_method`  <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">12</span>)  <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span> ,<br>  `max_user`   <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">16</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span> ,<br>  <span class="hljs-keyword">PRIMARY</span> KEY (`<span class="hljs-type">time</span>`, `resource`)<br>);<br></code></pre></td></tr></table></figure><h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><p>为模拟日志的实时产生，将提前下载好的access日志分割开来，然后按指定时间输出日志行。<br>使用命令<code>wc -l</code>查看当前日志文件的行数，例如该示例所使用的原文件为<em>27311</em>行，使用命令<code>split -l 15000 access.log part-</code>将该文件分割成两个文件（<em>part-aa</em>和<em>part-ab</em>），前者拥有<code>15000</code>行数据，后者则有剩下的<code>12311</code>行。</p><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><p>使用Maven对写好的程序进行打包（pom.xml稍后会在文章末尾放出）并上传到集群某主机。</p><ul><li>启动Zookeeper集群，使用命令<code>./bin/zkServer.sh start</code></li><li>启动Nimbus，使用命令<code>storm nimbus &amp;</code></li><li>启动Supervisor，使用命令<code>storm supervisor &amp;</code></li><li>启动Kafka，使用命令<code>./bin/kafka-server-start.sh config/server.properties &amp;</code></li><li>创建话题，使用命令<code>./bin/kafka-topics.sh -zookeeper hdfs1:2181,hdfs2:2181,hdfs3:2181 -topic flume-topic -replication-factor 1 -partitions 1 -create</code></li><li>启动Flume，使用命令<code>flume-ng agent -n &lt;agent名称&gt; -f conf/kafka-sink.conf -Dflume.root.logger=INFO,console</code></li></ul><p>以上命令和配置均可在本博客找到相关文章的描述，Flume日志采集及KafkaSink的配置可在《<a href="/big-data/flume-distribute-install/" title="分布式集群手操 – Flume搭建 Flume+Kafka的例子">分布式集群手操 – Flume搭建 Flume+Kafka的例子</a>》中找到。</p><p>部署Topology，使用命令<code>storm jar &lt;jar文件&gt; &lt;主类&gt;</code>，即可。</p><p>然后启动模拟数据生产，<code>./line.sh part-aa 0.1 &gt;&gt; access.log</code>，该脚本指定<em>每隔0.1s输出part-aa文件数据行</em>。该脚本代码如下：</p><figure class="highlight shell"><figcaption><span>line.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">!/bin/sh</span><br>filename=$1<br>time=$2<br>while read LINE<br>do<br>        echo $LINE<br>        sleep $time<br>done &lt; $filename<br></code></pre></td></tr></table></figure><h3 id="检视运行"><a href="#检视运行" class="headerlink" title="检视运行"></a>检视运行</h3><p>在Nimbus端启动UI组件（命令：<code>storm ui &amp;</code>），访问其8080端口可查看运行中的Topology的相关信息，如下图：</p><img src="/images/storm-data-ui.png" class="" title="StormUI" alt="StormUI"><p>展开查看图示，更为直观：</p><img src="/images/storm-data-graph.png" class="" title="Topology图示" alt="Topology图示"><p>在本地端连接数据库，查看已统计的信息:</p><img src="/images/storm-data-select-mysql.png" class="" title="查询数据库" alt="查询数据库"><p>至此，本示例已结束。</p><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><figure class="highlight xml"><figcaption><span>pom.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=<span class="hljs-string">&quot;1.0&quot;</span> encoding=<span class="hljs-string">&quot;UTF-8&quot;</span>?&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">project</span> <span class="hljs-attr">xmlns</span>=<span class="hljs-string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span><br><span class="hljs-tag">         <span class="hljs-attr">xmlns:xsi</span>=<span class="hljs-string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span><br><span class="hljs-tag">         <span class="hljs-attr">xsi:schemaLocation</span>=<span class="hljs-string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">modelVersion</span>&gt;</span>4.0.0<span class="hljs-tag">&lt;/<span class="hljs-name">modelVersion</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>me.vica.storm<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>AccessLogger<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>log4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>log4j<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.2.17<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.storm<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>storm-core<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.0.2<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.kafka<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>kafka_2.10<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>0.10.0.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>compile<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">exclusions</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.zookeeper<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>zookeeper<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.slf4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>slf4j-log4j12<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">exclusions</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.storm<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>storm-kafka<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.0.2<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>mysql<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>mysql-connector-java<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>5.1.37<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>runtime<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.google.code.gson<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>gson<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.2.4<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">build</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">plugins</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>maven-shade-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.3<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">executions</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">execution</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">phase</span>&gt;</span>package<span class="hljs-tag">&lt;/<span class="hljs-name">phase</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">goals</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">goal</span>&gt;</span>shade<span class="hljs-tag">&lt;/<span class="hljs-name">goal</span>&gt;</span><br>                        <span class="hljs-tag">&lt;/<span class="hljs-name">goals</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">transformers</span>&gt;</span><br>                                <span class="hljs-tag">&lt;<span class="hljs-name">transformer</span> <span class="hljs-attr">implementation</span>=<span class="hljs-string">&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;</span>&gt;</span><br>                                    <span class="hljs-tag">&lt;<span class="hljs-name">mainClass</span>&gt;</span>me.vica.Program<span class="hljs-tag">&lt;/<span class="hljs-name">mainClass</span>&gt;</span><br>                                <span class="hljs-tag">&lt;/<span class="hljs-name">transformer</span>&gt;</span><br>                            <span class="hljs-tag">&lt;/<span class="hljs-name">transformers</span>&gt;</span><br>                        <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>                    <span class="hljs-tag">&lt;/<span class="hljs-name">execution</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">executions</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">plugins</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">build</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">project</span>&gt;</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>big-data</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>distribution</tag>
      
      <tag>big-data</tag>
      
      <tag>flume</tag>
      
      <tag>kafka</tag>
      
      <tag>storm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式集群手操 – Spark搭建</title>
    <link href="/big-data/spark-distribute-install/"/>
    <url>/big-data/spark-distribute-install/</url>
    
    <content type="html"><![CDATA[<p>Spark的分布式集群搭建示例，是在之前的几篇分布式搭建环境基础上的进行的搭建示例，Spark运行在Hadoop之上，还可以以StandAlone方式运行，此篇介绍其集群部署安装。</p><span id="more"></span><h1 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h1><p>访问<a href="http://spark.apache.org/downloads.html">Apache Spark官方</a>下载站点，进入下载页，选择合适的版本下载即可。由于此示例环境为<em>hadoop2.6.4</em>，所以选择<em>package type</em>为<em>Pre-build for Hadoop2.6</em>，然后选择Spark发行版本，以<em>2.0.1</em>为例。</p><p>由于Spark是由Scala语言编写的，因此还需要Scala环境，通过<code> wget http://downloads.lightbend.com/scala/2.11.8/scala-2.11.8.tgz</code> 以下载<em>Scala2.11.8</em>。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>将下载好的tar包解压到适当的目录下即可。</p><ul><li>参考命令：<code>tar -zxf &lt;tar文件&gt;</code></li></ul><p>同时将Scala的安装目录添加到环境变量以使其生效，例如在用户环境变量文件中如下配置：</p><figure class="highlight shell"><figcaption><span>.bash_profile</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">export SCALA_HOME=/home/bigdata/services/scala-2.11.8<br>export PATH=$PATH:$SCALA_HOME/bin<br></code></pre></td></tr></table></figure><p>然后执行source使其生效：<code>source ~/.bash_profile</code> ，输入<code>scala</code>确认安装。</p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>进入<em>conf</em>目录，重命名<code>template</code>文件去掉<code>template</code>扩展名</p><h3 id="spark-env-sh"><a href="#spark-env-sh" class="headerlink" title="spark-env.sh"></a>spark-env.sh</h3><p>使用命令 <code>cp spark-env.sh.template spark-env.sh</code> 拷贝并重命名，然后修改<code>spark-env.sh</code>文件如下内容：</p><figure class="highlight shell"><figcaption><span>spark-env.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">export HADOOP_CONF_DIR=/home/bigdata/services/hadoop-2.6.4/etc/hadoop<br>export JAVA_HOME=/usr/local/jdk1.8.0_101<br>export SCALA_HOME=/home/bigdata/services/scala-2.11.8<br>export SPARK_MASTER_HOST=hdfs1<br>export SPARK_MASTER_WEBUI_PORT=8081<br></code></pre></td></tr></table></figure><h3 id="spark-default-conf"><a href="#spark-default-conf" class="headerlink" title="spark-default.conf"></a>spark-default.conf</h3><p>使用命令 <code>cp spark-default.conf.template spark-default.conf</code> 拷贝并重命名，然后修改<code>spark-default.conf</code>文件如下内容：</p><figure class="highlight plaintext"><figcaption><span>spark-default.conf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs conf">spark.master                       spark://hdfs1:7077<br>spark.eventLog.enabled             true<br>spark.eventLog.dir                 hdfs://hdfs1:9000/spark-event<br>spark.dirver.memory                1g<br>slaves<br></code></pre></td></tr></table></figure><p>使用命令 <code>cp slaves.template slaves</code> 拷贝并重命名，然后修改<code>slaves</code>文件如下内容：</p><figure class="highlight text"><figcaption><span>slaves</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">hdfs2<br>hdfs3<br></code></pre></td></tr></table></figure><h2 id="分发配置"><a href="#分发配置" class="headerlink" title="分发配置"></a>分发配置</h2><p>使用scp命令分发配置好的内容到其他节点的相同目录下，包括scala、spark，以hdfs3节点发送hdfs1节点为例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">scp -r ~/services/scala-2.11.8 bigdata@hdfs1:~/services/<br>scp -r ~/services/spark-2.0.1-bin-hadoop2.6 bigdata@hdfs1:~/services/<br>scp ~/.bash_profile bigdata@hdfs1:~/<br></code></pre></td></tr></table></figure><h1 id="启动与测试"><a href="#启动与测试" class="headerlink" title="启动与测试"></a>启动与测试</h1><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>在确认HDFS运行的情况下至Spark安装目录运行<code>sbin/start-all.sh</code>即可启动<strong>master</strong>和<strong>slaves</strong>。</p><p>通过<code>jps</code>命令确认各进程已成功启动。</p><p>按照配置的端口地址，打开WebUI查看信息，例如：<a href="http://hdfs1:8081。">http://hdfs1:8081。</a></p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>运行<code>bin/spark-shell</code>，可能会抛出以下异常：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs text">16/09/25 12:45:35 ERROR spark.SparkContext: Error initializing SparkContext.<br>java.io.FileNotFoundException: File does not exist: hdfs://hdfs1:9000/spark-event<br>at org.apache.hadoop.hdfs.DistributedFileSystem$18.doCall(DistributedFileSystem.java:1122)<br>at org.apache.hadoop.hdfs.DistributedFileSystem$18.doCall(DistributedFileSystem.java:1114)<br>at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)<br>at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1114)<br>at org.apache.spark.scheduler.EventLoggingListener.start(EventLoggingListener.scala:93)<br>at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:516)<br>at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2275)<br>at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:831)<br>at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:823)<br>at scala.Option.getOrElse(Option.scala:121)<br>at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:823)<br>at org.apache.spark.repl.Main$.createSparkSession(Main.scala:95)<br></code></pre></td></tr></table></figure><p>只需在hdfs创建指定的目录就好：<code>hadoop fs -mkdir /spark-event</code></p><p>重新运行<strong>spark-shell</strong>，等待一段时间的加载后进入shell命令行：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs text">Setting default log level to &quot;WARN&quot;.<br>To adjust logging level use sc.setLogLevel(newLevel).<br>16/09/25 13:05:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable<br>16/09/25 13:06:21 WARN spark.SparkContext: Use an existing SparkContext, some configuration may not take effect.<br>Spark context Web UI available at http://192.168.223.151:4040<br>Spark context available as &#x27;sc&#x27; (master = spark://hdfs1:7077, app id = app-20160925130549-0002).<br>Spark session available as &#x27;spark&#x27;.<br>Welcome to<br>      ____              __<br>     / __/__  ___ _____/ /__<br>    _\ \/ _ \/ _ `/ __/  &#x27;_/<br>   /___/ .__/\_,_/_/ /_/\_\   version 2.0.1<br>      /_/<br>         <br>Using Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_101)<br>Type in expressions to have them evaluated.<br>Type :help for more information.<br></code></pre></td></tr></table></figure><p>在shell输入以下代码行：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">var</span> wordcount=sc.textFile(<span class="hljs-string">&quot;hdfs://hdfs1:9000/spark/input/helloworld.txt&quot;</span>).flatMap(line=&gt;line.split(<span class="hljs-string">&quot; &quot;</span>)).map(word=&gt;(word,<span class="hljs-number">1</span>)).reduceByKey(_+_).collect().foreach(println)<br></code></pre></td></tr></table></figure><p>运行一个WordCount作业，同时通过WebUI查看作业信息<a href="http://192.168.223.151:4040：">http://192.168.223.151:4040：</a></p><img src="/images/src-spark-job-webui.png" class="" title="Spark WebUI" alt="Spark WebUI"><p>作业运行成功后，shell命令行输出：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs text">(Hello,3)                                                                       <br>(Thursday,1)<br>(Is,1)<br>(Line,1)<br>(World,3)<br>(File,1)<br>(The,1)<br>(End,1)<br>(Print,1)<br>(Today,1)<br>(System,1)<br>wordcount: Unit = ()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>big-data</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>distribution</tag>
      
      <tag>big-data</tag>
      
      <tag>spark</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>百般波折的Hadoop编译</title>
    <link href="/big-data/hadoop-make-install/"/>
    <url>/big-data/hadoop-make-install/</url>
    
    <content type="html"><![CDATA[<p>终于不能忍了，每次使用hadoop都出native库警告，于是决定编译hadoop，也是走了不少弯路。唯一参考了官方文档，当初居然没想到去百度一篇别人编译的过程，先填坑，哎~ 说多了都是泪。</p><span id="more"></span><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>首先从官方下载<code>hadoop2.6.4</code>的源码包（Hadoop分布式集群安装一文有介绍），同时查看了官方文档对于<em>Native Bulid</em>的需求描述：</p><ul><li>C compiler (e.g. GNU C Compiler)</li><li>GNU Autools Chain: autoconf, automake, libtool</li><li>zlib-development package (stable version &gt;&#x3D; 1.2.0)</li><li>openssl-development package(e.g. libssl-dev)</li><li>先查询系统是否有这些环境库：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">rpm -qa | grep -E &quot;gcc|autoconf|automake|libtool|libssl-dev&quot;<br></code></pre></td></tr></table></figure><p><code>zlib</code>是有的，版本<code>1.2.3</code>，达到要求，下面开始安装没有的<code>gcc</code>、<code>cmake</code>、<code>autoconf</code>和<code>automake</code>，以及<code>libssl-dev</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">yum install openssl-devel gcc cmake autoconf automake<br></code></pre></td></tr></table></figure><h2 id="libssl-dev"><a href="#libssl-dev" class="headerlink" title="libssl-dev"></a>libssl-dev</h2><p>由于<code>libssl-dev</code>在<code>yum</code>安装时叫<code>openssl-devel</code>，pkgs上的rpm包版本是<code>1.0.2i</code>，但使用命令<code>openssl version</code>查看系统当前<code>openssl</code>的版本是<code>1.0.1e</code>，与要安装的<code>libssl-dev</code>包不符，需要升级<code>openssl</code>，下载openssl源码包编译</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">wget https://www.openssl.org/source/openssl-1.0.2i.tar.gz<br></code></pre></td></tr></table></figure><p>解压，进入目录运行config可执行文件，报错</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">c_zlib.c:25:19: error: zlib.h: No such file or directory<br></code></pre></td></tr></table></figure><p><code>zlib.h</code>不存在，那就是缺少<code>zlib-dev</code>的包，<code>yum install zlib-dev</code>，没有这个包？<code>yum search zlib</code>，原来叫<code>zlib-devel</code>，安装完成后重新运行<code>config</code>，通过，然后<code>make</code>和<code>make install</code></p><p>完成后查看版本，<code>openssl version</code>，版本居然还是<code>1.0.1e</code>，哪里不对，翻上去看看<code>make install</code>时的输出，有下面一段：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs text">created directory `/usr/local/ssl/bin’<br>created directory `/usr/local/ssl/lib’<br>created directory `/usr/local/ssl/lib/engines’<br>created directory `/usr/local/ssl/lib/pkgconfig’<br>created directory `/usr/local/ssl/include’<br>created directory `/usr/local/ssl/include/openssl’<br>created directory `/usr/local/ssl/misc’<br>created directory `/usr/local/ssl/certs’<br>created directory `/usr/local/ssl/private’<br></code></pre></td></tr></table></figure><p>哦，原来是安装在<code>/usr/local/ssl</code>目录下了，运行<code>/usr/local/ssl/bin/openssl version</code>，版本是1.0.2i，那好办</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">mv /usr/bin/openssl /usr/bin/openssl.old<br>ln -s /usr/local/ssl/bin/openssl /usr/bin/openssl<br>ln -s /usr/local/ssl/include/openssl /usr/include/openssl<br>echo &#x27;/usr/local/ssl/lib&#x27;&gt;&gt; /etc/ld.so.conf<br>ldconfig -v<br></code></pre></td></tr></table></figure><p>上述命令依次<strong>备份了旧版本的openssl</strong>，但由于<code>/usr/include</code>下没有<code>openssl</code>的头文件库，就不去管它，接着在<code>/usr/bin</code>下创建名为<code>openssl</code>的软连接到<code>/usr/local/ssl/bin/openssl</code>以代替原来的旧版本，<br>同理，头文件库也是。最后别忘了动态共享库，把openssl新的lib路径加到<code>Id.so.conf</code>中，执行<code>Idconfig</code>命令生成缓存，现在再<code>openssl version</code>一下，版本变<code>1.0.2i</code>了。</p><h1 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h1><p>按照官方文档说的，输入以下命令执行编译：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">mvn package -Pdist,native -DskipTests -Dtar<br></code></pre></td></tr></table></figure><p>一看<code>mvn</code>命令，<strong>maven环境</strong>的安装也就不多说了。</p><p>再次运行编译。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">[ERROR] Failed to execute goal org.apache.hadoop:hadoop-maven-plugins:2.6.4:protoc (compile-protoc) on project hadoop-common: org.apache.maven.plugin.MojoExecutionException: ‘protoc –version’ did not return a version -&gt; [Help 1]<br></code></pre></td></tr></table></figure><p>没有<strong>protocol Buffer compiler</strong>，下载一个，在官方github上，我选择了<code>2.6.1</code>版本的<a href="https://github.com/google/protobuf/tree/v2.6.1">https://github.com/google/protobuf/tree/v2.6.1</a></p><p>下载解压后运行<code>./autogen.sh</code></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs text">Google Test not present.  Fetching gtest-1.5.0 from the web…<br>curl: (7) Failed to connect to 2404:6800:4008:c01::52: Network is unreachable<br>bzip2: Compressed file ends unexpectedly;<br>perhaps it is corrupted?  *Possible* reason follows.<br>bzip2: Invalid argument<br>Input file = (stdin), output file = (stdout)<br>It is possible that the compressed file(s) have become corrupted.<br>You can use the -tvv option to test integrity of such files.<br>You can use the `bzip2recover’ program to attempt to recover<br>data from undamaged sections of corrupted files.<br>tar: Child returned status 2<br>tar: Error is not recoverable: exiting now<br></code></pre></td></tr></table></figure><p>打开脚本文件看看是怎么回事。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">if test ! -e gtest; then<br>  echo &quot;Google Test not present.  Fetching gtest-1.5.0 from the web...&quot;<br>  curl http://googletest.googlecode.com/files/gtest-1.5.0.tar.bz2 | tar jx<br>  mv gtest-1.5.0 gtest<br>fi<br></code></pre></td></tr></table></figure><p>浏览器打开这个链接果然是404（挂了代理的），看样子是要下载一个<code>gtest-1.5.0</code>的tar包，上github找找，原来是google test，<a href="https://github.com/google/googletest/tree/release-1.5.0">https://github.com/google/googletest/tree/release-1.5.0</a></p><p>下载这个版本的tar包，解压后将文件夹重命名为<code>gtest</code>（注意是在当前protobuf的目录下），进入make目录输入<code>make</code>编译。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">g++ -I../include -g -Wall -Wextra -c ../samples/sample1.cc<br>make: g++: Command not found<br>make: *** [sample1.o] Error 127<br></code></pre></td></tr></table></figure><p>好吧，缺c++的编译环境，<code>yum install gcc-c++</code> ，再次运行编译，成功。返回protobuf的目录，重新运行<code>autogen.sh</code></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">+ exit 0<br></code></pre></td></tr></table></figure><p>看到结束状态为0，成功。在目录下多了一个<code>configure</code>可执行文件，运行它。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">config.status: creating Makefile<br>config.status: creating scripts/gtest-config<br>config.status: creating build-aux/config.h<br>config.status: executing depfiles commands<br>config.status: executing libtool commands<br></code></pre></td></tr></table></figure><p>最后这几行输出很重要，如果没有可能是前面某环节出错了，此时就可以<code>make</code>了，编译开始，输入<code>make</code>，经过几分钟等待，编译完成。<code>make check</code>下，看到一大堆的<em>OK</em>和<em>PASSED</em>就说明没问题了，<br>现在安装它，<code>make install</code>，完成，返回hadoop的编译，重新执行命令<code>mvn package -Pdist,native -DskipTests -Dtar</code></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">[ERROR] Failed to execute goal org.apache.hadoop:hadoop-maven-plugins:2.6.4:protoc (compile-protoc) on project hadoop-common: org.apache.maven.plugin.MojoExecutionException: protoc version is ‘libprotoc 2.6.1’, expected version is ‘2.5.0’ -&gt; [Help 1]<br></code></pre></td></tr></table></figure><p>WTF？你官方文档也没说啊！</p><p>先去protobuf目录<code>make uninstall</code>，再去下载<code>2.5.0</code>版本的<a href="https://github.com/google/protobuf/archive/v2.5.0.zip">https://github.com/google/protobuf/archive/v2.5.0.zip</a></p><p>好在<code>2.6.1</code>编译时的坑都填了，解压后把原来<code>2.6.1</code>版本的目录下的<code>gtest</code>文件夹拷到<code>2.5.0</code>版本的目录下，依旧是按步骤执行<code>autogen.sh</code> 、<code>configure</code>、 <code>make</code> 、<code>make check</code>、 <code>make install</code></p><p>一切OK，没有任何问题，还是确认一下版本，输入命令<code>protoc --version</code></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">libprotoc 2.5.0<br></code></pre></td></tr></table></figure><p>没问题，再次回到hadoop编译，运行<code>mvn package</code>的命令。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs text">[ERROR] /home/bigdata/hadoop-2.6.4-src/hadoop-common-project/hadoop-nfs/src/main/java/org/apache/hadoop/nfs/nfs3/Nfs3Interface.java:42: warning: no @return<br>[ERROR] public NFS3Response access(XDR xdr, RpcInfo info);<br>[ERROR] ^<br>[ERROR] /home/bigdata/hadoop-2.6.4-src/hadoop-common-project/hadoop-nfs/src/main/java/org/apache/hadoop/nfs/nfs3/Nfs3Interface.java:45: warning: no @param for xdr<br>[ERROR] public NFS3Response readlink(XDR xdr, RpcInfo info);<br>[ERROR] ^<br>[ERROR]<br>[ERROR] Command line was: /usr/local/jdk1.8.0_101/jre/../bin/javadoc @options @packages<br>[ERROR]<br>[ERROR] Refer to the generated Javadoc files in ‘/home/bigdata/hadoop-2.6.4-src/hadoop-common-project/hadoop-nfs/target’ dir.<br>[ERROR] -&gt; [Help 1]<br>[ERROR]<br>[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.<br>[ERROR] Re-run Maven using the -X switch to enable full debug logging.<br>[ERROR]<br>[ERROR] For more information about the errors and possible solutions, please read the following articles:<br>[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException<br>[ERROR]<br>[ERROR] After correcting the problems, you can resume the build with the command<br>[ERROR]   mvn &lt;goals&gt; -rf :hadoop-nfs<br></code></pre></td></tr></table></figure><p>javadoc生成出错？不要了，跳过它，加<code>-Dmaven.javadoc.skip=true</code> 跳过javadoc生成，重新运行编译。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs text">[INFO] ————————————————————————<br>[INFO] BUILD SUCCESS<br>[INFO] ————————————————————————<br>[INFO] Total time: 03:24 h<br>[INFO] Finished at: 2016-09-25T14:55:23+08:00<br>[INFO] Final Memory: 94M/206M<br>[INFO] ————————————————————————<br></code></pre></td></tr></table></figure><p>看到这段，激动不已，终于成功了，到<code>hadoop-dist/target/hadoop-2.6.4/lib/native</code>目录下拷走<strong>native</strong>库到hadoop的<code>native</code>库目录下，然后终于没有警告了，感觉世界清静了呢~</p>]]></content>
    
    
    <categories>
      
      <category>big-data</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>big-data</tag>
      
      <tag>hadoop</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop实战 – Apache访问日志</title>
    <link href="/big-data/hadoop-apache-accesslog/"/>
    <url>/big-data/hadoop-apache-accesslog/</url>
    
    <content type="html"><![CDATA[<p>本示例通过mapreduce计算任务实现对apache访问日志的解析存储和分析，将分析记录存储于HBase数据库中，该示例只是一个日志处理环节，后续处理可进一步扩充。</p><span id="more"></span><h1 id="日志说明"><a href="#日志说明" class="headerlink" title="日志说明"></a>日志说明</h1><p>在apache目录配置文件（<code>/etc/httpd/conf/httpd.conf</code>）中有如下配置：</p><figure class="highlight plaintext"><figcaption><span>httpd.conf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs conf"># The following directives define some format nicknames for use with<br># a CustomLog directive (see below).<br>#<br>LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combined<br>LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b&quot; common<br>LogFormat &quot;%&#123;Referer&#125;i -&gt; %U&quot; referer<br>LogFormat &quot;%&#123;User-agent&#125;i&quot; agent<br># For a single logfile with access, agent, and referer information<br># (Combined Logfile Format), use the following directive:<br>#<br>CustomLog logs/access_log combined<br></code></pre></td></tr></table></figure><p>该配置启用了名为combined的日志格式</p><p>该格式为<code>%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;</code></p><p>以下是官方对这些格式字段的描述：</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>%%</td><td>百分号(Apache2.0.44或更高的版本)</td></tr><tr><td>%a</td><td>远端IP地址</td></tr><tr><td>%A</td><td>本机IP地址</td></tr><tr><td>%B</td><td>除HTTP头以外传送的字节数</td></tr><tr><td>%b</td><td>以CLF格式显示的除HTTP头以外传送的字节数，也就是当没有字节传送时显示’-‘而不是0。</td></tr><tr><td>%{Foobar}C</td><td>在请求中传送给服务端的cookieFoobar的内容。</td></tr><tr><td>%D</td><td>服务器处理本请求所用时间，以微为单位。</td></tr><tr><td>%{FOOBAR}e</td><td>环境变量FOOBAR的值</td></tr><tr><td>%f</td><td>文件名</td></tr><tr><td>%h</td><td>远端主机</td></tr><tr><td>%H</td><td>请求使用的协议</td></tr><tr><td>%{Foobar}i</td><td>发送到服务器的请求头Foobar:的内容。</td></tr><tr><td>%l</td><td>远端登录名(由identd而来，如果支持的话)，除非IdentityCheck设为”On”，否则将得到一个”-“。</td></tr><tr><td>%m</td><td>请求的方法</td></tr><tr><td>%{Foobar}n</td><td>来自另一个模块的注解Foobar的内容。</td></tr><tr><td>%{Foobar}o</td><td>应答头Foobar:的内容。</td></tr><tr><td>%p</td><td>服务器服务于该请求的标准端口。</td></tr><tr><td>%P</td><td>为本请求提供服务的子进程的PID。</td></tr><tr><td>%{format}P</td><td>服务于该请求的PID或TID(线程ID)，format的取值范围为：pid和tid(2.0.46及以后版本)以及hextid(需要APR1.2.0及以上版本)</td></tr><tr><td>%q</td><td>查询字符串(若存在则由一个”?”引导，否则返回空串)</td></tr><tr><td>%r</td><td>请求的第一行</td></tr><tr><td>%s</td><td>状态。对于内部重定向的请求，这个状态指的是原始请求的状态，—%&gt;s则指的是最后请求的状态。</td></tr><tr><td>%t</td><td>时间，用普通日志时间格式(标准英语格式)</td></tr><tr><td>%{format}t</td><td>时间，用strftime(3)指定的格式表示的时间。(默认情况下按本地化格式)</td></tr><tr><td>%T</td><td>处理完请求所花时间，以秒为单位。</td></tr><tr><td>%u</td><td>远程用户名(根据验证信息而来；如果返回status(%s)为401，可能是假的)</td></tr><tr><td>%U</td><td>请求的URL路径，不包含查询字符串。</td></tr><tr><td>%v</td><td>对该请求提供服务的标准ServerName。</td></tr><tr><td>%V</td><td>根据UseCanonicalName指令设定的服务器名称。</td></tr><tr><td>%X</td><td>请求完成时的连接状态：X&#x3D; 连接在应答完成前中断。 +&#x3D; 应答传送完后继续保持连接。 -&#x3D; 应答传送完后关闭连接。 (在1.3以后的版本中，这个指令是%c，但这样就和过去的SSL语法：%{var}c冲突了)</td></tr><tr><td>%I</td><td>接收的字节数，包括请求头的数据，并且不能为零。要使用这个指令你必须启用mod_logio模块。</td></tr><tr><td>%O</td><td>发送的字节数，包括请求头的数据，并且不能为零。要使用这个指令你必须启用mod_logio模块。</td></tr></tbody></table><p>从上表可得该日志的格式表示为：</p><ul><li>客户端的IP地址。</li><li>由客户端identd进程判断的RFC1413身份(identity),输出中的符号”-“表示此处的信息无效。</li><li>HTTP认证系统得到的访问该网页的客户标识(userid),如果网页没有设置密码保护，则此项将是”-“。</li><li>服务器完成请求处理时的时间。</li><li>客户的动作\请求的资源\使用的协议。</li><li>服务器返回给客户端的状态码。</li><li>返回给客户端的不包括响应头的字节数.如果没有信息返回，则此项应该是”-“。</li><li>“Referer”请求头。</li><li>“User-Agent”请求头。</li></ul><p>例如：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">103.226.133.67</span> - - <span class="hljs-string">[22/Sep/2016:21:00:39 +0800]</span> <span class="hljs-string">&quot;<span class="hljs-keyword">GET</span> /hbase-distribute/ HTTP/1.1&quot;</span> <span class="hljs-number">200</span> <span class="hljs-number">35477</span> <span class="hljs-string">&quot;-&quot;</span> <span class="hljs-string">&quot;Mozilla/5.0 (Windows NT 10.0; WOW64; rv:48.0) Gecko/20100101 Firefox/48.0&quot;</span><br></code></pre></td></tr></table></figure><h1 id="任务分析"><a href="#任务分析" class="headerlink" title="任务分析"></a>任务分析</h1><p>使用hadoop MapReduce任务解析日志并存入Hbase。</p><h2 id="功能需求"><a href="#功能需求" class="headerlink" title="功能需求"></a>功能需求</h2><ul><li>日志解析</li><li>存储</li><li>分析</li></ul><h2 id="业务步骤"><a href="#业务步骤" class="headerlink" title="业务步骤"></a>业务步骤</h2><ul><li>读取日子记录</li><li>解析日志记录</li><li>存储已解析内容</li><li>读取已解析内容</li><li>分析数据</li><li>存储结果</li></ul><p>如图，分两个mapreduce来完成，第一个只有map用于解析，第二个使用map加载，reduce计数。后续的分析也依赖前面的解析操作。</p><img src="/images/src-hadoop-apache-log-grap.png" class="" title="业务流程" alt="业务流程"><h1 id="HTable表设计"><a href="#HTable表设计" class="headerlink" title="HTable表设计"></a>HTable表设计</h1><p>由于只是存储网站每小时（RowKey）访问流量信息，故只需一个表示数量的列簇，同时，为了网站访问分析（比如热点分析），增加一个列簇表示最大流量的标识（如连接地址、访问IP等）。</p><p>此处是预先设计的HTable结构的层次示意，Table结构如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs text">access-info<br>  |--datetime(key)            #日期时间为RowKey<br>  |    |--counter             #流量计数列簇<br>  |    |    |--page           #页面访问量列<br>  |    |    |--user           #用户访问量列<br>  |    |    |--post           #POST请求量列<br>  |    |    |--get            #GET请求量列<br>  |    |    |--put            #PUT请求量列<br>  |    |    |--delete         #DELETE请求量列<br>  |    |    |--error          #错误解析（一般认为脚本攻击）列<br>  |    |    |--connect<br>  |    |    |--other<br>  |    |    ...<br>  |    |--max                 #最多访问列簇<br>  |    |    |--page           #最多访问页列<br>  |    |    |--ip             #最多IP访问列<br></code></pre></td></tr></table></figure><p>使用命令以创建该表（或在程序中运行创建）</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-string">&#x27;access-info&#x27;</span>,&#123;NAME<span class="hljs-operator">=</span><span class="hljs-operator">&gt;</span><span class="hljs-string">&#x27;counter&#x27;</span>,VERSIONS<span class="hljs-operator">=</span><span class="hljs-operator">&gt;</span><span class="hljs-number">1</span>&#125;,&#123;NAME<span class="hljs-operator">=</span><span class="hljs-operator">&gt;</span><span class="hljs-string">&#x27;max&#x27;</span>,VERSIONS<span class="hljs-operator">=</span><span class="hljs-operator">&gt;</span><span class="hljs-number">10</span>&#125;<br></code></pre></td></tr></table></figure><h1 id="编程实现"><a href="#编程实现" class="headerlink" title="编程实现"></a>编程实现</h1><h2 id="初始部分"><a href="#初始部分" class="headerlink" title="初始部分"></a>初始部分</h2><p><strong>日志记录在整个分析中，起到POJO的作用，因此先封装一个日志记录对象</strong></p><figure class="highlight java"><figcaption><span>LogRecord.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">LogRecord</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">SimpleDateFormat</span> <span class="hljs-variable">format</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">SimpleDateFormat</span>(<span class="hljs-string">&quot;d/MMM/yy:HH:mm:ss Z&quot;</span>, Locale.ENGLISH);<br>    <span class="hljs-keyword">private</span> String ip;<br>    <span class="hljs-keyword">private</span> String loginName;<br>    <span class="hljs-keyword">private</span> String userName;<br>    <span class="hljs-keyword">private</span> Date dateTime;<br>    <span class="hljs-keyword">private</span> String method;<br>    <span class="hljs-keyword">private</span> String url;<br>    <span class="hljs-keyword">private</span> String protocol;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> stateCode;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">long</span> responseLength;<br>    <span class="hljs-keyword">private</span> String referFrom;<br>    <span class="hljs-keyword">private</span> String userAgent;<br>    <span class="hljs-keyword">private</span> String unhandled;<br>    <span class="hljs-comment">// 以下省去get/set方法</span><br>    <span class="hljs-comment">// ...</span><br>&#125;<br></code></pre></td></tr></table></figure><p>代码定义了日志记录的每一个元素属性，为了便于日期格式的转换，静态定义了一个私有<code>SimpleDateFormat</code>，同时额外增加了一个<code>unhandled</code>属性用于存储异常的格式解析。</p><p><strong>日志的解析首先应该想到字符串的截取操作，匹配模式，对，就是正则表达式</strong></p><figure class="highlight java"><figcaption><span>LogAnalyser.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">LogAnalyser</span> &#123;<br>    <span class="hljs-comment">/*</span><br><span class="hljs-comment">    正则的一些说明</span><br><span class="hljs-comment">    ^ :匹配每一行的开头。</span><br><span class="hljs-comment">    ^([0-9.]+)\s :匹配IP地址，\s匹配不可见字符，例如空格、制表符等。</span><br><span class="hljs-comment">    ([\w.&quot;-]+)\s :匹配identity，由下划线在内的任何单词字符（包括数字）或点引号杠组成。</span><br><span class="hljs-comment">    ([\w.&quot;-]+)\s :匹配userid。</span><br><span class="hljs-comment">    \[([^\[\]]+)\]\s :匹配时间，匹配外围的中括号且内部不存在中括号。</span><br><span class="hljs-comment">    &quot;(.+)&quot;\s :匹配请求信息，匹配外围双引号，匹配内部任意字符。</span><br><span class="hljs-comment">    (\d&#123;3&#125;)\s :匹配状态码，三个长度的数字。</span><br><span class="hljs-comment">    (\d+|-)\s :匹配响应字节数或-。</span><br><span class="hljs-comment">    &quot;((?:[^&quot;]|\&quot;-)*)&quot;\s :匹配&quot;Referer&quot;请求头，双引号中可能出现转义的双引号\&quot;。</span><br><span class="hljs-comment">    &quot;((?:[^&quot;]|\&quot;-)*)&quot; :匹配&quot;User-Agent&quot;请求头。</span><br><span class="hljs-comment">    $ :匹配行尾。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">regx</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;^([0-9.]+)\\s([\\w.\&quot;-]+)\\s([\\w.\&quot;-]+)\\s\\[([^\\[\\]]+)\\]\\s\&quot;(.+)\&quot;\\s(\\d&#123;3&#125;)\\s(\\d+|-)\\s\&quot;((?:[^\&quot;]|\\\&quot;-)*)\&quot;\\s\&quot;((?:[^\&quot;]|\\\&quot;-)*)\&quot;$&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">Pattern</span> <span class="hljs-variable">pattern</span> <span class="hljs-operator">=</span> Pattern.compile(regx);<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> LogRecord <span class="hljs-title function_">read</span><span class="hljs-params">(String source)</span>&#123;<br>        <span class="hljs-type">Matcher</span> <span class="hljs-variable">matcher</span> <span class="hljs-operator">=</span> pattern.matcher(source);<br>        <span class="hljs-keyword">if</span>(!matcher.matches()|| matcher.groupCount()!=<span class="hljs-number">9</span>)&#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">IllegalArgumentException</span>(<span class="hljs-string">&quot;error input format, source is : &quot;</span>+source);<br>        &#125;<span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-type">LogRecord</span> <span class="hljs-variable">record</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">LogRecord</span>();<br>            record.setIp(matcher.group(<span class="hljs-number">1</span>));<br>            record.setLoginName(matcher.group(<span class="hljs-number">2</span>).replaceAll(<span class="hljs-string">&quot;-&quot;</span>,<span class="hljs-string">&quot;&quot;</span>));<br>            record.setUserName(matcher.group(<span class="hljs-number">3</span>).replaceAll(<span class="hljs-string">&quot;-&quot;</span>,<span class="hljs-string">&quot;&quot;</span>));<br>            record.setDateTime(matcher.group(<span class="hljs-number">4</span>));<br>            String[] tmp = matcher.group(<span class="hljs-number">5</span>).split(<span class="hljs-string">&quot; &quot;</span>);<br>            <span class="hljs-keyword">if</span>(tmp.length!=<span class="hljs-number">3</span>)&#123;<br>                record.setUrl(matcher.group(<span class="hljs-number">5</span>));<br>                <span class="hljs-comment">//throw new IllegalArgumentException(&quot;the %r (RequestHeader) format error, source is : &quot;+source);</span><br>            &#125;<span class="hljs-keyword">else</span> &#123;<br>                record.setMethod(tmp[<span class="hljs-number">0</span>]);<br>                record.setUrl(tmp[<span class="hljs-number">1</span>]);<br>                record.setProtocol(tmp[<span class="hljs-number">2</span>]);<br>            &#125;<br>            record.setStateCode(Integer.parseInt(matcher.group(<span class="hljs-number">6</span>).replace(<span class="hljs-string">&#x27;-&#x27;</span>,<span class="hljs-string">&#x27;0&#x27;</span>)));<br>            record.setResponseLength(Long.parseLong(matcher.group(<span class="hljs-number">7</span>).replace(<span class="hljs-string">&#x27;-&#x27;</span>,<span class="hljs-string">&#x27;0&#x27;</span>)));<br>            record.setReferFrom(matcher.group(<span class="hljs-number">8</span>));<br>            record.setUserAgent(matcher.group(<span class="hljs-number">9</span>));<br>            <span class="hljs-keyword">return</span> record;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>如上代码，通过<strong>正则表达式匹配</strong>，获取各匹配组，按顺序赋值到日志记录对象。但注意，此处有坑，如果正则表达式效率不高，则会在一些匹配组长度上出现堆栈溢出，了解正则匹配原理后对正则表达式优化才能解决该问题。但实际问题实际对待，由于日志记录的解析操作仅仅是字符串的拆分，如果没有很优秀的正则技巧，考虑字符串截取处理会更高效，针对该日志类型，记录字符串起始段有固定格式（<code>主机IP</code>、<code>标识</code>、<code>用户</code>、<code>固定格式的时间</code>），而中间段（<code>请求信息</code>）具有不确定性，因为在大量日志记录分析中看到，该段内容一般为较长且包含大量不规则字符（包括各种符号）的连接，也有可能为一堆脚本（站点扫描、检测、攻击等），但比起尾段（<code>状态码</code>、<code>字节数</code>、<code>Refer</code>、<code>User-Agent</code>）更加具有不可预见性，所以在字符串截取时应该优先处理格式可知的字段，从两端向中间截取，最后剩下不可预知的中间段，对其单独处理即可。</p><p><strong>解析后的数据如何存储？</strong></p><p>需要按时段分析，每小时的网站流量，那么利用mapreduce的<em>shuffle</em>按时间（精确到小时）排序存储即可，所以键确定就是时间字段，值则是解析结果。对于结果的存储，由于结果是一个PO对象，可以考虑序列化存储，使用<em>BytesWritable</em>？可以考虑，但我更倾向于封装适合自己的，于是新建一个<code>LogRecordWritable</code>，实现<code>Writable</code>接口即可，序列化使用protostuff，比protobuf使用简单，尤其是不用自己写schema。</p><figure class="highlight java"><figcaption><span>LogRecordWritable.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">LogRecordWritable</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Writable</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> RuntimeSchema&lt;LogRecord&gt; schema = RuntimeSchema.createFrom(LogRecord.class);<br>    <span class="hljs-keyword">private</span> LogRecord record;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">BytesWritable</span> <span class="hljs-variable">data</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">BytesWritable</span>();<br>    <span class="hljs-keyword">public</span> LogRecord <span class="hljs-title function_">getRecord</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> record;<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">read</span><span class="hljs-params">(<span class="hljs-type">byte</span>[] data)</span>&#123;<br>        record = schema.newMessage();<br>        ProtostuffIOUtil.mergeFrom(data,record,schema);<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">setRecord</span><span class="hljs-params">(LogRecord record)</span> &#123;<br>        <span class="hljs-built_in">this</span>.record = record;<br>    &#125;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">write</span><span class="hljs-params">(DataOutput dataOutput)</span> <span class="hljs-keyword">throws</span> IOException &#123;<br>        <span class="hljs-type">byte</span>[] data = ProtostuffIOUtil.toByteArray(record,schema, LinkedBuffer.allocate(LinkedBuffer.DEFAULT_BUFFER_SIZE));<br>        <span class="hljs-built_in">this</span>.data.set(data,<span class="hljs-number">0</span>,data.length);<br>        <span class="hljs-built_in">this</span>.data.write(dataOutput);<br>    &#125;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">readFields</span><span class="hljs-params">(DataInput dataInput)</span> <span class="hljs-keyword">throws</span> IOException &#123;<br>        <span class="hljs-built_in">this</span>.data.readFields(dataInput);<br>        <span class="hljs-built_in">this</span>.data.setCapacity(<span class="hljs-built_in">this</span>.data.getLength());<br>        <span class="hljs-type">byte</span>[] data = <span class="hljs-built_in">this</span>.data.getBytes();<br>        record = schema.newMessage();<br>        ProtostuffIOUtil.mergeFrom(data,record,schema);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>巨坑预警</strong>，使用序列化的数据写入<code>DataOutput</code>和读取<code>DataInput</code>会出现数据不一致的情况，读取数据明显会比写入的多，需要先<code>setCapacity</code>再读取字节反序列化，原因参考接口的实现类（<code>DataInputStram</code>）源码，这里就不废话了。</p><h2 id="解析存储"><a href="#解析存储" class="headerlink" title="解析存储"></a>解析存储</h2><p>第一个mapreduce任务，只有mapper，将一条条的字符串记录解析为日期时间和LogRecordWritable的键值对，存储为序列化文件（便于压缩处理和传输）</p><figure class="highlight java"><figcaption><span>Extracter.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ExtractMapper</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">Mapper</span>&lt;Object, Text, Text, LogRecordWritable&gt; &#123;<br>        <span class="hljs-keyword">final</span> <span class="hljs-type">SimpleDateFormat</span> <span class="hljs-variable">format</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">SimpleDateFormat</span>(<span class="hljs-string">&quot;yyyy-MM-dd-HH&quot;</span>);<br>        <span class="hljs-type">LogRecordWritable</span> <span class="hljs-variable">logRecordWritable</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">LogRecordWritable</span>();<br>        <span class="hljs-type">Text</span> <span class="hljs-variable">date</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Text</span>();<br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">map</span><span class="hljs-params">(Object key, Text value, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException &#123;<br>            <span class="hljs-type">String</span> <span class="hljs-variable">source</span> <span class="hljs-operator">=</span> value.toString();<br>            <span class="hljs-keyword">if</span> (source != <span class="hljs-literal">null</span> &amp;&amp; source.length() &gt; <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-keyword">try</span> &#123;<br>                    <span class="hljs-type">LogRecord</span> <span class="hljs-variable">record</span> <span class="hljs-operator">=</span> LogAnalyser.read(source);<br>                    date.set(format.format(record.getDateTime()));<br>                    logRecordWritable.setRecord(record);<br>                &#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>                    <span class="hljs-type">LogRecord</span> <span class="hljs-variable">record</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">LogRecord</span>();<br>                    record.setUnhandled(source);<br>                    logRecordWritable.setRecord(record);<br>                    date.clear();<br>                    date.set(<span class="hljs-string">&quot;error&quot;</span>);<br>                &#125;<br>                context.write(date, logRecordWritable);<br>            &#125;<br>        &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>使用精确到小时的时间字符串格式，这里要考虑其他情况，比如脚本攻击产生的访问记录就有点不规则，归类到error列。</p><h2 id="分析存储"><a href="#分析存储" class="headerlink" title="分析存储"></a>分析存储</h2><p>第二个mapreduce任务，mapper加载上一个任务解析的结果，reducer统计流量数并存储到HBase数据库</p><figure class="highlight java"><figcaption><span>Loader.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">LoadMapper</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">Mapper</span>&lt;Text, LogRecordWritable, Text, LogRecordWritable&gt; &#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">map</span><span class="hljs-params">(Text key, LogRecordWritable value, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException &#123;<br>        context.write(key,value);<br>    &#125;<br>&#125;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">CounterReducer</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">TableReducer</span>&lt;Text, LogRecordWritable, ImmutableBytesWritable&gt;&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">reduce</span><span class="hljs-params">(Text key, Iterable&lt;LogRecordWritable&gt; values, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException &#123;<br>        Map&lt;String,Integer&gt; count = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;String, Integer&gt;();<br>        Map&lt;String,Integer&gt; users = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;String, Integer&gt;();<br>        Map&lt;String,Integer&gt; pages = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;String, Integer&gt;();<br>        <span class="hljs-type">int</span> pv=<span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(LogRecordWritable writable:values)&#123;<br>            String mk=<span class="hljs-literal">null</span>;<br>            <span class="hljs-type">LogRecord</span> <span class="hljs-variable">record</span> <span class="hljs-operator">=</span> writable.getRecord();<br>            <span class="hljs-keyword">if</span>(record.getUnhandled()!=<span class="hljs-literal">null</span>)&#123;<br>                mk=<span class="hljs-string">&quot;error&quot;</span>;<br>            &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(record.getUrl().startsWith(<span class="hljs-string">&quot;/&quot;</span>))&#123;<br>                users.put(record.getIp(),users.get(record.getIp())!=<span class="hljs-literal">null</span>?(users.get(record.getIp())+<span class="hljs-number">1</span>):<span class="hljs-number">1</span>);<br>                pages.put(record.getUrl(),pages.get(record.getUrl())!=<span class="hljs-literal">null</span>?(pages.get(record.getUrl())+<span class="hljs-number">1</span>):<span class="hljs-number">1</span>);<br>                mk=record.getMethod()!=<span class="hljs-literal">null</span>?record.getMethod().toLowerCase():<span class="hljs-literal">null</span>;<br>                pv++;<br>            &#125;<span class="hljs-keyword">else</span> &#123;<br>                mk=<span class="hljs-string">&quot;other&quot;</span>;<br>            &#125;<br>            count.put(mk,count.get(mk)!=<span class="hljs-literal">null</span>?(count.get(mk)+<span class="hljs-number">1</span>):<span class="hljs-number">1</span>);<br>        &#125;<br>        <span class="hljs-type">Put</span> <span class="hljs-variable">put</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Put</span>(key.getBytes());<br>        <span class="hljs-keyword">for</span>(String column : count.keySet())&#123;<br>            <span class="hljs-keyword">if</span>(column!=<span class="hljs-literal">null</span>)&#123;<br>                put.addColumn(Bytes.toBytes(<span class="hljs-string">&quot;counter&quot;</span>),Bytes.toBytes(column),Bytes.toBytes(String.valueOf(count.get(column))));<br>            &#125;<br>        &#125;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">uv</span> <span class="hljs-operator">=</span> users.size();<br>        put.addColumn(Bytes.toBytes(<span class="hljs-string">&quot;counter&quot;</span>),Bytes.toBytes(<span class="hljs-string">&quot;user&quot;</span>),Bytes.toBytes(String.valueOf(uv)));<br>        put.addColumn(Bytes.toBytes(<span class="hljs-string">&quot;counter&quot;</span>),Bytes.toBytes(<span class="hljs-string">&quot;page&quot;</span>),Bytes.toBytes(String.valueOf(pv)));<br>        put.addColumn(Bytes.toBytes(<span class="hljs-string">&quot;max&quot;</span>),Bytes.toBytes(<span class="hljs-string">&quot;page&quot;</span>),Bytes.toBytes(max(pages)));<br>        put.addColumn(Bytes.toBytes(<span class="hljs-string">&quot;max&quot;</span>),Bytes.toBytes(<span class="hljs-string">&quot;ip&quot;</span>),Bytes.toBytes(max(users)));<br>        context.write(<span class="hljs-keyword">new</span> <span class="hljs-title class_">ImmutableBytesWritable</span>(key.getBytes()),put);<br>    &#125;<br>    <span class="hljs-keyword">private</span> String <span class="hljs-title function_">max</span><span class="hljs-params">(Map&lt;String,Integer&gt; map)</span>&#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">val</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">max</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;-&quot;</span>;<br>        <span class="hljs-keyword">for</span>(String key:map.keySet())&#123;<br>             <span class="hljs-keyword">if</span>(map.get(key)&gt;val)&#123;<br>                val = map.get(key);<br>                max = key;<br>             &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> max;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>此处有坑</strong>，将结果统一转换为字符串再转Bytes存储，否则就需要区别对待，直接全<code>Bytes.toString()</code>是不行的。</p><h2 id="主函数实现"><a href="#主函数实现" class="headerlink" title="主函数实现"></a>主函数实现</h2><figure class="highlight java"><figcaption><span>Parser.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;<br>        properties = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Properties</span>();<br>        <span class="hljs-keyword">try</span> &#123;<br>            properties.load(Parser.class.getClassLoader().getResourceAsStream(<span class="hljs-string">&quot;conf.properties&quot;</span>));<br>        &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;<br>            logger.error(e.getMessage(),e);<br>            System.exit(<span class="hljs-number">1</span>);<br>        &#125;<br>        <span class="hljs-type">Configuration</span> <span class="hljs-variable">conf</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Configuration</span>();<br>        conf.set(<span class="hljs-string">&quot;fs.defaultFS&quot;</span>,properties.getProperty(<span class="hljs-string">&quot;fs.defaultFS&quot;</span>));<br>        conf.set(<span class="hljs-string">&quot;hbase.zookeeper.quorum&quot;</span>,  properties.getProperty(<span class="hljs-string">&quot;hbase.zookeeper.quorum&quot;</span>));<br>        <span class="hljs-keyword">if</span>(args.length&gt;<span class="hljs-number">1</span>) &#123;<br>            <span class="hljs-type">Job</span> <span class="hljs-variable">analysis</span> <span class="hljs-operator">=</span> Job.getInstance(conf);<br>            analysis.setMapperClass(Extracter.ExtractMapper.class);<br>            analysis.setOutputKeyClass(Text.class);<br>            analysis.setOutputValueClass(LogRecordWritable.class);<br>            analysis.setJarByClass(Parser.class);<br>            analysis.setOutputFormatClass(SequenceFileOutputFormat.class);<br>            analysis.setNumReduceTasks(<span class="hljs-number">0</span>);<br>            FileInputFormat.addInputPath(analysis, <span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(args[<span class="hljs-number">0</span>]));<br>            FileOutputFormat.setOutputPath(analysis, <span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(args[<span class="hljs-number">1</span>]));<br>            <span class="hljs-type">Job</span> <span class="hljs-variable">counter</span> <span class="hljs-operator">=</span> Job.getInstance(conf);<br>            counter.setMapperClass(Extracter.LoadMapper.class);<br>            counter.setMapOutputKeyClass(Text.class);<br>            counter.setMapOutputValueClass(LogRecordWritable.class);<br>            counter.setJarByClass(Parser.class);<br>            counter.setInputFormatClass(SequenceFileInputFormat.class);<br>            counter.setNumReduceTasks(<span class="hljs-number">1</span>);<br>            TableMapReduceUtil.initTableReducerJob(<span class="hljs-string">&quot;access-info&quot;</span>, Loader.CounterReducer.class, counter);<br>            FileInputFormat.addInputPath(counter, <span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(args[<span class="hljs-number">1</span>]));<br>            <span class="hljs-type">JobControl</span> <span class="hljs-variable">control</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">JobControl</span>(<span class="hljs-string">&quot;apache-log-group&quot;</span>);<br>            <span class="hljs-type">ControlledJob</span> <span class="hljs-variable">job1</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ControlledJob</span>(conf);<br>            job1.setJob(analysis);<br>            job1.setJobName(<span class="hljs-string">&quot;analysis&quot;</span>);<br>            <span class="hljs-type">ControlledJob</span> <span class="hljs-variable">job2</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ControlledJob</span>(conf);<br>            job2.setJob(counter);<br>            job2.setJobName(<span class="hljs-string">&quot;counter&quot;</span>);<br>            job2.addDependingJob(job1);<br>            control.addJob(job1);<br>            control.addJob(job2);<br>            <span class="hljs-type">Thread</span> <span class="hljs-variable">thread</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Thread</span>(control);<br>            thread.start();<br>            <span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) &#123;<br>                <span class="hljs-keyword">if</span> (control.allFinished()) &#123;<br>                    System.out.println(control.getSuccessfulJobList());<br>                    control.stop();<br>                    System.exit(<span class="hljs-number">0</span>);<br>                &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (control.getFailedJobList().size() &gt; <span class="hljs-number">0</span>) &#123;<br>                    System.out.println(control.getFailedJobList());<br>                    control.stop();<br>                    System.exit(<span class="hljs-number">1</span>);<br>                &#125;<br>            &#125;<br>        &#125;<span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-keyword">try</span> &#123;<br>                <span class="hljs-type">String</span> <span class="hljs-variable">tableName</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;access-info&quot;</span>;<br>                <span class="hljs-keyword">if</span>(args.length==<span class="hljs-number">1</span>)&#123;<br>                    tableName = args[<span class="hljs-number">0</span>];<br>                &#125;<br>                <span class="hljs-type">Scan</span> <span class="hljs-variable">scan</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Scan</span>();<br>                scan.setMaxVersions(<span class="hljs-number">10</span>);<br>                <span class="hljs-type">Connection</span> <span class="hljs-variable">connection</span> <span class="hljs-operator">=</span> ConnectionFactory.createConnection(conf);<br>                <span class="hljs-type">HTable</span> <span class="hljs-variable">table</span> <span class="hljs-operator">=</span> (HTable) connection.getTable(TableName.valueOf(tableName));<br>                <span class="hljs-type">ResultScanner</span> <span class="hljs-variable">rsc</span> <span class="hljs-operator">=</span> table.getScanner(scan);<br>                <span class="hljs-keyword">for</span> (Result result : rsc) &#123;<br>                    <span class="hljs-comment">//rowKey</span><br>                    System.out.println(<span class="hljs-string">&quot;- &quot;</span>+Bytes.toString(result.getRow()));<br>                    NavigableMap&lt;<span class="hljs-type">byte</span>[], NavigableMap&lt;<span class="hljs-type">byte</span>[], NavigableMap&lt;Long, <span class="hljs-type">byte</span>[]&gt;&gt;&gt; map = result.getMap();<br>                    <span class="hljs-keyword">for</span> (<span class="hljs-type">byte</span>[] key : map.keySet()) &#123;<br>                        <span class="hljs-comment">//columnFamilies</span><br>                        System.out.println(<span class="hljs-string">&quot;   | &quot;</span> + Bytes.toString(key));<br>                        <span class="hljs-keyword">for</span> (<span class="hljs-type">byte</span>[] tk : map.get(key).keySet()) &#123;<br>                            <span class="hljs-comment">//columns</span><br>                            System.out.println(<span class="hljs-string">&quot;      |-- &quot;</span> + Bytes.toString(tk));<br>                            <span class="hljs-keyword">for</span> (Long l : map.get(key).get(tk).keySet()) &#123;<br>                                <span class="hljs-comment">//values and timestamps</span><br>                                System.out.println(<span class="hljs-string">&quot;        |-- value[&quot;</span> + Bytes.toString(map.get(key).get(tk).get(l)) + <span class="hljs-string">&quot;] (timestamp:&quot;</span> + l + <span class="hljs-string">&quot;)&quot;</span>);<br>                            &#125;<br>                        &#125;<br>                    &#125;<br>                &#125;<br>                rsc.close();<br>            &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;<br>                logger.error(e.getMessage(), e);<br>            &#125;<br>        &#125;<br> &#125;<br></code></pre></td></tr></table></figure><p>在主方法中加入了扫描HTable的程序片，完全出于调试的目的，当然可以将其单独写一个方法从Main方法中拿出来，但记得第二个mapreduce任务mapper和reducer输入输出类型不一致，必须设置<code>MapOutPutKey/ValueClass</code>。还可以对输出的序列化文件进行压缩，设置压缩类型和算法，例如按记录压缩，使用Gzip压缩算法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java">SequenceFileOutputFormat.setOutputCompressionType(analysis, SequenceFile.CompressionType.RECORD);<br>SequenceFileOutputFormat.setOutputCompressorClass(analysis, GzipCodec.class);<br></code></pre></td></tr></table></figure><h1 id="运行测试"><a href="#运行测试" class="headerlink" title="运行测试"></a>运行测试</h1><p>打包并上传到hadoop集群运行（记得HBase得有）：</p><img src="/images/src-hadoop-apache-log-submit-job.png" class="" title="提交运行作业" alt="提交运行作业"><p>在RM管理页查看Application的运行：</p><img src="/images/src-hadoop-apache-log-watcher.png" class="" title="RM管理" alt="RM管理"><p>在HBase Shell中查看表数据记录数：</p><img src="/images/src-hadoop-apache-log-habse-count.png" class="" title="表数据量" alt="表数据量"><p>运行表扫描功能，将输出重定向到文件，运行结束后打开文件查看有层次结构的数据：</p><img src="/images/src-hadoop-apache-og-result.png" class="" title="表扫描结果" alt="表扫描结果"><p>最后：在实际环境中，数据量很大的情况下应该注意热点写的问题，使用<code>RowKey散列</code>和<code>预分区</code>。</p><h1 id="附"><a href="#附" class="headerlink" title="附"></a>附</h1><p>maven项目依赖：</p><figure class="highlight xml"><figcaption><span>pom.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">properties</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">hadoop.version</span>&gt;</span>2.6.4<span class="hljs-tag">&lt;/<span class="hljs-name">hadoop.version</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">hbase.version</span>&gt;</span>1.2.2<span class="hljs-tag">&lt;/<span class="hljs-name">hbase.version</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">properties</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>junit<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>junit<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>4.11<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-comment">&lt;!--HBase--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>commons-io<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>commons-io<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.4<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>commons-logging<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>commons-logging<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.1.3<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>log4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>log4j<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.2.17<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hbase<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hbase-client<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;hbase.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.google.protobuf<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>protobuf-java<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.5.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>io.netty<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>netty<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.7.0.Final<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hbase<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hbase-common<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;hbase.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hbase<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hbase-protocol<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;hbase.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.zookeeper<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>zookeeper<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.4.6<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.cloudera.htrace<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>htrace-core<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.04<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.codehaus.jackson<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>jackson-mapper-asl<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.9.13<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.codehaus.jackson<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>jackson-core-asl<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.9.13<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.codehaus.jackson<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>jackson-jaxrs<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.9.13<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.codehaus.jackson<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>jackson-xc<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.9.13<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.slf4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>slf4j-api<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.7.6<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.slf4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>slf4j-log4j12<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.7.5<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hbase<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hbase-server<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.2.2<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">exclusions</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-hdfs<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">exclusions</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-comment">&lt;!--Hadoop--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-client<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>commons-configuration<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>commons-configuration<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.6<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-auth<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-common<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- Protostuff高效序列化 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.dyuproject.protostuff<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>protostuff-core<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.0.8<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.dyuproject.protostuff<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>protostuff-runtime<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.0.8<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>big-data</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>distribution</tag>
      
      <tag>big-data</tag>
      
      <tag>hadoop</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用脚本监控服务状态</title>
    <link href="/python/service-watcher-by-shell/"/>
    <url>/python/service-watcher-by-shell/</url>
    
    <content type="html"><![CDATA[<p>通过shell脚本和定时任务实现服务的状态监控，并在服务状态异常时通报运维人员，当然这只是一个十分简单的脚本实现，可在此脚本基础上增加系统资源预警的功能。</p><span id="more"></span><h1 id="编写思路"><a href="#编写思路" class="headerlink" title="编写思路"></a>编写思路</h1><ol><li>既然是对是否启动的检测，也就是对进程是否存在的检测，即判断服务进程是否存在。</li><li>可通过service命令实现，该命令用来获取或管理Linux系统的服务信息，可通过服务名称找到服务的相关信息包括服务状态（或者查找服务进程，通过ps 命令）。</li><li>配合awk命令进行信息筛选过滤，判断服务状态。</li><li>邮件发送可使用linux自带的mail命令，但由于国内各大邮件服务均不再支持普通链接的方式发送，发送邮件需要SSL链接，在<code>/etc/mail.rc</code>中可配置发送方的邮件账号和密码，但至于怎样开启SSL方式，则无人问津，故放弃使用该命令发送邮件。</li><li>可以使用比较流行的Python脚本实现邮件发送。</li></ol><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p><strong>shell脚本编写（以apache和mysql服务为例）：</strong></p><figure class="highlight shell"><figcaption><span>watcher.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">!/bin/sh</span><br>datetime=`date +&#x27;%Y-%m-%d %H:%M:%S&#x27;`<br>proc_http=`/sbin/service httpd status | awk &#x27;$1==&quot;httpd&quot;&#123;if($5==&quot;running...&quot;)&#123;print &quot;ok&quot;&#125;else&#123;print ;&#125;&#125;&#x27;`<br>proc_mysql=`/sbin/service mysqld status | awk &#x27;$1==&quot;mysqld&quot;&#123;if($5==&quot;running...&quot;)&#123;print &quot;ok&quot;&#125;else&#123;print ;&#125;&#125;&#x27;`<br>log=&quot;/root/watcher/service.txt&quot;<br>if [ &quot;$proc_http&quot; != &quot;ok&quot; -o &quot;$proc_mysql&quot; != &quot;ok&quot; ] ; then<br>        msg=&quot;$datetime - the service is abnormal, mysqld is [ $proc_mysql ] and httpd is [ $proc_http ]&quot;<br>        if [ &quot;$proc_http&quot; = &quot;ok&quot; -a &quot;$proc_mysql&quot; != &quot;ok&quot; ] ; then<br>                echo &quot; - keep httpd service stopping now...&quot;<br>                some=`/sbin/service httpd stop | awk &#x27;&#123;print $4&#125;&#x27;`<br>                msg=&quot;$msg and keep the httpd service stopped [ $some ]&quot;<br>        fi<br>        echo &quot;$msg&quot;<br>        if [ -f &quot;$log&quot; ] ; then<br>                echo &quot; - the last error file exist, skip this time.&quot;<br>        else<br>                echo &quot;$msg&quot; &gt; &quot;$log&quot;<br>                python /root/watcher/mail.py &gt;&gt; /root/watcher/mail.log 2&gt;&amp;1<br>        fi<br>else<br>        if [ -f &quot;$log&quot; ] ; then<br>                echo &quot;$datetime - found error file, clean up ...[ $log ]&quot;<br>                rm -f &quot;$log&quot;<br>        fi<br>fi<br></code></pre></td></tr></table></figure><p><strong>编写Python脚本用以发送邮件</strong></p><figure class="highlight python"><figcaption><span>mail.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#!/usr/bin/python</span><br><span class="hljs-keyword">import</span> email<br><span class="hljs-keyword">import</span> mimetypes<br><span class="hljs-keyword">from</span> email.MIMEMultipart <span class="hljs-keyword">import</span> MIMEMultipart<br><span class="hljs-keyword">from</span> email.MIMEText <span class="hljs-keyword">import</span> MIMEText<br><span class="hljs-keyword">from</span> email.MIMEImage <span class="hljs-keyword">import</span> MIMEImage<br><span class="hljs-keyword">import</span> smtplib<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sendEmail</span>(<span class="hljs-params">authInfo, fromAdd, toAdd, subject, plainText</span>):<br>        strFrom = fromAdd<br>        strTo = toAdd<br>        server = authInfo.get(<span class="hljs-string">&#x27;server&#x27;</span>)<br>        user = authInfo.get(<span class="hljs-string">&#x27;user&#x27;</span>)<br>        passwd = authInfo.get(<span class="hljs-string">&#x27;password&#x27;</span>)<br>        sslPort = <span class="hljs-string">&#x27;465&#x27;</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> (server <span class="hljs-keyword">and</span> user <span class="hljs-keyword">and</span> passwd) :<br>                <span class="hljs-built_in">print</span> <span class="hljs-string">&#x27;incomplete login info, exit now&#x27;</span><br>                <span class="hljs-keyword">return</span><br>        msgRoot = MIMEMultipart(<span class="hljs-string">&#x27;related&#x27;</span>)<br>        msgRoot[<span class="hljs-string">&#x27;Subject&#x27;</span>] = subject<br>        msgRoot[<span class="hljs-string">&#x27;From&#x27;</span>] = strFrom<br>        msgRoot[<span class="hljs-string">&#x27;To&#x27;</span>] = strTo<br>        msgRoot.preamble = <span class="hljs-string">&#x27;This is a multi-part message in MIME format.&#x27;</span><br>        msgAlternative = MIMEMultipart(<span class="hljs-string">&#x27;alternative&#x27;</span>)<br>        msgRoot.attach(msgAlternative)<br>        msgText = MIMEText(plainText, <span class="hljs-string">&#x27;plain&#x27;</span>, <span class="hljs-string">&#x27;utf-8&#x27;</span>)<br>        msgAlternative.attach(msgText)<br>        <span class="hljs-comment">#smtp = smtplib.SMTP()</span><br>        <span class="hljs-comment">#smtp = smtplib.SMTP(server)</span><br>        smtp = smtplib.SMTP_SSL(server,sslPort)<br>        smtp.ehlo()<br>        smtp.set_debuglevel(<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">try</span>:<br>            smtp.ehlo()<br>            smtp.login(user, passwd)<br>            smtp.sendmail(strFrom, toAdd, msgRoot.as_string())<br>        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>            <span class="hljs-built_in">print</span> e<br>        smtp.close()<br>        <span class="hljs-keyword">return</span><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span> :<br>        authInfo = &#123;&#125;<br>        authInfo[<span class="hljs-string">&#x27;server&#x27;</span>] = <span class="hljs-string">&#x27;smtp.qq.com&#x27;</span><br>        authInfo[<span class="hljs-string">&#x27;user&#x27;</span>] = <span class="hljs-string">&#x27;xxxxxxxx@qq.com&#x27;</span><br>        authInfo[<span class="hljs-string">&#x27;password&#x27;</span>] = <span class="hljs-string">&#x27;xxxxxxxxx&#x27;</span><br>        fromAdd = <span class="hljs-string">&#x27;xxxxxxx@qq.com&#x27;</span><br>        toAdd = <span class="hljs-string">&#x27;yyyyyyyy@yy.yy.com&#x27;</span><br>        subject = <span class="hljs-string">&#x27;apache server error&#x27;</span><br>        file_object = <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;httpdlog.txt&#x27;</span>)<br>        <span class="hljs-keyword">try</span>:<br>            all_the_text = file_object.read()<br>        <span class="hljs-keyword">finally</span>:<br>            file_object.close()<br>        htmlText = all_the_text<br>        sendEmail(authInfo, fromAdd, toAdd, subject, htmlText)<br></code></pre></td></tr></table></figure><h1 id="运行与说明"><a href="#运行与说明" class="headerlink" title="运行与说明"></a>运行与说明</h1><p>如上代码，监控脚本在确认apache服务和mysql服务任意一个出现异常则输出信息到文件中，再通过python命令执行python脚本来发送通知邮件。而当mysql服务异常时则停止运行中的apache服务，对数据予以保护。且为了避免一旦有服务异常则频繁发送通知邮件的情况，在每次发送邮件前确认上次发送的异常状况是否被处理。</p><p>Python脚本通过读取服务监控脚本生成的文件内容为发送内容进行邮件发送，设置好发送方的SMTP服务地址（例如：<code>smtp.qq.com</code>）和用户名（<code>xxxxxxxx@qq.com</code>）及密码（<code>xxxxxxxxxx</code>），同时设置投递目标邮箱地址（<code>yyyyyyyy@yy.yy.com</code>）执行发送。脚本中一行<code>smtp.set_debuglevel(1)</code>用于启用debug模式，该模式下会输出大量运行日志以便对脚本执行进行分析，在实际使用中应该删除这行。</p><h1 id="添加定期任务"><a href="#添加定期任务" class="headerlink" title="添加定期任务"></a>添加定期任务</h1><p>以管理员身份输入命令 <code>crontab –e</code> 编辑定期任务，通过<code>-l</code> 参数选项查看已经编辑好的定期任务。例如每10分钟检查一次（或使用<code>*/10</code>代替<code>0,10,20,30,40,50</code>来实现，差别在于是否一定是正好的时间点，如10分、20分、30分、40分、50分的时候执行）：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">0,10,20,30,40,50 * * * * /root/watcher/watcher.sh &gt;&gt; /root/watcher/log.log 2&gt;/root/watcher/err.log &amp;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>shell</tag>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Storm实时处理 – Nginx访问日志</title>
    <link href="/big-data/storm-nginx-accesslog/"/>
    <url>/big-data/storm-nginx-accesslog/</url>
    
    <content type="html"><![CDATA[<p>此示例工程在上一篇关于Storm集群搭建的博文中提到，运行环境即为Storm+Kafka分布式集群环境，主要应用流式处理，实时解析Nginx访问日志，一般用于PV、UV统计及访问监控。该示例也起到举一反三的作用。Storm常被用于实时分析、在线机器学习、持续计算、分布式远程调用和ETL等领域。</p><span id="more"></span><h1 id="场景描述"><a href="#场景描述" class="headerlink" title="场景描述"></a>场景描述</h1><p>需要实时解析Nginx集群站点的访问日志，以供实时的访问分析、入侵检测、动态调整等。通过Kafka消息队列将新的访问记录传递到Storm集群，从消息队列中消费这些访问记录并解析存储，以供下一步分析。</p><h1 id="场景搭建-x2F-模拟"><a href="#场景搭建-x2F-模拟" class="headerlink" title="场景搭建&#x2F;模拟"></a>场景搭建&#x2F;模拟</h1><p>通过编写shell脚本，动态生成“访问日志”，以模拟此次实践环境。</p><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>取nginx访问日志的记录模板，通过随机数据替换关键部分信息，并将生成的模拟记录追加到文件中。</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><figure class="highlight shell"><figcaption><span>logger.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs shell">int=1<br>while(( $int&lt;=1000000000 ))<br>do<br>        rand=$(date +%N)<br>        ips=$((10#$rand%253+1))<br>        dates=`date +&#x27;%d/%b/%y:%H:%M:%S %z&#x27;`<br>        log=&quot;&#123; \&quot;time_local\&quot;: \&quot;$dates\&quot;, \&quot;remote_addr\&quot;: \&quot;182.92.77.$ips\&quot;, \&quot;remote_user\&quot;: \&quot;-\&quot;, \&quot;body_bytes_sent\&quot;: \&quot;5760\&quot;, \&quot;request_time\&quot;: \&quot;0.005\&quot;, \&quot;status\&quot;: \&quot;200\&quot;, \&quot;request\&quot;: \&quot;GET /jiayouserver/www/index.php\&quot;, \&quot;request_method\&quot;: \&quot;GET\&quot;, \&quot;http_referrer\&quot;: \&quot;-\&quot;, \&quot;body_bytes_sent\&quot;:\&quot;5760\&quot;, \&quot;http_x_forwarded_for\&quot;: \&quot;-\&quot;, \&quot;http_user_agent\&quot;: \&quot;Wget/1.12 (linux-gnu)\&quot; &#125;&quot;<br>        let &quot;int++&quot;<br>        echo $log &gt;&gt; access.log<br>        # echo $log<br>        sleep 1s<br>done<br></code></pre></td></tr></table></figure><p>如上代码，变量<code>rand</code>为当前时间的纳秒数，以此变量为基础生成随机访问IP的主机地址，<code>dates</code>变量则为格式化的当前时间字符串，每秒生成一条记录。由于使用系统时间产生的随机数分布很均匀，在后面的<code>PV</code>、<code>UV</code>统计中，数据会呈现基本持平的状态，可通过增加概率系数调整这一分布水平使得数据看起来更真实。</p><p>以上代码保存为<code>logger.sh</code>文件，使用命令 <code>./logger.sh 2&gt;&amp;1 &amp;</code>运行后台任务模拟nginx服务器。</p><h1 id="着手实现"><a href="#着手实现" class="headerlink" title="着手实现"></a>着手实现</h1><h2 id="通信队列"><a href="#通信队列" class="headerlink" title="通信队列"></a>通信队列</h2><p>在模拟的nginx服务器目录下生成的<em>access.log</em>文件会在每秒追加一条记录。</p><h3 id="创建新话题"><a href="#创建新话题" class="headerlink" title="创建新话题"></a>创建新话题</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">bin/kafka-topics.sh -zookeeper hdfs1:2181,hdfs2:2181,hdfs3:2181 -partitions 1 -replication-factor 1 -topic accesslog -create<br></code></pre></td></tr></table></figure><h3 id="创建生产者"><a href="#创建生产者" class="headerlink" title="创建生产者"></a>创建生产者</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">tail -f ~/accesslog/access.log | bin/kafka-console-producer.sh -broker-list hdfs1:9092,hdfs2:9092,hdfs3:9092 -topic accesslog &amp;<br></code></pre></td></tr></table></figure><h2 id="storm解析"><a href="#storm解析" class="headerlink" title="storm解析"></a>storm解析</h2><p>使用IDEA新建一个Maven项目，在<code>pom.xml</code>中添加以下依赖：</p><figure class="highlight xml"><figcaption><span>pom.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>junit<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>junit<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>4.11<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.storm<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>storm-core<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.0.2<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.storm<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>storm-kafka<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.0.2<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">exclusions</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.kafka<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>kafka-clients<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.slf4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>slf4j-api<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">exclusions</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.kafka<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>kafka_2.10<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>0.10.0.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>compile<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">exclusions</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.zookeeper<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>zookeeper<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>jmxri<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.sun.jmx<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>jms<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>javax.jms<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>jmxtools<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.sun.jdmk<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.slf4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>slf4j-log4j12<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.slf4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>slf4j-api<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>log4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>log4j<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>junit<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>junit<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">exclusions</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.google.code.gson<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>gson<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.2.4<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></td></tr></table></figure><p>分别是<em>单元测试</em>、<em>storm核心依赖包</em>、<em>storm-kafka消息队列依赖包</em>及<em>gson解析包</em>，这些依赖关系中存在较多版本冲突、依赖重复等问题，需要指定剔除部分依赖。</p><p>在国内可能无法下载到相关依赖包（尤其像storm核心包如此庞大的体型），此时需要手动安装该依赖包。以storm的核心包为例：</p><p>使用压缩软件从下载的<em>storm-1.02</em>的安装包中拷出<em>storm-core-1.02.jar</em>文件（在<code>lib</code>目录下）到本地磁盘，例如F盘。</p><p>运行命令行，切换到该jar文件所在目录（为方便），使用以下命令安装jar包到maven仓库：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">mvn install:install-file -DgroupId=org.apache.storm -DartifactId=storm-core -Dversion=1.0.2 -Dfile=storm-core-1.0.2.jar -Dpackaging=jar<br></code></pre></td></tr></table></figure><p>然后重新加载依赖即可。</p><p>编写代码，主要分为四步：</p><ol><li>从Kafka消息队列取消息</li><li>将消息字符串通过Gson解析为PO日志对象，此时可存储数据库（方法简单，不罗嗦了）</li><li>分字段传递消息到下一个Bolt</li><li>分字段统计PV、UV信息</li></ol><p>所以，项目结构如下：</p><img src="/images/src-storm-nginx-idea-project.png" class="" title="项目结构" alt="项目结构"><p>关键代码，主要为两个<strong>Bolt</strong>和主类：</p><figure class="highlight java"><figcaption><span>LogBolt.Java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-type">SimpleDateFormat</span> <span class="hljs-variable">format</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">SimpleDateFormat</span>(<span class="hljs-string">&quot;yyyy-MM-dd HH:mm&quot;</span>);<br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">prepare</span><span class="hljs-params">(Map stormConf, TopologyContext context)</span> &#123;<br>    <span class="hljs-comment">//获取数据库JDBC链接信息</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">mysqlUrl</span> <span class="hljs-operator">=</span> stormConf.get(<span class="hljs-string">&quot;mysql.url&quot;</span>).toString();<br>    <span class="hljs-type">String</span> <span class="hljs-variable">username</span> <span class="hljs-operator">=</span> stormConf.get(<span class="hljs-string">&quot;mysql.username&quot;</span>).toString();<br>    <span class="hljs-type">String</span> <span class="hljs-variable">password</span> <span class="hljs-operator">=</span> stormConf.get(<span class="hljs-string">&quot;mysql.password&quot;</span>).toString();<br>    <span class="hljs-comment">//初始化Mysql连接</span><br>    initConnection(mysqlUrl,username,password);<br>    <span class="hljs-built_in">super</span>.prepare(stormConf, context);<br>&#125;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">execute</span><span class="hljs-params">(Tuple input, BasicOutputCollector collector)</span> &#123;<br>    <span class="hljs-type">String</span> <span class="hljs-variable">line</span> <span class="hljs-operator">=</span> input.getString(<span class="hljs-number">0</span>);<br>    <span class="hljs-keyword">if</span>(line.trim().length()&lt;<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span>;<br>    <span class="hljs-comment">//解析</span><br>    <span class="hljs-type">LogRecord</span> <span class="hljs-variable">record</span> <span class="hljs-operator">=</span> EntityParser.parse(line );<br>    <span class="hljs-comment">//写数据库</span><br>    writeDb(record);<br>    <span class="hljs-comment">//传递至下一个Bolt</span><br>    collector.emit(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Values</span>(format.format(record.getTime_local()),record.getRemote_addr(),String.valueOf(record.getStatus()),<br>            String.valueOf(record.getBody_bytes_sent()),record.getRequest(),record.getHttp_referrer(),record.getHttp_user_agent(),<br>            record.getHttp_x_forwarded_for()));<br>&#125;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">declareOutputFields</span><span class="hljs-params">(OutputFieldsDeclarer declarer)</span> &#123;<br>    declarer.declare(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Fields</span>(<span class="hljs-string">&quot;date&quot;</span>, <span class="hljs-string">&quot;ip&quot;</span>, <span class="hljs-string">&quot;status&quot;</span>, <span class="hljs-string">&quot;body_bytes_sent&quot;</span>,<br>                <span class="hljs-string">&quot;request&quot;</span>, <span class="hljs-string">&quot;http_referer&quot;</span>, <span class="hljs-string">&quot;http_user_agent&quot;</span>, <span class="hljs-string">&quot;http_x_forwarded_for&quot;</span>));<br>&#125;<br></code></pre></td></tr></table></figure><p>在<strong>LogBolt</strong>类中，输出字段统一为字符串，而时间字符串则只保留到分钟，以便于在统计PV、UV时通过时间字符串实现每分钟的统计而非原始的每秒钟的统计。</p><figure class="highlight java"><figcaption><span>CountBlot.Java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> Map&lt;String, Integer&gt; all = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;String, Integer&gt;();<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">execute</span><span class="hljs-params">(Tuple input, BasicOutputCollector collector)</span> &#123;<br>    <span class="hljs-comment">//&quot;date&quot;, &quot;ip&quot;, &quot;status&quot;, &quot;body_bytes_sent&quot;,</span><br>    <span class="hljs-comment">//&quot;request&quot;, &quot;http_referer&quot;, &quot;http_user_agent&quot;, &quot;http_x_forwarded_for&quot;</span><br>    <span class="hljs-type">String</span> <span class="hljs-variable">date</span> <span class="hljs-operator">=</span> input.getStringByField(<span class="hljs-string">&quot;date&quot;</span>);<br>    <span class="hljs-type">String</span> <span class="hljs-variable">ip</span> <span class="hljs-operator">=</span> input.getStringByField(<span class="hljs-string">&quot;ip&quot;</span>);<br>    <span class="hljs-type">String</span> <span class="hljs-variable">status</span> <span class="hljs-operator">=</span> input.getStringByField(<span class="hljs-string">&quot;status&quot;</span>);<br>    <span class="hljs-type">String</span> <span class="hljs-variable">body_bytes_sent</span> <span class="hljs-operator">=</span> input.getStringByField(<span class="hljs-string">&quot;body_bytes_sent&quot;</span>);<br>    <span class="hljs-type">String</span> <span class="hljs-variable">request</span> <span class="hljs-operator">=</span> input.getStringByField(<span class="hljs-string">&quot;request&quot;</span>);<br>    <span class="hljs-type">String</span> <span class="hljs-variable">http_referer</span> <span class="hljs-operator">=</span> input.getStringByField(<span class="hljs-string">&quot;http_referer&quot;</span>);<br>    <span class="hljs-type">String</span> <span class="hljs-variable">http_user_agent</span> <span class="hljs-operator">=</span> input.getStringByField(<span class="hljs-string">&quot;http_user_agent&quot;</span>);<br>    <span class="hljs-type">String</span> <span class="hljs-variable">http_x_forwarded_for</span> <span class="hljs-operator">=</span> input.getStringByField(<span class="hljs-string">&quot;http_x_forwarded_for&quot;</span>);<br>    <span class="hljs-comment">//统计IP的PV/UV</span><br>    countPVUVByIP(date,ip);<br>    <span class="hljs-comment">//还可以统计Status的PV/UV</span><br>    <span class="hljs-comment">//同理</span><br>    <span class="hljs-comment">//进行下一步处理...</span><br>    <span class="hljs-comment">//此处就直接打印结果不做其他处理，可以在输出日志中查看</span><br>    System.out.println(<span class="hljs-string">&quot;======================================================&quot;</span>);<br>    <span class="hljs-keyword">for</span>(String key : all.keySet())&#123;<br>        System.out.println(key+<span class="hljs-string">&quot; = &quot;</span>+all.get(key));<br>    &#125;<br>&#125;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">declareOutputFields</span><span class="hljs-params">(OutputFieldsDeclarer declarer)</span> &#123;&#125;<br><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">countPVUVByIP</span><span class="hljs-params">(String data, String ip)</span>&#123;<br>    <span class="hljs-type">String</span> <span class="hljs-variable">ipkey</span> <span class="hljs-operator">=</span> data+<span class="hljs-string">&quot;_&quot;</span>+ip;<br>    <span class="hljs-type">String</span> <span class="hljs-variable">pvkey</span> <span class="hljs-operator">=</span> data+<span class="hljs-string">&quot;_pv&quot;</span>;<br>    <span class="hljs-type">String</span> <span class="hljs-variable">uvkey</span> <span class="hljs-operator">=</span> data+<span class="hljs-string">&quot;_uv&quot;</span>;<br>    <span class="hljs-type">Integer</span> <span class="hljs-variable">count</span> <span class="hljs-operator">=</span> all.get(ipkey);<br>    <span class="hljs-keyword">if</span>(count==<span class="hljs-literal">null</span>)&#123;<br>        count = <span class="hljs-number">0</span>;<br>    &#125;<br>    all.put(ipkey, ++count);<br>    <span class="hljs-type">Integer</span> <span class="hljs-variable">pv</span> <span class="hljs-operator">=</span> all.get(pvkey);<br>    <span class="hljs-keyword">if</span>(pv==<span class="hljs-literal">null</span>) &#123;<br>        pv = <span class="hljs-number">0</span>;<br>    &#125;<br>    all.put(pvkey,++pv);<br>    <span class="hljs-keyword">if</span>(count&lt;<span class="hljs-number">2</span>)&#123;<br>    <span class="hljs-type">Integer</span> <span class="hljs-variable">uv</span> <span class="hljs-operator">=</span>all.get(uvkey);<br>    <span class="hljs-keyword">if</span>(uv==<span class="hljs-literal">null</span>)&#123;<br>        uv=<span class="hljs-number">0</span>;<br>    &#125;<br>    all.put(uvkey,++uv);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>从上<strong>CountBolt</strong>类代码，可知通过HashMap进行归类统计数量，实时输出。</p><figure class="highlight java"><figcaption><span>ReadLog.Java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>    <span class="hljs-type">Properties</span> <span class="hljs-variable">prop</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Properties</span>();<br>    <span class="hljs-keyword">try</span> &#123;<br>        prop.load(ReadLog.class.getClassLoader().getResourceAsStream(<span class="hljs-string">&quot;config.properties&quot;</span>));<br>    &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;<br>        System.out.println(<span class="hljs-string">&quot;error: missing config.properties&quot;</span>);<br>        e.printStackTrace();<br>        System.exit(<span class="hljs-number">1</span>);<br>    &#125;<br>    <span class="hljs-type">SpoutConfig</span> <span class="hljs-variable">config</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">SpoutConfig</span>(<span class="hljs-keyword">new</span> <span class="hljs-title class_">ZkHosts</span>(prop.getProperty(<span class="hljs-string">&quot;zookeeper.server&quot;</span>)), prop.getProperty(<span class="hljs-string">&quot;kafka.topic&quot;</span>),<span class="hljs-string">&quot;/bigdata/nginx&quot;</span>,<span class="hljs-string">&quot;nginx-access&quot;</span>);<br>    config.scheme = <span class="hljs-keyword">new</span> <span class="hljs-title class_">SchemeAsMultiScheme</span>(<span class="hljs-keyword">new</span> <span class="hljs-title class_">StringScheme</span>());<br>    <span class="hljs-type">TopologyBuilder</span> <span class="hljs-variable">builder</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">TopologyBuilder</span>();<br>    builder.setSpout(<span class="hljs-string">&quot;kafka-spout&quot;</span>, <span class="hljs-keyword">new</span> <span class="hljs-title class_">KafkaSpout</span>(config));<br>    builder.setBolt(<span class="hljs-string">&quot;accesslog-bolt&quot;</span>, <span class="hljs-keyword">new</span> <span class="hljs-title class_">LogBolt</span>()).shuffleGrouping(<span class="hljs-string">&quot;kafka-spout&quot;</span>);<br>    builder.setBolt(<span class="hljs-string">&quot;count-pvuv&quot;</span>,<span class="hljs-keyword">new</span> <span class="hljs-title class_">CountBolt</span>(),<span class="hljs-number">1</span>).shuffleGrouping(<span class="hljs-string">&quot;accesslog-bolt&quot;</span>);<br>    <span class="hljs-type">Config</span> <span class="hljs-variable">stormConfig</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Config</span>();<br>    stormConfig.setNumWorkers(<span class="hljs-number">1</span>);<br>    stormConfig.put(Config.TOPOLOGY_TRIDENT_BATCH_EMIT_INTERVAL_MILLIS, <span class="hljs-number">1000</span>);<br>    stormConfig.setMaxSpoutPending(<span class="hljs-number">10</span>);<br>    stormConfig.put(<span class="hljs-string">&quot;mysql.url&quot;</span>,prop.getProperty(<span class="hljs-string">&quot;mysql.url&quot;</span>));<br>    stormConfig.put(<span class="hljs-string">&quot;mysql.username&quot;</span>,prop.getProperty(<span class="hljs-string">&quot;mysql.username&quot;</span>));<br>    stormConfig.put(<span class="hljs-string">&quot;mysql.password&quot;</span>,prop.getProperty(<span class="hljs-string">&quot;mysql.password&quot;</span>));<br>    String topology_name=prop.getProperty(<span class="hljs-string">&quot;topology.name&quot;</span>);<br>    <span class="hljs-type">StormTopology</span> <span class="hljs-variable">topology</span> <span class="hljs-operator">=</span> builder.createTopology();<br>    <span class="hljs-keyword">if</span>(System.getProperty(<span class="hljs-string">&quot;os.name&quot;</span>).contains(<span class="hljs-string">&quot;Window&quot;</span>))&#123;<br>        <span class="hljs-comment">//Windows环境下本地集群调试</span><br>        <span class="hljs-type">LocalCluster</span> <span class="hljs-variable">cluster</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">LocalCluster</span>();<br>        cluster.submitTopology(topology_name,stormConfig,topology);<br>        <span class="hljs-keyword">try</span> &#123;<br>            Thread.sleep(<span class="hljs-number">600000000L</span>);<br>        &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<br>            e.printStackTrace();<br>        &#125;<br>    &#125;<span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-keyword">try</span> &#123;<br>            StormSubmitter.submitTopology(topology_name,stormConfig,topology);<br>        &#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>            e.printStackTrace();<br>        &#125;<br>    &#125;<br>    System.exit(<span class="hljs-number">0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>主类Main方法中读取并加载配置文件，该文件定义了运行此<em>Topology</em>所需的一些参数，比如Kafka消息主题、mysql连接信息等。</p><p>通过maven打jar包，上传到storm集群，并使用 <code>storm jar &lt;jar文件&gt; &lt;主类&gt; </code>命令提交<em>Topology</em>，成功提交后可在Storm的WebUI查看执行状态：</p><img src="/images/src-stormui-storm-idea-nginx-project.png" class="" title="Topology 状态" alt="Topology 状态">]]></content>
    
    
    <categories>
      
      <category>big-data</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>distribution</tag>
      
      <tag>big-data</tag>
      
      <tag>storm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式集群手操 – HBase搭建</title>
    <link href="/big-data/hbase-distribute-install/"/>
    <url>/big-data/hbase-distribute-install/</url>
    
    <content type="html"><![CDATA[<p>HBase分布式集群搭建的示例，搭建环境以Hive集群搭建为基础，且二者并无直接依赖关系，只是按照搭建顺序而已，请勿误解。搭建过程可参考前几篇集群搭建过程。</p><span id="more"></span><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>Hbase下载解压后，进入配置文件目录：<code>./conf</code>.</p><p>修改<code>hbase-env.sh</code>文件的如下内容：</p><figure class="highlight shell"><figcaption><span>hbase-env.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">The java implementation to use.  Java 1.7+ required.</span><br>export JAVA_HOME=/usr/local/jdk1.8.0_101<br><span class="hljs-meta prompt_"># </span><span class="language-bash">Extra Java CLASSPATH elements.  Optional.</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">加入Hadoop和Zookeeper的配置文件路径</span><br>export HBASE_CLASSPATH=/home/bigdata/services/hadoop-2.6.4/etc/hadoop:/home/bigdata/services/zookeeper-3.4.8/conf<br><span class="hljs-meta prompt_"># </span><span class="language-bash">The directory <span class="hljs-built_in">where</span> pid files are stored. /tmp by default.</span><br>export HBASE_PID_DIR=/home/bigdata/services/hbase-1.2.2/pids<br><span class="hljs-meta prompt_"># </span><span class="language-bash">Tell HBase whether it should manage it<span class="hljs-string">&#x27;s own instance of Zookeeper or not.</span></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-string">使用Zookeeper管理</span></span><br>export HBASE_MANAGES_ZK=false<br></code></pre></td></tr></table></figure><p>修改<code>hbase-site.xml</code>文件的如下内容：</p><figure class="highlight xml"><figcaption><span>hbase-site.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.cluster.distributed<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.rootdir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://hdfs1:9000/hbase<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs1,hdfs2,hdfs3<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.master.info.port<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>60010<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hbase.client.write.buffer<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>4194304<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure><p>修改<code>regionservers</code>文件为如下内容：</p><figure class="highlight text"><figcaption><span>regionservers</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">hdfs2<br>hdfs3<br></code></pre></td></tr></table></figure><p><code>scp</code>配置文件到其他节点主机相应目录即可（<code>scp</code>命令参考前几篇集群搭建过程）。</p><h1 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h1><p>在任意节点使用 <code>bin/start-hbase.sh</code> 启动HBase，启动成功后使用<code>bin/hbase shell</code> 进入HBase命令行，输入<code>status</code>查看集群状态。例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">hbase(main):001:0&gt; status 1 active master, 2 backup masters, 2 servers, 0 dead, 1.0000 average load<br></code></pre></td></tr></table></figure><p>可以在配置文件定义的端口（如：<code>60010</code>）查看管理Web界面。</p><p>至此，按照搭建顺序，<code>Hadoop+Zookeeper+Kafka+Hive+HBase</code>分布式集群环境搭建完毕。</p>]]></content>
    
    
    <categories>
      
      <category>big-data</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>distribution</tag>
      
      <tag>big-data</tag>
      
      <tag>hbase</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式集群手操 – Storm搭建</title>
    <link href="/big-data/storm-distribute-install/"/>
    <url>/big-data/storm-distribute-install/</url>
    
    <content type="html"><![CDATA[<p>Storm分布式集群搭建的示例，搭建环境基于上一篇HBase集群环境后的主机环境，但二者并无直接依赖，Storm集群需要依赖Zookeeper集群，可参见前几篇关于集群搭建的博文。</p><span id="more"></span><h1 id="获取Strom"><a href="#获取Strom" class="headerlink" title="获取Strom"></a>获取Strom</h1><p>通过访问<a href="http://storm.apache.org/downloads.html">Apache Storm官方</a>下载页获取新版本的Storm下载。以下安装以<code>1.02</code>版本为例。</p><p>将下载好的storm上传到虚拟机集群（当然也可以直接使用网络下载相关命令），并解压缩。</p><h1 id="配置Storm"><a href="#配置Storm" class="headerlink" title="配置Storm"></a>配置Storm</h1><p>Storm依赖于Zookeeper，所以必须有Zookeeper集群，同时该版本的Storm需要<em>Java7</em>及<em>Python2.6</em>的运行环境，其他版本的运行环境需求参见官方说明。</p><p>进入storm安装目录下的<code>conf</code>配置文件夹，该目录下一般有以下三个文件：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">storm_env.ini  storm-env.sh  storm.yaml<br></code></pre></td></tr></table></figure><p>做以下配置的修改即可。</p><h3 id="修改storm-yaml文件的如下内容："><a href="#修改storm-yaml文件的如下内容：" class="headerlink" title="修改storm.yaml文件的如下内容："></a>修改storm.yaml文件的如下内容：</h3><figure class="highlight yaml"><figcaption><span>storm.yaml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">storm.zookeeper.servers:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;hdfs1&quot;</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;hdfs2&quot;</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;hdfs3&quot;</span><br><span class="hljs-attr">storm.local.dir:</span> <span class="hljs-string">&quot;/home/bigdata/services/tmp/storm&quot;</span><br><span class="hljs-attr">nimbus.seeds:</span> [<span class="hljs-string">&quot;hdfs1&quot;</span>]<br></code></pre></td></tr></table></figure><p>主要设置了<em>zookeeper集群主机列表</em>、<em>storm本地文件的存储目录</em>及<em>Nimbus节点列表</em>（如果有多台，则在列表中列出[Nimbus H&#x2F;A，1.0的新特性]）</p><p>还可以通过设置<code>supervisor.slots.ports</code>选项控制<em>Supervisor的Worker数量</em>，该选项接受端口列表，默认为4个，例如：<code>nimbus.seeds: [&quot;hdfs1&quot;,&quot;hdfs2&quot;,&quot;hdfs3&quot;]</code>。</p><h3 id="分发配置好的storm安装文件到各节点"><a href="#分发配置好的storm安装文件到各节点" class="headerlink" title="分发配置好的storm安装文件到各节点"></a>分发配置好的storm安装文件到各节点</h3><p>此处使用<code>scp</code>命令，参考前几篇集群搭建过程即可。</p><h1 id="启动Storm"><a href="#启动Storm" class="headerlink" title="启动Storm"></a>启动Storm</h1><ul><li>在Nimbus节点使用命令<code>storm nimbus &amp;</code>启动Nimbus</li><li>在Nimbus节点使用命令<code>storm ui &amp;</code>启动Storm的可视化Web管理容器</li><li>在Supervisor节点使用命令<code>storm supervisor &amp;</code>启动Supervisor</li></ul><p>启动成功后，可以在Nimbus节点<code>8080</code>端口看到storm ui页，如下图：</p><img src="/images/src-stormui-storm.png" class="" title="storm ui" alt="storm ui"><p>至此，Storm集群环境搭建完毕，使用该环境+Kafka集群（参见<a href="/big-data/kafka-distribute-install/" title="分布式集群手操 – Kafka搭建">分布式集群手操 – Kafka搭建</a>）即可进行一次实际演练——<a href="/big-data/storm-nginx-accesslog/" title="Storm实时处理 – Nginx访问日志">Storm实时处理 – Nginx访问日志</a></p>]]></content>
    
    
    <categories>
      
      <category>big-data</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>distribution</tag>
      
      <tag>big-data</tag>
      
      <tag>storm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式集群手操 – Hive搭建</title>
    <link href="/big-data/hive-distribute-install/"/>
    <url>/big-data/hive-distribute-install/</url>
    
    <content type="html"><![CDATA[<p>Hive分布式集群搭建的示例，按照顺序，该搭建环境在Kafka集群搭建环境的基础上，但二者并无直接依赖关系。搭建过程部分可参考前几篇分布式搭建过程（内含部分通用操作提示）</p><span id="more"></span><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>由于我们使用Hive+Mysql为<strong>元数据库</strong>，所以在使用Hive前需配置Mysql数据库，Mysql数据库的安装参见<a href="/mysql/mysql-install-57/" title="MysqlServer的安装部署">《Mysql5.7的安装部署》</a></p><p>仅在<em>hdfs1</em>节点安装了Mysql数据库，其他节点以网络访问的方式访问该主机数据库即可，无需分布式的mysql数据库。</p><p>首先，需要指定数据库和用户权限，我们使用<em>bigdata</em>用户，数据库则为<em>hive</em>数据库，因此需执行以下操作：</p><h2 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h2><p>使用<code>root</code>身份登陆mysql，创建名为<code>hive</code>的数据库：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> database hive;<br></code></pre></td></tr></table></figure><h2 id="创建用户权限"><a href="#创建用户权限" class="headerlink" title="创建用户权限"></a>创建用户权限</h2><p>指定<code>bigdata</code>拥有对<code>hive</code>数据库的所有权限：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">grant</span> <span class="hljs-keyword">all</span> <span class="hljs-keyword">on</span> hive.<span class="hljs-operator">*</span> <span class="hljs-keyword">to</span> bigdata@<span class="hljs-string">&#x27;localhost&#x27;</span> identified <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;abcd1234&#x27;</span>;<br><span class="hljs-keyword">grant</span> <span class="hljs-keyword">all</span> <span class="hljs-keyword">on</span> hive.<span class="hljs-operator">*</span> <span class="hljs-keyword">to</span> bigdata@<span class="hljs-string">&#x27;%&#x27;</span> identified <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;abcd1234&#x27;</span>;<br></code></pre></td></tr></table></figure><p>以上两条命令旨在开启<code>bigdata</code>用户的本地以及网络登陆及对<code>hive</code>数据库的权限控制。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">flush privileges;<br></code></pre></td></tr></table></figure><p>为使Hive能与mysql进行连接，还需要为其添加mysql的<strong>JDBC驱动</strong>，目前为止最新版驱动版本为<code>5.1.37</code>，故将驱动包<code>mysql-connector-java-5.1.37.jar</code>上传到Hive安装目录下的<em>lib</em>文件夹下。</p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>切换到Hive配置文件目录下（<code>./conf</code>），可以看到很多以<code>.template</code>结尾的文件，即配置模板文件，需要将其重命名以去掉该后缀，但为保险起见，使用拷贝命令复制并命名即可（例如：<code>cp hive-env.sh.template hive-env.sh</code>）。</p><h2 id="配置hive-env-sh"><a href="#配置hive-env-sh" class="headerlink" title="配置hive-env.sh"></a>配置hive-env.sh</h2><p>编辑该文件，修改如下内容：</p><figure class="highlight shell"><figcaption><span>hive-env.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">Set HADOOP_HOME to point to a specific hadoop install directory</span><br>HADOOP_HOME=/home/bigdata/services/hadoop-2.6.4<br><span class="hljs-meta prompt_"># </span><span class="language-bash">Hive Configuration Directory can be controlled by:</span><br>export HIVE_CONF_DIR=/home/bigdata/services/apache-hive-2.1.0-bin/conf<br></code></pre></td></tr></table></figure><h2 id="配置hive-site-xml"><a href="#配置hive-site-xml" class="headerlink" title="配置hive-site.xml"></a>配置hive-site.xml</h2><p>重命名<code>hive-default.xml.template</code>为<code>hive-site.xml</code>，修改如下内容：</p><figure class="highlight xml"><figcaption><span>hive-site.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>jdbc:mysql://hdfs1:3306/hive?createDatabaseIfNotExist=true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>JDBC connect string for a JDBC metastore<span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>Driver class name for a JDBC metastore<span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>bigdata<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>username to use against metastore database<span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>123456789vs<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>password to use against metastore database<span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><h1 id="调整"><a href="#调整" class="headerlink" title="调整"></a>调整</h1><p>至此，Hive基本配置完成，<code>scp</code>配置文件到其他节点，然后修改其他节点的配置文件，由于本机<em>hdfs1</em>为Mysql元数据库服务器，同时也是<em>master</em>服务器，因此其他客户端节点需在此配置的基础上修改<code>hive-site.xml</code>如下内容：</p><figure class="highlight xml"><figcaption><span>hive-site.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hive.metastore.uris<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>thrift://hdfs1:9083<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><p>在元数据节点（<em>master</em>节点）运行命令启动元数据存储服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">hive --service metastore &amp;<br></code></pre></td></tr></table></figure><h1 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h1><ul><li>启动元数据存储服务时出现以下错误：</li></ul><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">org.datanucleus.store.rdbms.exceptions.MissingTableException: Required table missing : “`VERSION`” in Catalog “” Schema “”. DataNucleus requires this table to perform its persistence operations. Either your MetaData is incorrect, or you need to enable “datanucleus.schema.autoCreateTables”<br></code></pre></td></tr></table></figure><p>需修改Master节点的<code>hive.site.xml</code>文件的如下配置：</p><figure class="highlight xml"><figcaption><span>hive.site.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>datanucleus.schema.autoCreateAll<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>creates necessary schema on a startup if one doesn&#x27;t exist. set this to false, after creating it once<span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure><ul><li>服务成功运行后就可以使用hive命令进入客户端操作，执行hive命令出现如下错误</li></ul><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">Exception in thread “main” java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: $&#123;system:java.io.tmpdir%7D/$%7Bsystem:user.name%7D<br></code></pre></td></tr></table></figure><p>则需修改所有节点的<code>hive-site.xml</code>文件，查找值含有<code>system:java.io.tmpdir</code>字段，将其替换为指定的绝对路径，例如<code>/tmp/hive/iotmp</code></p><figure class="highlight xml"><figcaption><span>hive.site.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hive.exec.local.scratchdir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/tmp/hive/iotmp<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>Local scratch space for Hive jobs<span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hive.downloaded.resources.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/tmp/hive/iotmp/download<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>Temporary local directory for added resources in the remote file system.<span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure><p>注意：元数据存储服务只需在<em>master</em>节点开启，其他节点无需开启，直接使用<code>hive</code>命令登陆即可</p>]]></content>
    
    
    <categories>
      
      <category>big-data</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>distribution</tag>
      
      <tag>big-data</tag>
      
      <tag>hive</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式集群手操 – Kafka搭建</title>
    <link href="/big-data/kafka-distribute-install/"/>
    <url>/big-data/kafka-distribute-install/</url>
    
    <content type="html"><![CDATA[<p>Kafka分布式集群搭建的示例，该示例搭建环境以Zookeeper集群搭建为基础，且依赖于Zookeeper集群，因此，若未搭建Zookeeper集群请先查阅：<a href="/big-data/zookeeper-distribute-install/" title="分布式集群手操 – Zookeeper搭建">《分布式集群手操 – Zookeeper搭建》</a></p><span id="more"></span><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>下载解压同理，此处不再重复说明。</p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>进入Kafka根目录下的<em>config</em>目录，配置<em>server.properties</em>，主要增加<code>host.name</code>和<code>port</code>配置项以及修改<code>zookeeper.connect</code>配置项，其中<code>host.name</code>为当前主机的主机名，<code>port</code>为<code>9092</code>端口，<code>zookeeper.connect</code>为所有主机的主机地址，中间用逗号隔开，注意一个<code>broker.id</code>配置项，它为当前主机在集群中的唯一标识Id，从<code>0</code>开始，必须保证每台主机的<code>broker.id</code>及<code>host.name</code>唯一。</p><p>配置文件如下：以<em>hdfs1</em>为例，其他节点需做适当修改</p><figure class="highlight properties"><figcaption><span>server.properties</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-comment"># Licensed to the Apache Software Foundation (ASF) under one or more</span><br><span class="hljs-comment"># contributor license agreements.  See the NOTICE file distributed with</span><br><span class="hljs-comment"># this work for additional information regarding copyright ownership.</span><br><span class="hljs-comment"># The ASF licenses this file to You under the Apache License, Version 2.0</span><br><span class="hljs-comment"># (the &quot;License&quot;); you may not use this file except in compliance with</span><br><span class="hljs-comment"># the License.  You may obtain a copy of the License at</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># Unless required by applicable law or agreed to in writing, software</span><br><span class="hljs-comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="hljs-comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="hljs-comment"># See the License for the specific language governing permissions and</span><br><span class="hljs-comment"># limitations under the License.</span><br><span class="hljs-comment"># see kafka.server.KafkaConfig for additional details and defaults</span><br><span class="hljs-comment">############################# Server Basics #############################</span><br><span class="hljs-comment"># The id of the broker. This must be set to a unique integer for each broker.</span><br><span class="hljs-attr">broker.id</span>=<span class="hljs-string">0</span><br><span class="hljs-comment">############################# Socket Server Settings #############################</span><br><span class="hljs-comment"># The address the socket server listens on. It will get the value returned from</span><br><span class="hljs-comment"># java.net.InetAddress.getCanonicalHostName() if not configured.</span><br><span class="hljs-comment">#   FORMAT:</span><br><span class="hljs-comment">#     listeners = security_protocol://host_name:port</span><br><span class="hljs-comment">#   EXAMPLE:</span><br><span class="hljs-comment">#     listeners = PLAINTEXT://your.host.name:9092</span><br><span class="hljs-comment">#listeners=PLAINTEXT://:9092</span><br><span class="hljs-comment"># Hostname and port the broker will advertise to producers and consumers. If not set,</span><br><span class="hljs-comment"># it uses the value for &quot;listeners&quot; if configured.  Otherwise, it will use the value</span><br><span class="hljs-comment"># returned from java.net.InetAddress.getCanonicalHostName().</span><br><span class="hljs-comment">#advertised.listeners=PLAINTEXT://your.host.name:9092</span><br><span class="hljs-attr">port</span>=<span class="hljs-string">9092</span><br><span class="hljs-attr">host.name</span>=<span class="hljs-string">hdfs1</span><br><span class="hljs-comment"># The number of threads handling network requests</span><br><span class="hljs-attr">num.network.threads</span>=<span class="hljs-string">3</span><br><span class="hljs-comment"># The number of threads doing disk I/O</span><br><span class="hljs-attr">num.io.threads</span>=<span class="hljs-string">1</span><br><span class="hljs-comment"># The send buffer (SO_SNDBUF) used by the socket server</span><br><span class="hljs-attr">socket.send.buffer.bytes</span>=<span class="hljs-string">102400</span><br><span class="hljs-comment"># The receive buffer (SO_RCVBUF) used by the socket server</span><br><span class="hljs-attr">socket.receive.buffer.bytes</span>=<span class="hljs-string">102400</span><br><span class="hljs-comment"># The maximum size of a request that the socket server will accept (protection against OOM)</span><br><span class="hljs-attr">socket.request.max.bytes</span>=<span class="hljs-string">104857600</span><br><span class="hljs-comment">############################# Log Basics #############################</span><br><span class="hljs-comment"># A comma seperated list of directories under which to store log files</span><br><span class="hljs-attr">log.dirs</span>=<span class="hljs-string">/home/bigdata/services/tmp/kafka</span><br><span class="hljs-comment"># The default number of log partitions per topic. More partitions allow greater</span><br><span class="hljs-comment"># parallelism for consumption, but this will also result in more files across</span><br><span class="hljs-comment"># the brokers.</span><br><span class="hljs-attr">num.partitions</span>=<span class="hljs-string">1</span><br><span class="hljs-comment"># The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.</span><br><span class="hljs-comment"># This value is recommended to be increased for installations with data dirs located in RAID array.</span><br><span class="hljs-attr">num.recovery.threads.per.data.dir</span>=<span class="hljs-string">1</span><br><span class="hljs-comment">############################# Log Flush Policy #############################</span><br><span class="hljs-comment"># Messages are immediately written to the filesystem but by default we only fsync() to sync</span><br><span class="hljs-comment"># the OS cache lazily. The following configurations control the flush of data to disk.</span><br><span class="hljs-comment"># There are a few important trade-offs here:</span><br><span class="hljs-comment">#    1. Durability: Unflushed data may be lost if you are not using replication.</span><br><span class="hljs-comment">#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.</span><br><span class="hljs-comment">#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to exceessive seeks.</span><br><span class="hljs-comment"># The settings below allow one to configure the flush policy to flush data after a period of time or</span><br><span class="hljs-comment"># every N messages (or both). This can be done globally and overridden on a per-topic basis.</span><br><span class="hljs-comment"># The number of messages to accept before forcing a flush of data to disk</span><br><span class="hljs-comment">#log.flush.interval.messages=10000</span><br><span class="hljs-comment"># The maximum amount of time a message can sit in a log before we force a flush</span><br><span class="hljs-comment">#log.flush.interval.ms=1000</span><br><span class="hljs-comment">############################# Log Retention Policy #############################</span><br><span class="hljs-comment"># The following configurations control the disposal of log segments. The policy can</span><br><span class="hljs-comment"># be set to delete segments after a period of time, or after a given size has accumulated.</span><br><span class="hljs-comment"># A segment will be deleted whenever *either* of these criteria are met. Deletion always happens</span><br><span class="hljs-comment"># from the end of the log.</span><br><span class="hljs-comment"># The minimum age of a log file to be eligible for deletion</span><br><span class="hljs-attr">log.retention.hours</span>=<span class="hljs-string">168</span><br><span class="hljs-comment"># A size-based retention policy for logs. Segments are pruned from the log as long as the remaining</span><br><span class="hljs-comment"># segments don&#x27;t drop below log.retention.bytes.</span><br><span class="hljs-comment">#log.retention.bytes=1073741824</span><br><span class="hljs-comment"># The maximum size of a log segment file. When this size is reached a new log segment will be created.</span><br><span class="hljs-attr">log.segment.bytes</span>=<span class="hljs-string">1073741824</span><br><span class="hljs-comment"># The interval at which log segments are checked to see if they can be deleted according</span><br><span class="hljs-comment"># to the retention policies</span><br><span class="hljs-attr">log.retention.check.interval.ms</span>=<span class="hljs-string">300000</span><br><span class="hljs-comment">############################# Zookeeper #############################</span><br><span class="hljs-comment"># Zookeeper connection string (see zookeeper docs for details).</span><br><span class="hljs-comment"># This is a comma separated host:port pairs, each corresponding to a zk</span><br><span class="hljs-comment"># server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;.</span><br><span class="hljs-comment"># You can also append an optional chroot string to the urls to specify the</span><br><span class="hljs-comment"># root directory for all kafka znodes.</span><br><span class="hljs-attr">zookeeper.connect</span>=<span class="hljs-string">hdfs1:2181,hdfs2:2181,hdfs3:2181</span><br><span class="hljs-comment"># Timeout in ms for connecting to zookeeper</span><br><span class="hljs-attr">zookeeper.connection.timeout.ms</span>=<span class="hljs-string">6000</span><br></code></pre></td></tr></table></figure><p>同时可修改<em>zookeeper.properties</em>文件的<code>dataDir</code>属性项：</p><figure class="highlight properties"><figcaption><span>zookeeper.properties</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-attr">dataDir</span>=<span class="hljs-string">/home/bigdata/services/tmp/kafka/zookeeper</span><br><span class="hljs-comment"># the port at which the clients will connect</span><br><span class="hljs-attr">clientPort</span>=<span class="hljs-string">2181</span><br><span class="hljs-comment"># disable the per-ip limit on the number of connections since this is a non-production config</span><br><span class="hljs-attr">maxClientCnxns</span>=<span class="hljs-string">0</span><br></code></pre></td></tr></table></figure><p>完成<em>server.properties</em>的配置后，使用<code>scp</code>命令分发Kafka目录文件到其他节点主机，然后修改相应的属性保证唯一。</p><h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><p>在Kafka根目录下使用命令启动每台节点上的Kafka</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">nohup ./bin/kafka-server-start.sh config/server.properties &amp;<br></code></pre></td></tr></table></figure><p>启动成功后创建Topic进行测试，例如创建名为<code>mytopic</code>的Topic，然后在<em>hdfs1</em>上创建生产者，<em>hdfs2</em>和<em>hdfs3</em>上创建消费者。</p><ul><li>创建topic</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">./bin/kafka-topics.sh -zookeeper hdfs1:2181,hdfs2:2181,hdfs3:2181 -topic mytopic -replication-factor 1 -partitions 1 -create<br></code></pre></td></tr></table></figure><ul><li>查看topic</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">./bin/kafka-topics.sh -zookeeper hdfs1:2181,hdfs2:2181,hdfs3:2181 -list<br></code></pre></td></tr></table></figure><ul><li>删除topic*</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">./bin/kafka-topics.sh -zookeeper hdfs1:2181,hdfs2:2181,hdfs3:2181 -topic mytopic -delete<br></code></pre></td></tr></table></figure><ul><li>创建生产者</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">./bin/kafka-console-producer.sh -broker-list hdfs1:9092,hdfs2:9092,hdfs3:9092 -topic mytopic<br></code></pre></td></tr></table></figure><ul><li>创建消费者</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">./bin/kafka-console-consumer.sh -zookeeper hdfs1:2181,hdfs2:2181,hdfs3:2181 - from-begining  -topic mytopic<br></code></pre></td></tr></table></figure><p>如果严格按照以上配置，测试是一次通过的，中间不会产生任何警告或错误。</p><p><em>删除Topic并不会立即生效，而是将其标记为待删除，或者可以直接在Zookeeper的文件目录中删除该Topic目录</em></p>]]></content>
    
    
    <categories>
      
      <category>big-data</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>distribution</tag>
      
      <tag>big-data</tag>
      
      <tag>kafka</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式集群手操 – Zookeeper搭建</title>
    <link href="/big-data/zookeeper-distribute-install/"/>
    <url>/big-data/zookeeper-distribute-install/</url>
    
    <content type="html"><![CDATA[<p>Zookeeper的分布式集群搭建示例，搭建环境以Hadoop的集群搭建示例为基础，只是集群系列搭建实例的顺序安排，二者并不存在依赖关系。</p><span id="more"></span><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>安装参考Hadoop集群搭建的Hadoop下载流程，tar.gz文件解压即可，主要过程集中在配置上。</p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>进入Zookeeper配置文件目录（*.&#x2F;conf*）</p><p>拷贝<em>zoo_sample.cfg</em>文件为<em>zoo.cfg</em>文件，并修改该文件的如下内容（添加或修改配置项）：</p><figure class="highlight properties"><figcaption><span>zoo.cfg</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-comment"># The number of milliseconds of each tick</span><br><span class="hljs-attr">tickTime</span>=<span class="hljs-string">2000</span><br><span class="hljs-comment"># The number of ticks that the initial</span><br><span class="hljs-comment"># synchronization phase can take</span><br><span class="hljs-attr">initLimit</span>=<span class="hljs-string">10</span><br><span class="hljs-comment"># The number of ticks that can pass between</span><br><span class="hljs-comment"># sending a request and getting an acknowledgement</span><br><span class="hljs-attr">syncLimit</span>=<span class="hljs-string">5</span><br><span class="hljs-comment"># the directory where the snapshot is stored.</span><br><span class="hljs-comment"># do not use /tmp for storage, /tmp here is just</span><br><span class="hljs-comment"># example sakes.</span><br><span class="hljs-attr">dataDir</span>=<span class="hljs-string">/home/bigdata/services/tmp/zookeeper</span><br><span class="hljs-comment"># the port at which the clients will connect</span><br><span class="hljs-attr">clientPort</span>=<span class="hljs-string">2181</span><br><span class="hljs-comment"># log file directory</span><br><span class="hljs-attr">dataLogDir</span>=<span class="hljs-string">~/app/zookeeper/log</span><br><span class="hljs-comment"># servers set</span><br><span class="hljs-comment"># server.X=server_ip:port1:port2</span><br><span class="hljs-comment"># X              -Server的ID</span><br><span class="hljs-comment"># server_ip      -Server的IP地址</span><br><span class="hljs-comment"># port1          -该Server和集群中的leader交换信息使用的端口</span><br><span class="hljs-comment"># port2          -选举leader使用的端口</span><br><span class="hljs-attr">server.1</span>=<span class="hljs-string">hdfs1:5088:6088</span><br><span class="hljs-attr">server.2</span>=<span class="hljs-string">hdfs2:5088:6088</span><br><span class="hljs-attr">server.3</span>=<span class="hljs-string">hdfs3:5088:6088</span><br><span class="hljs-comment"># the maximum number of client connections.</span><br><span class="hljs-comment"># increase this if you need to handle more clients</span><br><span class="hljs-comment">#maxClientCnxns=60</span><br></code></pre></td></tr></table></figure><p>Zookeeper配置很简单，至此，就可以将Zookeeper分发到其他子节点了。</p><h1 id="调整"><a href="#调整" class="headerlink" title="调整"></a>调整</h1><p>在各节点创建<em>dataDir</em>配置项指定的目录，并在该目录下创建名为<em>myid</em>的文件，创建方法为输出当前节点在Zookeeper配置文件服务器集群配置项的集群Id至该文件即可，例如在<strong>hdfs3</strong>节点，由于配置文件指定该节点服务器Id为<code>3</code>，故使用命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">echo 3 &gt; /home/bigdata/services/tmp/zookeeper/myid<br></code></pre></td></tr></table></figure><h1 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">bin/zkServer.sh start   #启动Zookeeper<br>bin/zkServer.sh status  #查看阶段状态<br></code></pre></td></tr></table></figure><p>启动后若状态显示<code>Error contacting service. It is probably not running.</code> 原因有二：</p><ul><li>未按要求设置myid文件</li><li>Zookeeper集群只有一台机器</li></ul>]]></content>
    
    
    <categories>
      
      <category>big-data</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>distribution</tag>
      
      <tag>big-data</tag>
      
      <tag>zookeeper</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式集群手操 – Hadoop搭建</title>
    <link href="/big-data/hadoop-distribute-install/"/>
    <url>/big-data/hadoop-distribute-install/</url>
    
    <content type="html"><![CDATA[<p>Hadoop的分布式集群搭建示例，是在分布式节点部署准备工作基础上的首个集群搭建示例，后续集群将以此为基础。</p><span id="more"></span><p>在搭建集群前，请确认以做好分布式节点部署的准备工作，参见<a href="/distribution/distribute-node-build-prepare/" title="分布式节点部署准备工作">《分布式节点部署准备工作》</a></p><h1 id="下载Hadoop"><a href="#下载Hadoop" class="headerlink" title="下载Hadoop"></a>下载Hadoop</h1><p>访问 <a href="http://www.apache.org/dyn/closer.cgi/hadoop/common">http://www.apache.org/dyn/closer.cgi/hadoop/common</a> 网站以获取可用的镜像地址。</p><p>以北京理工大学镜像为例：</p><p>访问：<code>http://mirror.bit.edu.cn/apache/hadoop/common/</code> ，在列表中选择合适的Hadoop版本下载，每个版本文件夹内含四种文件，分别是以<code>-src.tar.gz</code>为后缀的源码文件、<code>.mds</code>为后缀的校验文件（俩），以及<code>.tar.gz</code>的已编译文件，如无特殊要求，一般下载体积较大的编译文件。</p><p>以<em>Hadoop2.6.4</em>为例，该已编译文件大小约为187MB，下载后通过XShell文件传输上载到某节点目录（例如hdfs1节点）。使用tar命令解压，然后执行相关配置即可。</p><p><strong>参考命令：</strong></p><p>解压tar.gz文件：<code>tar -zvxf &lt;压缩文件名&gt;</code></p><h1 id="配置Hadoop"><a href="#配置Hadoop" class="headerlink" title="配置Hadoop"></a>配置Hadoop</h1><p>为保持用户目录整洁，习惯上对其进行归纳并适当重命名，在用户目录下创建文件夹<em>Services</em>，定义所有Hadoop集群相关组件均以此为基础安装目录。</p><h2 id="规划"><a href="#规划" class="headerlink" title="规划"></a>规划</h2><p>三台节点分别为<code>hdfs1</code>、<code>hdfs2</code>、<code>hdfs3</code>，其中，<em>NameNode</em>、<em>JobTracker</em>和<em>SecondaryNameNode</em>以及<em>ResourceManager</em>均在主节点<code>hdfs1</code>上，其余两节点均为<em>DataNode</em>、<em>TaskTracker</em>.</p><p>修改用户目录下的<code>.bash_profile</code>文件，添加或修改如下内容：</p><figure class="highlight shell"><figcaption><span>.bash_profile</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">export HADOOP_HOME=/home/bigdata/services/hadoop-2.6.4<br>export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin<br></code></pre></td></tr></table></figure><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>进入Hadoop配置文件路径（<code>./etc/hadoop/</code>），配置以下文件内容：</p><ul><li>修改<code>hadoop-env.sh</code>及<code>yarn-env.sh</code>，设置<em>JAVA_HOME</em>为当前系统JDK安装的绝对路径</li><li>修改<code>core-site.xml</code>，添加如下配置：</li></ul><figure class="highlight xml"><figcaption><span>core-site.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://hdfs1:9000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/home/bigdata/services/tmp<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><ul><li>修改<code>hdfs-site.xml</code>，添加如下配置：</li></ul><figure class="highlight xml"><figcaption><span>hdfs-site.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>2<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.datanode.data.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/home/bigdata/services/tmp/dfs/data<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/home/bigdata/services/tmp/dfs/name<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.heartbeat.interval<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>3<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.blocksize<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>67108864<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.http.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs1:50070<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs1:50090<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><ul><li>新建文件名为<em>masters</em>，写入如下内容：</li></ul><figure class="highlight text"><figcaption><span>masters</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">hdfs1<br></code></pre></td></tr></table></figure><ul><li>修改<code>mapred-site.xml</code>，添加如下配置：</li></ul><figure class="highlight xml"><figcaption><span>mapred-site.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapred.job.tracker<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs1:9001<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><ul><li>修改<code>yarn-site.xml</code>，添加如下配置：</li></ul><figure class="highlight xml"><figcaption><span>yarn-site.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><ul><li>修改<em>slaves</em>，添加如下配置：</li></ul><figure class="highlight text"><figcaption><span>slaves</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">hdfs2<br>hdfs3<br></code></pre></td></tr></table></figure><p>通过<code>scp -r</code>传送配置好的Hadoop至其他节点，并使环境生效。</p><h1 id="启动Hadoop"><a href="#启动Hadoop" class="headerlink" title="启动Hadoop"></a>启动Hadoop</h1><h3 id="格式化NameNode"><a href="#格式化NameNode" class="headerlink" title="格式化NameNode"></a>格式化NameNode</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">hadoop namenode -format<br></code></pre></td></tr></table></figure><h3 id="启动HDFS"><a href="#启动HDFS" class="headerlink" title="启动HDFS"></a>启动HDFS</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sbin/start-dfs.sh<br></code></pre></td></tr></table></figure><h3 id="启动Yarn"><a href="#启动Yarn" class="headerlink" title="启动Yarn"></a>启动Yarn</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sbin/start-yarn.sh<br></code></pre></td></tr></table></figure><h3 id="运行测试"><a href="#运行测试" class="headerlink" title="运行测试"></a>运行测试</h3><p>切换至<code>./share/hadoop/mapreduce/</code>，运行示例任务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">hadoop jar hadoop-mapreduce-examples-2.6.4.jar pi 2 2<br></code></pre></td></tr></table></figure><p>注意：hdfs启动后处于安全模式中，直到收到足够多的各DataNode文件块报告并加载，以组成元数据，才会退出安全模式，在安全模式下不能运行或提交任何Job，否则会抛出异常并提示安全模式预计还有多久关闭。</p><h3 id="查看管理"><a href="#查看管理" class="headerlink" title="查看管理"></a>查看管理</h3><ul><li><a href="http://hdfs1:50070/">http://hdfs1:50070</a> （HDFS管理界面）</li><li><a href="http://hdfs1:8088/">http://hdfs1:8088</a> （RM管理界面）</li></ul>]]></content>
    
    
    <categories>
      
      <category>big-data</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>distribution</tag>
      
      <tag>big-data</tag>
      
      <tag>hadoop</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MysqlServer的安装部署</title>
    <link href="/mysql/mysql-install-57/"/>
    <url>/mysql/mysql-install-57/</url>
    
    <content type="html"><![CDATA[<p>在Linux上安装mysql5.7的示例。由于一些老系统镜像默认的源一般为mysql5.1左右，要想安装较高版本的mysql数据库，则需要手动更新源。</p><span id="more"></span><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>首先切换到管理员用户，执行<code>rpm -qa | grep mysql</code></p><p>如果命令返回结果存在任意项，则先卸载出现的mysql相关项，以避免安装冲突或其他异常。</p><p>例如：出现<code>mysql-libs-5.1.71-1.el6.x86_64</code>，则使用卸载命令<code>rpm -e --nodeps mysql-libs-5.1.71-1.el6.x86_64</code></p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h3 id="下载mysql的最新yum源"><a href="#下载mysql的最新yum源" class="headerlink" title="下载mysql的最新yum源"></a>下载mysql的最新yum源</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">wget dev.mysql.com/get/mysql-community-release-el6-5.noarch.rpm<br></code></pre></td></tr></table></figure><h3 id="安装yum源"><a href="#安装yum源" class="headerlink" title="安装yum源"></a>安装yum源</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">yum localinstall mysql-community-release-el6-5.noarch.rpm<br></code></pre></td></tr></table></figure><h3 id="查看源"><a href="#查看源" class="headerlink" title="查看源"></a>查看源</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">yum repolist all | grep mysql<br></code></pre></td></tr></table></figure><p>如果安装顺利，查看结果应该大致如下图所示：</p><img src="/images/src-repolist-mysqld.png" class="" title="查看yum源" alt="查看yum源"><h3 id="配置源"><a href="#配置源" class="headerlink" title="配置源"></a>配置源</h3><p>禁用<em>mysql5.5</em>和<em>mysql5.6</em>，启用<em>mysql5.7</em>的安装源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">yum-config-manager --disable mysql55-community<br>yum-config-manager --disable mysql56-community<br>yum-config-manager --enable mysql57-community-dmr<br></code></pre></td></tr></table></figure><h3 id="确认源"><a href="#确认源" class="headerlink" title="确认源"></a>确认源</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">yum repolist enabled | grep mysql<br></code></pre></td></tr></table></figure><p>此时应该只显示mysql5.7的信息，如图：</p><img src="/images/src-repolist-enabled-mysqld.png" class="" title="查看mysql5.7源" alt="查看mysql5.7源"><h3 id="执行安装"><a href="#执行安装" class="headerlink" title="执行安装"></a>执行安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">yum install mysql-community-server<br></code></pre></td></tr></table></figure><p>注意安装列表显示的版本号，如果不是<em>5.7</em>，请不要输入<code>y</code>，仔细检查前几步的操作过程是否有误。</p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><h3 id="启动Mysql"><a href="#启动Mysql" class="headerlink" title="启动Mysql"></a>启动Mysql</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">service mysqld start<br></code></pre></td></tr></table></figure><h3 id="设置开机自启动"><a href="#设置开机自启动" class="headerlink" title="设置开机自启动"></a>设置开机自启动</h3><p>查看mysql是否开启</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">chkconfig --list | grep mysqld<br>chkconfig mysqld on<br></code></pre></td></tr></table></figure><h3 id="登陆并设置密码"><a href="#登陆并设置密码" class="headerlink" title="登陆并设置密码"></a>登陆并设置密码</h3><p>由于<code>mysql5.6</code>开始安全机制就开始变了，所以在<code>mysql5.7</code>时，root初始不能免密码登陆哦</p><p><strong>方法有二：</strong></p><ul><li>使用初始随机密码登陆<br>在<code>mysql5.6</code>，安装成功后初始化数据库会在root目录下生成一个<code>.mysql_sercet</code>的文件，内含生成的初始随机密码，使用该密码登陆mysql后再使用命令修改密码。</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">set</span> password<span class="hljs-operator">=</span>password(<span class="hljs-string">&#x27;&lt;新密码&gt;&#x27;</span>);<br></code></pre></td></tr></table></figure><p>但在<code>mysql5.7</code>中却不存在该文件，因为随机密码会生成在日志中，所以直接查看日志以获取随机密码，日志路径一般为<code>/var/log/mysqld.log</code>，使用命令查看随机密码：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">grep &quot;A temporary password&quot;  /var/log/mysqld.log<br></code></pre></td></tr></table></figure><p>显示类似信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs log">2016-09-05T02:20:59.735447Z 1 [Note] A temporary password is generated for root@localhost: :M3dBN_3V!uk<br></code></pre></td></tr></table></figure><ul><li>关闭验证，修改密码</li></ul><p>先关闭mysql服务，<code>service mysqld stop</code>，然后启动安全模式，携带<code>–skip-grant-tables</code>参数。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">mysqld_safe --skip-grant-tables &amp;<br></code></pre></td></tr></table></figure><p>确认mysql服务此时启动后，直接输入<code>mysql</code>命令登陆mysql，无需指定用户名和密码。</p><p>在mysql命令行执行以下语句更新密码：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">update</span> <span class="hljs-keyword">user</span> <span class="hljs-keyword">set</span> authentication_string<span class="hljs-operator">=</span>password(<span class="hljs-string">&#x27;&lt;新密码&gt;&#x27;</span>) <span class="hljs-keyword">where</span> <span class="hljs-keyword">user</span><span class="hljs-operator">=</span><span class="hljs-string">&#x27;root&#x27;</span>;<br>flush privileges;<br></code></pre></td></tr></table></figure><p>然后退出mysql，结束刚才启动的mysql安全模式服务及mysql进程。</p><p>再次以标准方式启动mysql服务，然后以root身份登陆，输入新密码即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">mysql  -uroot -p<br></code></pre></td></tr></table></figure><p>在mysql命令行执行以下操作更新密码，否则不能执行任何查询操作。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">user</span> <span class="hljs-string">&#x27;root&#x27;</span>@<span class="hljs-string">&#x27;localhost&#x27;</span> identified <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;&lt;你的密码&gt;&#x27;</span>;<br>flush privileges;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式节点部署准备工作</title>
    <link href="/distribution/distribute-node-build-prepare/"/>
    <url>/distribution/distribute-node-build-prepare/</url>
    
    <content type="html"><![CDATA[<p>分布式集群环境搭建的准备工作，包括主机名和IP地址、SSH互信等，是搭建分布式集群环境的基础和不可或缺的部分。此文将详细描述这一准备工作，是系列集群搭建的环境基础。</p><span id="more"></span><h1 id="节点规划"><a href="#节点规划" class="headerlink" title="节点规划"></a>节点规划</h1><p>假设有三台主机用以搭建分布式集群，分别为<code>hdfs1</code>、<code>hdfs2</code>、<code>hdfs3</code>.</p><p>为此，我们通过VM克隆新装的空白CentOS 6.5虚拟机依次完成三台空白节点的产生，并以唯一可用的root用户登陆配置网卡信息，参见<a href="/vmware/vm-clone-network-recover/" title="VMware克隆虚拟机后的网卡恢复操作">《VMware克隆虚拟机后的网卡恢复操作》</a>.</p><p>通过配置静态IP地址以便分布式集群后续的搭建。配置IP地址如下：</p><table><thead><tr><th>主机</th><th>静态IP</th><th>预设</th></tr></thead><tbody><tr><td>hdfs1</td><td>192.168.223.151</td><td>master</td></tr><tr><td>hdfs2</td><td>192.168.223.152</td><td>slave</td></tr><tr><td>hdfs3</td><td>192.168.223.153</td><td>slave</td></tr></tbody></table><h1 id="映射主机名"><a href="#映射主机名" class="headerlink" title="映射主机名"></a>映射主机名</h1><p>设置主机名称以符合设计，修改 <em>&#x2F;etc&#x2F;sysconfig&#x2F;network</em> 文件，主机名可自行修改为合适的主机名，不必遵循上述表格内容，修改<em>HOSTNAME</em>字段为该主机的名称即可。<br>修改hosts文件以实现主机名与IP映射关联，这样就可以直接使用主机名操作而非难记的IP地址，在hosts文件新增如下配置：</p><figure class="highlight text"><figcaption><span>/etc/hosts</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">192.168.223.151 hdfs1<br>192.168.223.152 hdfs2<br>192.168.223.153 hdfs3<br></code></pre></td></tr></table></figure><p>然后将统一配置的hosts文件分发到各节点对应目录覆盖</p><ul><li>参考命令：<em>scp</em></li><li>目标文件：*&#x2F;etc&#x2F;hosts*</li></ul><h1 id="统一账户"><a href="#统一账户" class="headerlink" title="统一账户"></a>统一账户</h1><p>为方便操作，统一搭建在名为<code>bigdata</code>的用户下，创建该用户</p><ul><li>参考命令：<em>useradd</em></li></ul><h1 id="访问验证-SSH互信"><a href="#访问验证-SSH互信" class="headerlink" title="访问验证 - SSH互信"></a>访问验证 - SSH互信</h1><p>SSH互信，即主机间通过SSH公钥验证，从而取代繁琐且不安全的明文密码，带给主机通信极大的便捷和安全。</p><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>SSH通过用户目录下*.ssh&#x2F;authorized_keys*文件对访问者的身份进行鉴别，从而实现免密码访问，在分布式集群搭建中的使用极为重要。</p><p>首先，各节点能通过各自IP地址进行通讯，即网络正常</p><h2 id="生成密钥对"><a href="#生成密钥对" class="headerlink" title="生成密钥对"></a>生成密钥对</h2><p>在用户目录下生成公私钥对，即使用命令<code>ssh-keygen -t rsa -P &#39;&#39;</code> 即可在用户目录下<code>.ssh</code>目录下生成密钥对，不要对该目录下的<em>id_rsa</em> 及<em>id_rsa.pub</em> 密钥对文件进行改动，它们是作为SSH互信的钥匙。</p><p>在其他节点下同样运行该命令生成各自的密钥对。</p><h2 id="互信操作"><a href="#互信操作" class="headerlink" title="互信操作"></a>互信操作</h2><p>通过SCP命令传输各节点的公钥（即 <em>id_rsa.pub</em> 文件）到指定的一台节点进行统一的验证生成处理。注意：只需其他节点将公钥文件拷贝到某一台节点上做统一互信后再一并分发到各个节点以减少工作量。</p><p>例如：将所有节点的公钥发送到一号节点的用户目录下的一个名为<em>pub_kyes</em>文件夹下，注意使用SCP命令时将公钥文件重命名，以避免文件覆盖，建议命名加统一的各自节点名称后缀。</p><p>传输完成后，也要记得拷贝当前节点的公钥到该文件夹下。在该文件夹追加所有的公钥到<em>authorized_keys</em>文件中，然后将该文件依次分发到各节点的用户目录下的<code>.ssh</code>目录中，注意确保该文件在<code>.ssh</code>目录下权限<code>600</code>，而<code>.ssh</code>目录权限<code>700</code>。</p><ul><li>命令示例：<code>cat id_rsa1.pub &gt;&gt; authorized_keys</code></li></ul><p>最后别忘了给当前节点的<code>.ssh</code>目录下也放一份<em>authorized_keys</em>文件。</p><h3 id="SCP命令参考"><a href="#SCP命令参考" class="headerlink" title="SCP命令参考"></a>SCP命令参考</h3><ul><li>本地到远端：scp &lt;本地文件&gt; &lt;远端用户&gt;@&lt;远端主机&gt;:&lt;远端文件&gt;</li><li>远端到本地：scp &lt;远端用户&gt;@&lt;远端主机&gt;:&lt;远端文件&gt; &lt;本地文件&gt;</li><li>常用参数： -v 显示调试信息； -r 迭代传输（用于文件夹传输）</li></ul><p><strong>示例</strong> </p><p>传输*&#x2F;etc&#x2F;hosts*到远端主机<code>192.168.223.152</code>对应目录覆盖</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">scp  /etc/hosts  root@192.168.223.152:/etc/hosts<br></code></pre></td></tr></table></figure><p>传输文件夹*&#x2F;usr&#x2F;local&#x2F;jdk*到远端主机<code>hdfs3</code>对应目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">scp  -r /usr/local/jdk  root@hdfs3:/usr/local/<br></code></pre></td></tr></table></figure><p>注意：使用scp命令时未使用主机名称而使用IP地址，可能会出现链接缓慢的问题，连接出现响应要大约15秒甚至更久，原因一般为GSSAPI ( Generic Security Services Application Programming Interface) ，它是一套类似Kerberos 5 的通用网络安全系统接口。该接口是对各种不同的客户端服务器安全机制的封装，以消除安全接口的不同，降低编程难度。但该接口在目标机器无域名解析时会有问题。所以，可以在hosts中添加域名解析从而使用主机名，或者修改*&#x2F;etc&#x2F;ssh&#x2F;ssh_conf*文件将<code>GSSAPIAuthentication</code>字段改为<code>no</code>。</p><h1 id="JDK安装"><a href="#JDK安装" class="headerlink" title="JDK安装"></a>JDK安装</h1><p>从网络下载好合适版本的JDK后，使用SCP命令统一JDK的安装文件及配置文件（环境变量<code>/etc/profile</code>)</p><h1 id="启动终端设置"><a href="#启动终端设置" class="headerlink" title="启动终端设置"></a>启动终端设置</h1><p>为节省节点的无关资源消耗，建议使用命令行终端代替图形终端，同时也会加快节点启动速度。</p><h2 id="终端切换"><a href="#终端切换" class="headerlink" title="终端切换"></a>终端切换</h2><p>使用命令<code>init 3</code>切换到网络多用户命令终端，<code>init 5</code>则切换到图形终端。</p><h2 id="设置启动终端"><a href="#设置启动终端" class="headerlink" title="设置启动终端"></a>设置启动终端</h2><p>修改*&#x2F;etc&#x2F;inittab*文件，将<code>id:5:initdefault:</code>改为<code>id:3:initdefault:</code>保存，重启主机即可。</p>]]></content>
    
    
    <categories>
      
      <category>distribution</category>
      
    </categories>
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>vmware</tag>
      
      <tag>distribution</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VMware克隆虚拟机后的网卡恢复操作</title>
    <link href="/vmware/vm-clone-network-recover/"/>
    <url>/vmware/vm-clone-network-recover/</url>
    
    <content type="html"><![CDATA[<p>同时运行通过VM克隆的虚拟主机一般会发生网卡冲突的情况，需手动对网络配置文件进行修改以解决该问题。</p><span id="more"></span><p>通过<code>VM–&gt;Manage–&gt;Clone..</code>命令对已关闭的虚拟机进行克隆，这比直接手动复制虚拟机文件要方便的多，尤其是在克隆时会为该虚拟机生成新的网卡MAC，而手动复制的虚拟机镜像在导入到VM中时一般会询问该虚拟机是通过复制产生的还是移动文件产生的，对应操作为生成新网卡MAC和什么都不操作。</p><p>虽然有新的MAC可用，但复制&#x2F;克隆后的系统文件是一致的，即网络配置文件一致，需手动修改以避免MAC冲突，在 <em>&#x2F;etc&#x2F;udev&#x2F;rules.d&#x2F;70-persistent-net.rules</em> 文件中会生成新生成的网卡信息包括MAC地址，但由于原本存在复制的 <code>eth0</code> 网卡信息，所以系统会认为是新网卡，则生成的有效网卡信息NAME为eth1 ，所以，只需修改其NAME为eth0并删除原来的eth0的信息，同时记录<code>ATTR(address)=xx:xx:xx:xx:xx:xx</code>这串MAC地址用以更改网卡IP配置信息中的MAC与其对应，确保IP设置对该网卡MAC生效。<br>故修改 <em>&#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0</em> 文件中的 <code>HWADDR</code> 字段为该MAC地址，注意到所有生成的MAC地址均以 <code>00:0C:29</code> 为起始，随机生成后面的三个段，所以修改前面固定的这三个段是无效的。</p><p>当然，也可以自己手动生成该网卡的新MAC，只需选中要修改的主机，在右键<code>Settings</code>里选择网络设备，并打开高级设置，在MAC地址标签下点击生成按钮，即可随机生成MAC地址，但要使其生效必须关闭主机再启动，而非重启。</p><img src="/images/src-clone-vm.png" class="" title="高级设置" alt="高级设置"><img src="/images/src-gen-mac-vm.png" class="" title="生成新MAC" alt="生成新MAC"><p>然后重启网络服务即可。<br>参考命令：<code>service network restart</code></p><p>当然 <em>70-persistent-net.rules</em> 文件如果不存在会重新生成的，所以，如果不知道VM为系统生成了什么MAC地址，只需删除该文件并重启系统即可。</p><p><strong>主机如果要使用静态IP访问外网，则默认DNS必须为网关IP哦</strong></p>]]></content>
    
    
    <categories>
      
      <category>vmware</category>
      
    </categories>
    
    
    <tags>
      
      <tag>vmware</tag>
      
      <tag>windows</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>C#使用RawInput实现自由组合快捷键</title>
    <link href="/csharp/cs-rawinput-look/"/>
    <url>/csharp/cs-rawinput-look/</url>
    
    <content type="html"><![CDATA[<p>本文是我在大二初即2015年5月份写的一篇关于C#任意组合快捷键，当初是自己有这方面的需求，在百度搜索上找了两天无果，最后在“外面的世界”找到了相关的介绍，然后自己实现了该需求。</p><span id="more"></span><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>使用C#语言做一些客户端应用时，会较长用到全局快捷键功能，而就关于C#全局快捷键的创建，较常使用的方法不外乎以下两种：</p><ul><li>使用<code>user32.dll</code>动态链接库的<code>RegisterHotKey</code>和<code>UnregisterHotKey</code>入口方法实现快捷键的注册和注销，但缺点明显，它会截获系统默认快捷键，和系统快捷键产生冲突后会有一系列麻烦，而且最主要的是，它只能提供注册两个键组合的快捷键，且有组合的限制，这就使得快捷键应用不尽人意。  </li><li>使用Win32API实现全局钩子，即使用<code>user32.dll</code>动态链接库的<code>SetWindowsHookEx</code>和<code>UnhookWindowsHookEx</code>入口方法创建和卸载监听按键的键盘全局钩子，通过对按键判断处理即可确认设置的快捷键是否被使用，缺点是处理麻烦，且占用较多系统资源，钩子的安装需要系统 管理员权限。</li></ul><p>以上方法虽然可以实现基本快捷键的创建，但仍旧达不到对自由快捷键的要求。一个偶然的机会，我在国外某论坛平台找到一篇介绍<strong>RawInput</strong>使用的文章，我在该文章中找到了解决办法。</p><p>首先，什么是RawInput，据字面意思就是“未经加工的输入”，或者我们可以这样叫它——“原始输入”， 意思也就不难理解了。自Windows XP开始，Windows平台开始支持多人机接口设备（即多个人机交互设备的接入使用），允许通过rawinput API使应用程序能直接处理多个设备的信息输入，而一般的处理事件只会把多个设备看作同一个设备进行处理。也就是说，rawinput API支持应用程序对不同输入设备的信息处理，这使得你可以通过不同的输入设备同时完成不同的工作，比如：使用多键盘协同工作、多人多控制器游戏等等。</p><p>对于一个键盘的按键信息，Windows一般会截获该数据并转换为一个按键事件，也就是操作系统会将设备按键的特定数据转换为虚拟按键（virtual keys）数据。然而正常的Windows系统处理不会提供关于按键数据来源设备的任何信息，而是将所有按键捆绑为为一类事件（KeyPressEvent），使得应用程序只能认为它们来自同一个输入设备。通过Rawinput，应用程序就可以直接接收到键盘按键数据，以最小的操作系统介入，保证可以从中得到数据的发生源。然而rawinput API不只局限于键盘，还包括鼠标、控制器、触屏等各种人机设备（HID【Human Interface Device】是Windows最早支持的USB类别），而在这篇文章里，我只应需求，介绍关于键盘设备的数据处理。 关于RawInput API请参考<a href="https://msdn.microsoft.com/en-us/library/ms645536(VS.85).aspx">MSDN文档</a></p><h1 id="内容实现"><a href="#内容实现" class="headerlink" title="内容实现"></a>内容实现</h1><h2 id="入口方法"><a href="#入口方法" class="headerlink" title="入口方法"></a>入口方法</h2><p>实现本次功能，主要用到的入口方法为：</p><ul><li>RegisterRawInputDevices <strong>#允许应用程序注册监听的输入设备</strong></li><li>GetRawInputData <strong>#从输入设备检索数据</strong></li><li>GetRawInputDeviceList <strong>#检索连接到系统的输入设备列表</strong></li><li>GetRawInputDeviceInfo <strong>#检索设备信息</strong></li></ul><h2 id="核心步骤"><a href="#核心步骤" class="headerlink" title="核心步骤"></a>核心步骤</h2><h3 id="注册设备"><a href="#注册设备" class="headerlink" title="注册设备"></a>注册设备</h3><p>起初，应用程序是不能得到输入设备的原始数据的，需要对希望获取原始数据的设备进行注册，将设备与应用程序联系起来就可以接收数据。</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs cs"><span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;summary&gt;</span></span><br><span class="hljs-comment"><span class="hljs-doctag">///</span> 注册监听原始输入设备</span><br><span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;/summary&gt;</span></span><br><span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;param name=&quot;pRawInputDevices&quot;&gt;</span>原始输入设备集<span class="hljs-doctag">&lt;/param&gt;</span></span><br><span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;param name=&quot;uiNumDevices&quot;&gt;</span>设备集的元素个数<span class="hljs-doctag">&lt;/param&gt;</span></span><br><span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;param name=&quot;cbSize&quot;&gt;</span>原始输入设备信息占用的字节数<span class="hljs-doctag">&lt;/param&gt;</span></span><br><span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;returns&gt;</span>如果执行成功则返回True，否则为False，可通过调用GetLastError方法获取关于失败的更多信息<span class="hljs-doctag">&lt;/returns&gt;</span></span><br>[<span class="hljs-meta">DllImport(<span class="hljs-string">&quot;User32.dll&quot;</span>, SetLastError = true)</span>]<br><span class="hljs-function"><span class="hljs-keyword">internal</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">extern</span> <span class="hljs-built_in">bool</span> <span class="hljs-title">RegisterRawInputDevices</span>(<span class="hljs-params">RawInputDevice[] pRawInputDevices, <span class="hljs-built_in">uint</span> uiNumDevices, <span class="hljs-built_in">uint</span> cbSize</span>)</span>;<br></code></pre></td></tr></table></figure><p>该方法的首个参数为<code>RawInputDevice</code>数据结构类型的数组，第二个参数为该数组的元素个数，第三个为该结构所占用的字节数。<br>而<code>RawInputDevice</code>结构原本定义在<code>windows.h</code>头文件中，在此处，我们仿照C++对其重新进行定义，可参考前面提到MSDN文档</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs cs"><span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;summary&gt;</span></span><br><span class="hljs-comment"><span class="hljs-doctag">///</span> 定义原始数据设备信息</span><br><span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;/summary&gt;</span></span><br>[<span class="hljs-meta">StructLayout(LayoutKind.Sequential)</span>]<br><span class="hljs-keyword">internal</span> <span class="hljs-keyword">struct</span> RawInputDevice<br>&#123;<br>    <span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;summary&gt;</span></span><br>    <span class="hljs-comment"><span class="hljs-doctag">///</span> 顶级集合用法页，接口设备用法页</span><br>    <span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;/summary&gt;</span></span><br>    <span class="hljs-keyword">internal</span> HidUsagePage usUsagePage;<br>    <span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;summary&gt;</span></span><br>    <span class="hljs-comment"><span class="hljs-doctag">///</span> 顶级集合用法，即监听设备标识</span><br>    <span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;/summary&gt;</span></span><br>    <span class="hljs-keyword">internal</span> HidUsage usUsage;<br>    <span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;summary&gt;</span></span><br>    <span class="hljs-comment"><span class="hljs-doctag">///</span> 模式标识，指示如何解释处理由用法页和用法提供的信息</span><br>    <span class="hljs-comment"><span class="hljs-doctag">///</span> 默认为Zero时，操作系统会在已经注册的应用窗口获得焦点时，传送顶级集合指定的设备原始数据</span><br>    <span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;/summary&gt;</span></span><br>    <span class="hljs-keyword">internal</span> RawInputDeviceFlags dwFlags;<br>    <span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;summary&gt;</span></span><br>    <span class="hljs-comment"><span class="hljs-doctag">///</span> 与监听设备关联的目标窗口句柄，如果为空，则遵循键盘焦点</span><br>    <span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;/summary&gt;</span></span><br>    <span class="hljs-keyword">internal</span> IntPtr hwndTarget;<br>&#125;<br></code></pre></td></tr></table></figure><p>由于我们只关心键盘设备类型信息，在<code>RawKeyBoardB</code>（原始键盘设备封闭类）的构造方法中只声明一个长度的<code>RawInputDevice</code>结构：</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">RawKeyBoard</span>(<span class="hljs-params">IntPtr hwnd, <span class="hljs-built_in">bool</span> captureOnlyInForeground</span>)</span>&#123;<br>    <span class="hljs-keyword">var</span> rid = <span class="hljs-keyword">new</span> RawInputDevice[<span class="hljs-number">1</span>];<br>    rid[<span class="hljs-number">0</span>].usUsagePage = HidUsagePage.GENERIC;<br>    rid[<span class="hljs-number">0</span>].usUsage = HidUsage.Keyboard;<br>    rid[<span class="hljs-number">0</span>].dwFlags = (captureOnlyInForeground ? RawInputDeviceFlags.UNDEFINE : RawInputDeviceFlags.RIDEV_INPUTSINK) | RawInputDeviceFlags.RIDEV_DEVNOTIFY;<br>    rid[<span class="hljs-number">0</span>].hwndTarget = hwnd;<br>    <span class="hljs-keyword">if</span>(!Win32API.RegisterRawInputDevices(rid, (<span class="hljs-built_in">uint</span>)rid.Length, (<span class="hljs-built_in">uint</span>)Marshal.SizeOf(rid[<span class="hljs-number">0</span>])))<br>    &#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> ApplicationException(<span class="hljs-string">&quot;注册设备失败&quot;</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里<code>RawInputDeviceFlags.INPUTSINK</code>的取值为<code>0x00000100</code>，意味着应用窗口将一直接收输入信息，即便窗口是不被激活的，关于<code>RawInputDeviceFlags</code>的取值，可参考API文档。</p><p>注册设备后，应用程序就可以通过<code>GetRawInputData</code>方法获取处理数据了。</p><h3 id="过滤接收"><a href="#过滤接收" class="headerlink" title="过滤接收"></a>过滤接收</h3><p>当设备注册后，应用开始准备接收原始数据，一旦注册设备被使用，Windows会生成一个包含来自该设备未处理数据的<code>WM_INPUT</code>消息。</p><p>而与该设备关联的窗口会在一个 <code>WM_INPUT</code>消息送达时检查收到的信息，并作进一步处理，在本应用程序中， <code>RawInputManager</code>类会负责过滤和截取<code>WM_INPUT</code>消息，它继承自低级封装窗口，通过重写其 <code>WndProc</code>方法以截取该消息，并通过<code>RawKeyBoard</code>对象的<code>ProcessRawInput</code>方法传递和处理该消息。</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">override</span> <span class="hljs-keyword">void</span> <span class="hljs-title">WndProc</span>(<span class="hljs-params"><span class="hljs-keyword">ref</span> Message message</span>)</span><br>&#123;<br>    <span class="hljs-keyword">switch</span> (message.Msg)<br>    &#123;<br>        <span class="hljs-keyword">case</span> WinMessage.WM_INPUT:<br>        &#123;<br>             keyBoardDriver.ProcessRawInput(message.LParam);<br>        &#125;<br>        <span class="hljs-keyword">break</span>;<br>        <span class="hljs-keyword">case</span> WinMessage.WM_USB_DEVICECHANGE:<br>        &#123;<br>            keyBoardDriver.EnumerateDevices();<br>        &#125;<br>        <span class="hljs-keyword">break</span>;<br>    &#125;<br>    <span class="hljs-keyword">base</span>.WndProc(<span class="hljs-keyword">ref</span> message);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="接收处理"><a href="#接收处理" class="headerlink" title="接收处理"></a>接收处理</h3><p>现在，通过消息过滤获得了我们想要的信息，然后就可以对其进行数据处理。<code>ProcessRawInput</code>方法用<code>GetRawInputData</code>方法检索<code>WM_INPUT</code>消息内容并转换为有用的信息。首先，导入该方法</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cs">[<span class="hljs-meta">DllImport(<span class="hljs-string">&quot;User32.dll&quot;</span>, SetLastError = true)</span>]<br><span class="hljs-function"><span class="hljs-keyword">internal</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">extern</span> <span class="hljs-built_in">int</span> <span class="hljs-title">GetRawInputData</span>(<span class="hljs-params">IntPtr hRawInput, RawInputDataCommand command, [Out] IntPtr pData, [In, Out] <span class="hljs-keyword">ref</span> <span class="hljs-built_in">int</span> size, <span class="hljs-built_in">int</span> sizeHeader</span>)</span>;<br></code></pre></td></tr></table></figure><p>该方法的参数如下：</p><ul><li><p>hRawInput<br><code>RAWINPUT</code> 数据结构句柄，包含<code>WM_INPUT</code>消息的<code>lParam</code> 数据</p></li><li><p>command<br>标识如何从<code>RAWINPUT</code>数据结构检索输入信息或头信息，可能的取值为<code>RID_INPUT</code> (<code>0x10000003</code>) 或 <code>RID_HEADER</code> (<code>0x10000005</code>)</p></li><li><p>pData:<br>取决于期望的结果：<br>如果<code>pData</code> 赋值为 <code>IntrPtr.Zero</code>, 数据所需的内存区大小将被返回给 <code>size</code>变量。<br>否则<code>pData</code> 必须为分配给由<code>WM_INPUT</code>消息产生的<code>RAWINPUT</code> 数据结构的内存区指针。当方法返回时，已分配存储的内容将组成消息的头信息或输入数据，这取决于<code>command</code>的值</p></li><li><p>size<br>返回由 <code>pData</code>指示的数据大小</p></li><li><p>sizeHeader<br><code>RAWINPUTHEADER</code> 数据结构大小</p></li></ul><p>具体介绍参考MSND文档。</p><p>为了确保能为我们期望的数据分配足够的空间，我们首先在调用该方法时将<code>pData</code> 赋值为<code>IntrPtr.Zero</code>以获取数据大小：</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cs"><span class="hljs-keyword">var</span> dwSize = <span class="hljs-number">0</span>;<br>Win32.GetRawInputData(hdevice, RawInputDataCommand.RID_INPUT, IntPtr.Zero, <span class="hljs-keyword">ref</span> dwSize, Marshal.SizeOf(<span class="hljs-keyword">typeof</span>(Rawinputheader)));<br></code></pre></td></tr></table></figure><p>现在，可以再次调用该方法， 从当前消息中用<code>RAWINPUT</code> 数据结构填充 <code>_rawBuffer</code>变量。 调用成功的话，方法会返回接收数据的大小，以此来检查是否与之前获取的数据大小匹配以判断是否获取到了期望的正确数据。</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cs"><span class="hljs-keyword">if</span> (dwSize == Win32.GetRawInputData(hdevice, RawInputDataCommand.RID_INPUT, <span class="hljs-keyword">out</span> _rawBuffer, <span class="hljs-keyword">ref</span> dwSize, Marshal.SizeOf(<span class="hljs-keyword">typeof</span> (Rawinputheader))))<br>&#123;<br>    <span class="hljs-comment">//dosomething...</span><br>&#125;<br></code></pre></td></tr></table></figure><p>数据已经获取，现在可以对其进行处理了。<code>WM_INPUT</code> 包含了封装进<code>RAWINPUT</code>数据结构的原始数据。同样的，该数据类型也要被重新定义</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs cs"><span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;summary&gt;</span></span><br><span class="hljs-comment"><span class="hljs-doctag">///</span> 包含来自设备的原始输入</span><br><span class="hljs-comment"><span class="hljs-doctag">///</span> <span class="hljs-doctag">&lt;/summary&gt;</span></span><br>[<span class="hljs-meta">StructLayout(LayoutKind.Explicit)</span>]<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">struct</span> RAWINPUT<br>&#123;<br>    [<span class="hljs-meta">FieldOffset(0)</span>]<br>    <span class="hljs-keyword">internal</span> RAWMOUSE mouse;<br>    [<span class="hljs-meta">FieldOffset(0)</span>]<br>    <span class="hljs-keyword">internal</span> RAWKEYBOARD keyboard;<br>    [<span class="hljs-meta">FieldOffset(0)</span>]<br>    <span class="hljs-keyword">internal</span> RAWHID hid;<br>&#125;<br>[<span class="hljs-meta">StructLayout(LayoutKind.Sequential)</span>]<br><span class="hljs-keyword">internal</span> <span class="hljs-keyword">struct</span> RAWHID<br>&#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">uint</span> dwSizHid;<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">uint</span> dwCount;<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">byte</span> bRawData;<br>&#125;<br>[<span class="hljs-meta">StructLayout(LayoutKind.Explicit)</span>]<br><span class="hljs-keyword">internal</span> <span class="hljs-keyword">struct</span> RAWMOUSE<br>&#123;<br>    [<span class="hljs-meta">FieldOffset(0)</span>]<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">ushort</span> usFlags;<br>    [<span class="hljs-meta">FieldOffset(4)</span>]<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">uint</span> ulButtons;<br>    [<span class="hljs-meta">FieldOffset(4)</span>]<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">ushort</span> usButtonFlags;<br>    [<span class="hljs-meta">FieldOffset(6)</span>]<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">ushort</span> usButtonData;<br>    [<span class="hljs-meta">FieldOffset(8)</span>]<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">uint</span> ulRawButtons;<br>    [<span class="hljs-meta">FieldOffset(12)</span>]<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">int</span> lLastX;<br>    [<span class="hljs-meta">FieldOffset(16)</span>]<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">int</span> lLastY;<br>    [<span class="hljs-meta">FieldOffset(20)</span>]<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">uint</span> ulExtraInformation;<br>&#125;<br>[<span class="hljs-meta">StructLayout(LayoutKind.Sequential)</span>]<br><span class="hljs-keyword">internal</span> <span class="hljs-keyword">struct</span> RAWKEYBOARD<br>&#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">ushort</span> Makecode;<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">ushort</span> Flags;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">readonly</span> <span class="hljs-built_in">ushort</span> Reserved;<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">ushort</span> VKey;<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">uint</span> Message;<br>    <span class="hljs-keyword">public</span> <span class="hljs-built_in">uint</span> ExtraInformation;<br>&#125;<br></code></pre></td></tr></table></figure><p>接下来，就是对数据进行筛选，确定是否有按键被按下。通过驱动相应事件向窗体传递特定按键消息（如设定的快捷键已匹配）。</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-built_in">int</span> <span class="hljs-title">ProcessRawInput</span>(<span class="hljs-params">IntPtr hdevice</span>)</span><br>&#123;<br>    <span class="hljs-keyword">if</span> (deviceList.Count == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">var</span> dwSize = <span class="hljs-number">0</span>;<br>    Win32API.GetRawInputData(hdevice, RawInputDataCommand.RID_INPUT, IntPtr.Zero, <span class="hljs-keyword">ref</span> dwSize, Marshal.SizeOf(<span class="hljs-keyword">typeof</span>(Rawinputheader)));<br>    <span class="hljs-keyword">if</span> (dwSize != Win32API.GetRawInputData(hdevice, RawInputDataCommand.RID_INPUT, <span class="hljs-keyword">out</span> _rawBuffer, <span class="hljs-keyword">ref</span> dwSize, Marshal.SizeOf(<span class="hljs-keyword">typeof</span>(Rawinputheader))))<br>    &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>    &#125;<br>    <span class="hljs-built_in">int</span> virtualKey = _rawBuffer.data.keyboard.VKey;<br>    <span class="hljs-built_in">int</span> makeCode = _rawBuffer.data.keyboard.Makecode;<br>    <span class="hljs-built_in">int</span> flags = _rawBuffer.data.keyboard.Flags;<br>    <span class="hljs-keyword">if</span> (virtualKey == WinMessage.KEYBOARD_OVERRUN_MAKE_CODE) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">var</span> isE0BitSet = ((flags &amp; WinMessage.RI_KEY_E0) != <span class="hljs-number">0</span>);<br>    KeyPressEvent keyPressEvent;<br>    <span class="hljs-keyword">if</span> (deviceList.ContainsKey(_rawBuffer.header.hDevice))<br>    &#123;<br>        <span class="hljs-keyword">lock</span> (padLock)<br>        &#123;<br>            keyPressEvent = deviceList[_rawBuffer.header.hDevice];<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">else</span><br>    &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">2</span>;<br>    &#125;<br>    <span class="hljs-keyword">var</span> isBreakBitSet = ((flags &amp; WinMessage.RI_KEY_BREAK) != <span class="hljs-number">0</span>);<br>    keyPressEvent.KeyPressState = isBreakBitSet ? <span class="hljs-string">&quot;BREAK&quot;</span> : <span class="hljs-string">&quot;MAKE&quot;</span>;<br>    keyPressEvent.Message = _rawBuffer.data.keyboard.Message;<br>    keyPressEvent.VKeyName = KeyMapper.GetKeyName(VirtualKeyCorrection(virtualKey, isE0BitSet, makeCode)).ToUpper();<br>    keyPressEvent.VKey = virtualKey;<br>    <span class="hljs-keyword">if</span> (KeyPressed != <span class="hljs-literal">null</span>)<br>    &#123;<br>        hotkeyPressEvent.CheckKey(keyPressEvent);<br>        KeyPressed(<span class="hljs-keyword">this</span>, <span class="hljs-keyword">new</span> RawKeyEventArg(keyPressEvent));<br>    &#125;<br>    <span class="hljs-keyword">if</span>(hotkeyPressEvent.hotActived)<br>    &#123;<br>        OnHotKeyPressed(<span class="hljs-keyword">this</span>, <span class="hljs-keyword">new</span> RawHotKeyEventArg(hotkeyPressEvent));<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="测试实现"><a href="#测试实现" class="headerlink" title="测试实现"></a>测试实现</h3><p>核心功能已经完成，再进行一些完善即可测试使用了。（当然，虽说是核心功能，但仅占到代码量的十分之一左右，这就是我不贴全代码的原因）</p><p>新建一个WPF窗体项目，并将该类库进行引用。由于，类库中的<code>RawInputManager</code>继承自<code>System.Windows.Forms</code>下的<code>NativeWindow</code>低级封装窗口，而<code>WPF</code>并不支持，所以要在<code>WPF</code>项目中同样对该命名空间进行引用。</p><p>在实例化<code>RawInputManager</code>对象时，需要提供窗体句柄，这个在<code>Winform</code>环境下只需<code>this.Handle</code>即可，但WPF窗体不支持句柄，可以通过引用<code>System.Windows.Interop</code>命名空间，使用<code>IntPtr handle = new WindowInteropHelper(this).Handle</code> 即可取得（但这样并不是经常起作用，在某些时候会出现获取不到的情况，即 handle值为0，此时可尝试另一种非安全的方法，即通过API入口调用非安全代码（不是<code>unsafe</code>代码块）获取窗体句柄（该方法不被官方建议使用）：</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs cs">[<span class="hljs-meta">System.Runtime.InteropServices.DllImport(<span class="hljs-string">&quot;user32.dll&quot;</span>)</span>]<br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">extern</span> IntPtr <span class="hljs-title">GetForegroundWindow</span>()</span>;<br><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">Window_Loaded</span>(<span class="hljs-params"><span class="hljs-built_in">object</span> sender, RoutedEventArgs e</span>)</span><br>&#123;<br>    IntPtr handle= GetForegroundWindow(); <span class="hljs-comment">//通过非安全代码获取句柄（不建议）</span><br>    KeyMap[] hotkey = &#123; KeyMap.LWin, KeyMap.LMenu , KeyMap.C &#125;;<br>    rawinput = <span class="hljs-keyword">new</span> RawInputManager(handle, <span class="hljs-literal">false</span>);<br>    rawinput.HotKeys = hotkey;<br>    rawinput.AddMessageFilter(); <span class="hljs-comment">//消息筛选过滤是为了让按键消息不再被其他应用处理</span><br>    rawinput.OnKeyPressed += rawinput_OnKeyPressed;<br>    rawinput.OnHotKeyPressed += rawinput_OnHotKeyPressed;<br>&#125;<br></code></pre></td></tr></table></figure><p>运行测试，从上面的代码可以看到，我们设置了快捷键为<strong>左Windows徽标键+左ALT键+C</strong>的三键组合，而按键信息会显示在窗体上：</p><ul><li>启动后依次按下键且不松开，可以看到此窗口并没有被Actived，但依旧能接收到按键信息：</li></ul><img src="/images/src-cs-rawinput-print.jpg" class="" title="按下键" alt="按下键"><ul><li>当设定的快捷按键被按下时，显示消息（或做出反应）：</li></ul><img src="/images/src-cs-rawinput-active.jpg" class="" title="激活快捷键" alt="激活快捷键"><p>当然，注意到设备源信息，你可以通过指定过滤设备源来实现不同输入设备区别处理。</p><blockquote><p>终于写完了，这应该是一篇理解很累的文章，具体内容<a href="/package/RawInputDemo.zip">参见源码</a>，有不懂的可以问我或度娘。如果文章有语病或错别字，请谅解，语文课是什么来着已经忘了。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>csharp</category>
      
    </categories>
    
    
    <tags>
      
      <tag>csharp</tag>
      
      <tag>win32</tag>
      
      <tag>wpf</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
